{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12050604,"sourceType":"datasetVersion","datasetId":7583917},{"sourceId":12059763,"sourceType":"datasetVersion","datasetId":7590496},{"sourceId":12060456,"sourceType":"datasetVersion","datasetId":7590998}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\nfrom tensorflow.keras import Sequential\n\n\nclass FederatedLearning:\n    def __init__(self, dataset_root, test_data_dir):\n        self.clients = [f\"client_{i}\" for i in range(1, 7)]\n        self.dataset_root = dataset_root\n        self.test_data_dir = test_data_dir\n        self.global_model = self.initialize_model()\n        self.client_data = self.load_client_data()\n        self.test_data = self.load_test_data()\n\n    def initialize_model(self):\n        model = load_model(\"/kaggle/input/braintumor-detection/xception_transfer_model.h5\")\n        model.trainable = True\n\n        # The second layer is likely the nested Xception base model\n        xception_layer = model.layers[1]\n        print(f\"Model layers count: {len(model.layers)}\")\n        print(f\"Xception nested model layers count: {len(xception_layer.layers)}\")\n\n        # Freeze first 50 layers of xception base model, unfreeze rest\n        for i, layer in enumerate(xception_layer.layers):\n            if i < 50:\n                layer.trainable = False\n            else:\n                layer.trainable = True\n\n        # Freeze other layers in top model except xception base model\n        for i, layer in enumerate(model.layers):\n            if i != 1:\n                layer.trainable = False\n\n        # Print trainable status to verify\n        for i, layer in enumerate(model.layers):\n            if layer.name == 'xception':\n                print(f\"Layer {i} - {layer.name} trainable: {layer.trainable}\")\n                for j, inner_layer in enumerate(layer.layers[:10]):\n                    print(f\"  Xception layer {j}: {inner_layer.name}, trainable={inner_layer.trainable}\")\n            else:\n                print(f\"Layer {i} - {layer.name} trainable: {layer.trainable}\")\n\n        return model\n\n    def normalize_img(self, x, y):\n        return tf.cast(x, tf.float32) / 255.0, y\n\n    def get_augmented_dataset(self, dataset):\n        data_augmentation = Sequential([\n            RandomFlip(\"horizontal\"),\n            RandomRotation(0.1),\n            RandomZoom(0.1),\n        ])\n        return dataset.map(lambda x, y: (data_augmentation(x, training=True), y)).map(self.normalize_img)\n\n    def load_client_data(self):\n        client_data = {}\n        for client in self.clients:\n            client_path = os.path.join(self.dataset_root, client)\n            if os.path.exists(client_path):\n                dataset = image_dataset_from_directory(\n                    client_path,\n                    image_size=(299, 299),\n                    batch_size=32,\n                    label_mode=\"categorical\",\n                    shuffle=True,\n                )\n                dataset = self.get_augmented_dataset(dataset)\n                print(f\"Loaded {client} dataset batches: {tf.data.experimental.cardinality(dataset).numpy()}\")\n                client_data[client] = dataset\n            else:\n                print(f\"Warning: {client_path} does not exist.\")\n        return client_data\n\n    def load_test_data(self):\n        if os.path.exists(self.test_data_dir):\n            test_dataset = image_dataset_from_directory(\n                self.test_data_dir,\n                image_size=(299, 299),\n                batch_size=32,\n                label_mode=\"categorical\",\n                shuffle=False\n            ).map(self.normalize_img)\n            print(f\"Loaded test dataset batches: {tf.data.experimental.cardinality(test_dataset).numpy()}\")\n            return test_dataset\n        else:\n            print(f\"Warning: Test data directory {self.test_data_dir} does not exist.\")\n            return None\n\n    def train_client_model(self, client_name):\n        local_model = tf.keras.models.clone_model(self.global_model)\n        local_model.build((None, 299, 299, 3))\n        local_model.set_weights(self.global_model.get_weights())\n        local_model.compile(\n            optimizer=Adamax(learning_rate=0.001, decay=1e-5),\n            loss='categorical_crossentropy',\n            metrics=['accuracy', Precision(), Recall()]\n        )\n\n        print(f\"Training {client_name} for 5 epochs...\")\n\n        sum_weights_before = np.sum([np.sum(w) for w in local_model.get_weights()])\n        print(f\"Sum of weights before training: {sum_weights_before:.3f}\")\n\n        history = local_model.fit(\n            self.client_data[client_name],\n            epochs=5,\n            verbose=1\n        )\n\n        sum_weights_after = np.sum([np.sum(w) for w in local_model.get_weights()])\n        print(f\"Sum of weights after training: {sum_weights_after:.3f}\")\n\n        global_weights = self.global_model.get_weights()\n        local_weights = local_model.get_weights()\n\n        total_diff = 0\n        for i, (g, l) in enumerate(zip(global_weights, local_weights)):\n            diff = np.sum(np.abs(g - l))\n            total_diff += diff\n            print(f\"{client_name} Layer {i} weight diff: {diff:.10f}\")\n\n        print(f\"{client_name} training accuracy history: {history.history['accuracy']}\")\n        print(f\"{client_name} total local-global weight diff: {total_diff:.8f}\")\n\n        return local_weights, history.history['accuracy'][-1]\n\n    def aggregate_weights(self, client_weights):\n        avg_weights = []\n        for weights_list_tuple in zip(*client_weights):\n            avg_weights.append(np.mean(weights_list_tuple, axis=0))\n        return avg_weights\n\n    def evaluate_global_model(self):\n        if self.test_data is None:\n            print(\"No test dataset found, skipping evaluation.\")\n            return None\n        self.global_model.compile(\n            optimizer=Adamax(learning_rate=0.0005),\n            loss='categorical_crossentropy',\n            metrics=['accuracy', Precision(), Recall()]\n        )\n        results = self.global_model.evaluate(self.test_data, verbose=0)\n        metrics_names = self.global_model.metrics_names\n        eval_results = dict(zip(metrics_names, results))\n        print(f\"\\n📈 Global model evaluation on test data: {eval_results}\")\n        return eval_results\n\n    def federated_training(self, rounds=1):\n        for r in range(rounds):\n            print(f\"\\n🔁 Federated Round {r + 1}\")\n\n            client_weights = []\n            accuracies = []\n\n            for client_name in self.client_data:\n                print(f\"\\n📶 Training on {client_name}\")\n                weights, acc = self.train_client_model(client_name)\n                client_weights.append(weights)\n                accuracies.append(acc)\n\n            new_weights = self.aggregate_weights(client_weights)\n            self.global_model.set_weights(new_weights)\n\n            avg_acc = np.mean(accuracies)\n            print(f\"\\n✅ Round {r + 1} average client accuracy: {avg_acc:.4f}\")\n\n            self.evaluate_global_model()\n\n        print(\"\\n✅ Federated training complete.\")\n\n\nif __name__ == \"__main__\":\n    dataset_root = r'/kaggle/input/braintumor-detection/final_clients/final_clients'\n    test_data_dir = r'/kaggle/input/braintumor-detection/final_test_data/final_test_data'\n    fl = FederatedLearning(dataset_root, test_data_dir)\n    fl.federated_training(rounds=10)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:37:19.576332Z","iopub.execute_input":"2025-06-04T12:37:19.576893Z","iopub.status.idle":"2025-06-04T13:50:14.335393Z","shell.execute_reply.started":"2025-06-04T12:37:19.576871Z","shell.execute_reply":"2025-06-04T13:50:14.333450Z"}},"outputs":[{"name":"stdout","text":"Model layers count: 7\nXception nested model layers count: 133\nLayer 0 - input_layer_1 trainable: False\nLayer 1 - xception trainable: False\n  Xception layer 0: input_layer, trainable=False\n  Xception layer 1: block1_conv1, trainable=False\n  Xception layer 2: block1_conv1_bn, trainable=False\n  Xception layer 3: block1_conv1_act, trainable=False\n  Xception layer 4: block1_conv2, trainable=False\n  Xception layer 5: block1_conv2_bn, trainable=False\n  Xception layer 6: block1_conv2_act, trainable=False\n  Xception layer 7: block2_sepconv1, trainable=False\n  Xception layer 8: block2_sepconv1_bn, trainable=False\n  Xception layer 9: block2_sepconv2_act, trainable=False\nLayer 2 - flatten trainable: False\nLayer 3 - dropout trainable: False\nLayer 4 - dense trainable: False\nLayer 5 - dropout_1 trainable: False\nLayer 6 - dense_1 trainable: False\nFound 954 files belonging to 4 classes.\nLoaded client_1 dataset batches: 30\nFound 952 files belonging to 4 classes.\nLoaded client_2 dataset batches: 30\nFound 952 files belonging to 4 classes.\nLoaded client_3 dataset batches: 30\nFound 952 files belonging to 4 classes.\nLoaded client_4 dataset batches: 30\nFound 952 files belonging to 4 classes.\nLoaded client_5 dataset batches: 30\nFound 950 files belonging to 4 classes.\nLoaded client_6 dataset batches: 30\nFound 1311 files belonging to 4 classes.\nLoaded test dataset batches: 41\n\n🔁 Federated Round 1\n\n📶 Training on client_1\nTraining client_1 for 5 epochs...\nSum of weights before training: 138648.625\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1749040677.203156      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040677.356446      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040678.523704      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040678.663873      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040679.220058      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040679.371706      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - accuracy: 0.6818 - loss: 0.9285 - precision_17: 0.7244 - recall_17: 0.6213","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1749040709.066803      97 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040709.216321      97 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040710.370261      97 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040710.510091      97 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040710.913377      97 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040711.064648      97 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.6882 - loss: 0.9084 - precision_17: 0.7305 - recall_17: 0.6289\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 663ms/step - accuracy: 0.9142 - loss: 0.2743 - precision_17: 0.9421 - recall_17: 0.8823\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 670ms/step - accuracy: 0.9365 - loss: 0.1704 - precision_17: 0.9456 - recall_17: 0.9328\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 697ms/step - accuracy: 0.9699 - loss: 0.0878 - precision_17: 0.9705 - recall_17: 0.9669\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 0.9597 - loss: 0.0841 - precision_17: 0.9622 - recall_17: 0.9580\nSum of weights after training: 169925.750\nclient_1 Layer 0 weight diff: 0.0000000000\nclient_1 Layer 1 weight diff: 0.0000000000\nclient_1 Layer 2 weight diff: 0.0000000000\nclient_1 Layer 3 weight diff: 0.0000000000\nclient_1 Layer 4 weight diff: 0.0000000000\nclient_1 Layer 5 weight diff: 0.0000000000\nclient_1 Layer 6 weight diff: 0.0000000000\nclient_1 Layer 7 weight diff: 0.0000000000\nclient_1 Layer 8 weight diff: 0.0000000000\nclient_1 Layer 9 weight diff: 0.0000000000\nclient_1 Layer 10 weight diff: 0.0000000000\nclient_1 Layer 11 weight diff: 0.0000000000\nclient_1 Layer 12 weight diff: 0.0000000000\nclient_1 Layer 13 weight diff: 0.0000000000\nclient_1 Layer 14 weight diff: 0.0000000000\nclient_1 Layer 15 weight diff: 0.0000000000\nclient_1 Layer 16 weight diff: 0.0000000000\nclient_1 Layer 17 weight diff: 0.0000000000\nclient_1 Layer 18 weight diff: 0.0000000000\nclient_1 Layer 19 weight diff: 0.0000000000\nclient_1 Layer 20 weight diff: 0.0000000000\nclient_1 Layer 21 weight diff: 0.0000000000\nclient_1 Layer 22 weight diff: 0.0000000000\nclient_1 Layer 23 weight diff: 0.0000000000\nclient_1 Layer 24 weight diff: 0.0000000000\nclient_1 Layer 25 weight diff: 0.0000000000\nclient_1 Layer 26 weight diff: 0.0000000000\nclient_1 Layer 27 weight diff: 0.0000000000\nclient_1 Layer 28 weight diff: 0.0000000000\nclient_1 Layer 29 weight diff: 0.0000000000\nclient_1 Layer 30 weight diff: 0.0000000000\nclient_1 Layer 31 weight diff: 0.0000000000\nclient_1 Layer 32 weight diff: 0.0000000000\nclient_1 Layer 33 weight diff: 0.0000000000\nclient_1 Layer 34 weight diff: 0.0000000000\nclient_1 Layer 35 weight diff: 0.0000000000\nclient_1 Layer 36 weight diff: 0.0000000000\nclient_1 Layer 37 weight diff: 0.0000000000\nclient_1 Layer 38 weight diff: 0.0000000000\nclient_1 Layer 39 weight diff: 0.0000000000\nclient_1 Layer 40 weight diff: 0.0000000000\nclient_1 Layer 41 weight diff: 0.0000000000\nclient_1 Layer 42 weight diff: 0.0000000000\nclient_1 Layer 43 weight diff: 0.0000000000\nclient_1 Layer 44 weight diff: 0.0000000000\nclient_1 Layer 45 weight diff: 0.0000000000\nclient_1 Layer 46 weight diff: 0.0000000000\nclient_1 Layer 47 weight diff: 0.0000000000\nclient_1 Layer 48 weight diff: 0.0000000000\nclient_1 Layer 49 weight diff: 0.0000000000\nclient_1 Layer 50 weight diff: 0.0000000000\nclient_1 Layer 51 weight diff: 0.0000000000\nclient_1 Layer 52 weight diff: 0.0000000000\nclient_1 Layer 53 weight diff: 0.0000000000\nclient_1 Layer 54 weight diff: 0.0000000000\nclient_1 Layer 55 weight diff: 0.0000000000\nclient_1 Layer 56 weight diff: 0.0000000000\nclient_1 Layer 57 weight diff: 0.0000000000\nclient_1 Layer 58 weight diff: 0.0000000000\nclient_1 Layer 59 weight diff: 0.0000000000\nclient_1 Layer 60 weight diff: 0.0000000000\nclient_1 Layer 61 weight diff: 0.0000000000\nclient_1 Layer 62 weight diff: 0.0000000000\nclient_1 Layer 63 weight diff: 0.0000000000\nclient_1 Layer 64 weight diff: 0.0000000000\nclient_1 Layer 65 weight diff: 0.0000000000\nclient_1 Layer 66 weight diff: 0.0000000000\nclient_1 Layer 67 weight diff: 0.0000000000\nclient_1 Layer 68 weight diff: 0.0000000000\nclient_1 Layer 69 weight diff: 0.0000000000\nclient_1 Layer 70 weight diff: 0.0000000000\nclient_1 Layer 71 weight diff: 0.0000000000\nclient_1 Layer 72 weight diff: 0.0000000000\nclient_1 Layer 73 weight diff: 0.0000000000\nclient_1 Layer 74 weight diff: 0.0000000000\nclient_1 Layer 75 weight diff: 0.0000000000\nclient_1 Layer 76 weight diff: 0.0000000000\nclient_1 Layer 77 weight diff: 0.0000000000\nclient_1 Layer 78 weight diff: 0.0000000000\nclient_1 Layer 79 weight diff: 0.0000000000\nclient_1 Layer 80 weight diff: 0.0000000000\nclient_1 Layer 81 weight diff: 0.0000000000\nclient_1 Layer 82 weight diff: 0.0000000000\nclient_1 Layer 83 weight diff: 0.0000000000\nclient_1 Layer 84 weight diff: 0.0000000000\nclient_1 Layer 85 weight diff: 22.7489433289\nclient_1 Layer 86 weight diff: 1780.2847900391\nclient_1 Layer 87 weight diff: 2.5011687279\nclient_1 Layer 88 weight diff: 2.4886579514\nclient_1 Layer 89 weight diff: 78.4552078247\nclient_1 Layer 90 weight diff: 65.7983093262\nclient_1 Layer 91 weight diff: 21.9365062714\nclient_1 Layer 92 weight diff: 1751.6800537109\nclient_1 Layer 93 weight diff: 2.4245555401\nclient_1 Layer 94 weight diff: 2.4776020050\nclient_1 Layer 95 weight diff: 31.9465999603\nclient_1 Layer 96 weight diff: 79.3008728027\nclient_1 Layer 97 weight diff: 21.8334369659\nclient_1 Layer 98 weight diff: 1775.5278320312\nclient_1 Layer 99 weight diff: 2.4003157616\nclient_1 Layer 100 weight diff: 2.3977208138\nclient_1 Layer 101 weight diff: 91.1921691895\nclient_1 Layer 102 weight diff: 77.3647155762\nclient_1 Layer 103 weight diff: 21.7993869781\nclient_1 Layer 104 weight diff: 1749.8374023438\nclient_1 Layer 105 weight diff: 2.3193261623\nclient_1 Layer 106 weight diff: 2.3349280357\nclient_1 Layer 107 weight diff: 16.9905662537\nclient_1 Layer 108 weight diff: 15.0301570892\nclient_1 Layer 109 weight diff: 21.7059669495\nclient_1 Layer 110 weight diff: 1744.8737792969\nclient_1 Layer 111 weight diff: 2.3842551708\nclient_1 Layer 112 weight diff: 2.4428081512\nclient_1 Layer 113 weight diff: 9.1795835495\nclient_1 Layer 114 weight diff: 24.5692596436\nclient_1 Layer 115 weight diff: 22.4438781738\nclient_1 Layer 116 weight diff: 1791.0068359375\nclient_1 Layer 117 weight diff: 2.4637639523\nclient_1 Layer 118 weight diff: 2.4207978249\nclient_1 Layer 119 weight diff: 55.8099250793\nclient_1 Layer 120 weight diff: 93.3552398682\nclient_1 Layer 121 weight diff: 21.3806114197\nclient_1 Layer 122 weight diff: 1762.5119628906\nclient_1 Layer 123 weight diff: 2.5121860504\nclient_1 Layer 124 weight diff: 2.4571917057\nclient_1 Layer 125 weight diff: 22.0424041748\nclient_1 Layer 126 weight diff: 16.0101127625\nclient_1 Layer 127 weight diff: 21.9062461853\nclient_1 Layer 128 weight diff: 1748.1827392578\nclient_1 Layer 129 weight diff: 2.3835604191\nclient_1 Layer 130 weight diff: 2.3842103481\nclient_1 Layer 131 weight diff: 13.0853462219\nclient_1 Layer 132 weight diff: 10.7990913391\nclient_1 Layer 133 weight diff: 21.6325435638\nclient_1 Layer 134 weight diff: 1755.1984863281\nclient_1 Layer 135 weight diff: 2.4948611259\nclient_1 Layer 136 weight diff: 2.5338854790\nclient_1 Layer 137 weight diff: 98.0629577637\nclient_1 Layer 138 weight diff: 124.7321319580\nclient_1 Layer 139 weight diff: 22.0476398468\nclient_1 Layer 140 weight diff: 1724.1752929688\nclient_1 Layer 141 weight diff: 2.4132156372\nclient_1 Layer 142 weight diff: 2.5091190338\nclient_1 Layer 143 weight diff: 23.4044151306\nclient_1 Layer 144 weight diff: 18.6635589600\nclient_1 Layer 145 weight diff: 21.3060607910\nclient_1 Layer 146 weight diff: 1697.8491210938\nclient_1 Layer 147 weight diff: 2.3252749443\nclient_1 Layer 148 weight diff: 2.3169686794\nclient_1 Layer 149 weight diff: 18.4176864624\nclient_1 Layer 150 weight diff: 12.4677791595\nclient_1 Layer 151 weight diff: 21.6039848328\nclient_1 Layer 152 weight diff: 1727.6032714844\nclient_1 Layer 153 weight diff: 2.3177471161\nclient_1 Layer 154 weight diff: 2.3756194115\nclient_1 Layer 155 weight diff: 68.4556121826\nclient_1 Layer 156 weight diff: 72.1146240234\nclient_1 Layer 157 weight diff: 20.6771583557\nclient_1 Layer 158 weight diff: 1702.8620605469\nclient_1 Layer 159 weight diff: 2.2639613152\nclient_1 Layer 160 weight diff: 2.2849748135\nclient_1 Layer 161 weight diff: 16.6515693665\nclient_1 Layer 162 weight diff: 12.5199069977\nclient_1 Layer 163 weight diff: 20.9794254303\nclient_1 Layer 164 weight diff: 1701.6367187500\nclient_1 Layer 165 weight diff: 2.4027583599\nclient_1 Layer 166 weight diff: 2.3282279968\nclient_1 Layer 167 weight diff: 11.2577409744\nclient_1 Layer 168 weight diff: 9.0677614212\nclient_1 Layer 169 weight diff: 21.1634864807\nclient_1 Layer 170 weight diff: 1711.8757324219\nclient_1 Layer 171 weight diff: 2.3180036545\nclient_1 Layer 172 weight diff: 2.4233992100\nclient_1 Layer 173 weight diff: 66.8083343506\nclient_1 Layer 174 weight diff: 89.1867370605\nclient_1 Layer 175 weight diff: 20.7340621948\nclient_1 Layer 176 weight diff: 1686.9678955078\nclient_1 Layer 177 weight diff: 2.2605459690\nclient_1 Layer 178 weight diff: 2.2570953369\nclient_1 Layer 179 weight diff: 14.5134935379\nclient_1 Layer 180 weight diff: 11.8245210648\nclient_1 Layer 181 weight diff: 20.1422042847\nclient_1 Layer 182 weight diff: 1684.8127441406\nclient_1 Layer 183 weight diff: 2.2726602554\nclient_1 Layer 184 weight diff: 2.3025417328\nclient_1 Layer 185 weight diff: 8.4579210281\nclient_1 Layer 186 weight diff: 5.2190713882\nclient_1 Layer 187 weight diff: 21.4047584534\nclient_1 Layer 188 weight diff: 1683.5468750000\nclient_1 Layer 189 weight diff: 2.3104295731\nclient_1 Layer 190 weight diff: 2.3887193203\nclient_1 Layer 191 weight diff: 96.0881271362\nclient_1 Layer 192 weight diff: 141.2055053711\nclient_1 Layer 193 weight diff: 20.4160652161\nclient_1 Layer 194 weight diff: 1664.3583984375\nclient_1 Layer 195 weight diff: 2.2509481907\nclient_1 Layer 196 weight diff: 2.2650508881\nclient_1 Layer 197 weight diff: 16.9576148987\nclient_1 Layer 198 weight diff: 15.1918487549\nclient_1 Layer 199 weight diff: 19.2294044495\nclient_1 Layer 200 weight diff: 1670.3670654297\nclient_1 Layer 201 weight diff: 2.3324511051\nclient_1 Layer 202 weight diff: 2.2826733589\nclient_1 Layer 203 weight diff: 9.1406326294\nclient_1 Layer 204 weight diff: 6.7448353767\nclient_1 Layer 205 weight diff: 20.5938549042\nclient_1 Layer 206 weight diff: 1657.6206054688\nclient_1 Layer 207 weight diff: 2.2709534168\nclient_1 Layer 208 weight diff: 2.2571563721\nclient_1 Layer 209 weight diff: 199.6386718750\nclient_1 Layer 210 weight diff: 485.1471557617\nclient_1 Layer 211 weight diff: 20.8875083923\nclient_1 Layer 212 weight diff: 2317.9995117188\nclient_1 Layer 213 weight diff: 3.2315890789\nclient_1 Layer 214 weight diff: 3.2529544830\nclient_1 Layer 215 weight diff: 35.7523345947\nclient_1 Layer 216 weight diff: 21.1051044464\nclient_1 Layer 217 weight diff: 2338.8186035156\nclient_1 Layer 218 weight diff: 3.1419670582\nclient_1 Layer 219 weight diff: 3.2529547215\nclient_1 Layer 220 weight diff: 1306.1791992188\nclient_1 Layer 221 weight diff: 39853.8320312500\nclient_1 Layer 222 weight diff: 30.1115837097\nclient_1 Layer 223 weight diff: 5015.9467773438\nclient_1 Layer 224 weight diff: 4.9680099487\nclient_1 Layer 225 weight diff: 4.8837108612\nclient_1 Layer 226 weight diff: 255.8050537109\nclient_1 Layer 227 weight diff: 580.3435058594\nclient_1 Layer 228 weight diff: 45.0117340088\nclient_1 Layer 229 weight diff: 9489.3261718750\nclient_1 Layer 230 weight diff: 7.0147752762\nclient_1 Layer 231 weight diff: 6.7928037643\nclient_1 Layer 232 weight diff: 407.0624389648\nclient_1 Layer 233 weight diff: 413.3345336914\nclient_1 Layer 234 weight diff: 0.0000000000\nclient_1 Layer 235 weight diff: 0.0000000000\nclient_1 Layer 236 weight diff: 0.0000000000\nclient_1 Layer 237 weight diff: 0.0000000000\nclient_1 training accuracy history: [0.7819706201553345, 0.9245283007621765, 0.9402515888214111, 0.9675052165985107, 0.9685534834861755]\nclient_1 total local-global weight diff: 101240.94221187\n\n📶 Training on client_2\nTraining client_2 for 5 epochs...\nSum of weights before training: 138648.625\nEpoch 1/5\n\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 668ms/step - accuracy: 0.7024 - loss: 0.9519 - precision_18: 0.7406 - recall_18: 0.6251","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1749040856.652349      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040856.798580      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040857.542016      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040857.681741      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040858.084399      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749040858.236020      95 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.7086 - loss: 0.9287 - precision_18: 0.7468 - recall_18: 0.6327\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 629ms/step - accuracy: 0.9370 - loss: 0.2172 - precision_18: 0.9406 - recall_18: 0.9240\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 681ms/step - accuracy: 0.9518 - loss: 0.1342 - precision_18: 0.9565 - recall_18: 0.9408\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 662ms/step - accuracy: 0.9616 - loss: 0.1040 - precision_18: 0.9627 - recall_18: 0.9610\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 642ms/step - accuracy: 0.9725 - loss: 0.0867 - precision_18: 0.9767 - recall_18: 0.9706\nSum of weights after training: 161540.625\nclient_2 Layer 0 weight diff: 0.0000000000\nclient_2 Layer 1 weight diff: 0.0000000000\nclient_2 Layer 2 weight diff: 0.0000000000\nclient_2 Layer 3 weight diff: 0.0000000000\nclient_2 Layer 4 weight diff: 0.0000000000\nclient_2 Layer 5 weight diff: 0.0000000000\nclient_2 Layer 6 weight diff: 0.0000000000\nclient_2 Layer 7 weight diff: 0.0000000000\nclient_2 Layer 8 weight diff: 0.0000000000\nclient_2 Layer 9 weight diff: 0.0000000000\nclient_2 Layer 10 weight diff: 0.0000000000\nclient_2 Layer 11 weight diff: 0.0000000000\nclient_2 Layer 12 weight diff: 0.0000000000\nclient_2 Layer 13 weight diff: 0.0000000000\nclient_2 Layer 14 weight diff: 0.0000000000\nclient_2 Layer 15 weight diff: 0.0000000000\nclient_2 Layer 16 weight diff: 0.0000000000\nclient_2 Layer 17 weight diff: 0.0000000000\nclient_2 Layer 18 weight diff: 0.0000000000\nclient_2 Layer 19 weight diff: 0.0000000000\nclient_2 Layer 20 weight diff: 0.0000000000\nclient_2 Layer 21 weight diff: 0.0000000000\nclient_2 Layer 22 weight diff: 0.0000000000\nclient_2 Layer 23 weight diff: 0.0000000000\nclient_2 Layer 24 weight diff: 0.0000000000\nclient_2 Layer 25 weight diff: 0.0000000000\nclient_2 Layer 26 weight diff: 0.0000000000\nclient_2 Layer 27 weight diff: 0.0000000000\nclient_2 Layer 28 weight diff: 0.0000000000\nclient_2 Layer 29 weight diff: 0.0000000000\nclient_2 Layer 30 weight diff: 0.0000000000\nclient_2 Layer 31 weight diff: 0.0000000000\nclient_2 Layer 32 weight diff: 0.0000000000\nclient_2 Layer 33 weight diff: 0.0000000000\nclient_2 Layer 34 weight diff: 0.0000000000\nclient_2 Layer 35 weight diff: 0.0000000000\nclient_2 Layer 36 weight diff: 0.0000000000\nclient_2 Layer 37 weight diff: 0.0000000000\nclient_2 Layer 38 weight diff: 0.0000000000\nclient_2 Layer 39 weight diff: 0.0000000000\nclient_2 Layer 40 weight diff: 0.0000000000\nclient_2 Layer 41 weight diff: 0.0000000000\nclient_2 Layer 42 weight diff: 0.0000000000\nclient_2 Layer 43 weight diff: 0.0000000000\nclient_2 Layer 44 weight diff: 0.0000000000\nclient_2 Layer 45 weight diff: 0.0000000000\nclient_2 Layer 46 weight diff: 0.0000000000\nclient_2 Layer 47 weight diff: 0.0000000000\nclient_2 Layer 48 weight diff: 0.0000000000\nclient_2 Layer 49 weight diff: 0.0000000000\nclient_2 Layer 50 weight diff: 0.0000000000\nclient_2 Layer 51 weight diff: 0.0000000000\nclient_2 Layer 52 weight diff: 0.0000000000\nclient_2 Layer 53 weight diff: 0.0000000000\nclient_2 Layer 54 weight diff: 0.0000000000\nclient_2 Layer 55 weight diff: 0.0000000000\nclient_2 Layer 56 weight diff: 0.0000000000\nclient_2 Layer 57 weight diff: 0.0000000000\nclient_2 Layer 58 weight diff: 0.0000000000\nclient_2 Layer 59 weight diff: 0.0000000000\nclient_2 Layer 60 weight diff: 0.0000000000\nclient_2 Layer 61 weight diff: 0.0000000000\nclient_2 Layer 62 weight diff: 0.0000000000\nclient_2 Layer 63 weight diff: 0.0000000000\nclient_2 Layer 64 weight diff: 0.0000000000\nclient_2 Layer 65 weight diff: 0.0000000000\nclient_2 Layer 66 weight diff: 0.0000000000\nclient_2 Layer 67 weight diff: 0.0000000000\nclient_2 Layer 68 weight diff: 0.0000000000\nclient_2 Layer 69 weight diff: 0.0000000000\nclient_2 Layer 70 weight diff: 0.0000000000\nclient_2 Layer 71 weight diff: 0.0000000000\nclient_2 Layer 72 weight diff: 0.0000000000\nclient_2 Layer 73 weight diff: 0.0000000000\nclient_2 Layer 74 weight diff: 0.0000000000\nclient_2 Layer 75 weight diff: 0.0000000000\nclient_2 Layer 76 weight diff: 0.0000000000\nclient_2 Layer 77 weight diff: 0.0000000000\nclient_2 Layer 78 weight diff: 0.0000000000\nclient_2 Layer 79 weight diff: 0.0000000000\nclient_2 Layer 80 weight diff: 0.0000000000\nclient_2 Layer 81 weight diff: 0.0000000000\nclient_2 Layer 82 weight diff: 0.0000000000\nclient_2 Layer 83 weight diff: 0.0000000000\nclient_2 Layer 84 weight diff: 0.0000000000\nclient_2 Layer 85 weight diff: 24.0884799957\nclient_2 Layer 86 weight diff: 1820.7714843750\nclient_2 Layer 87 weight diff: 2.6016912460\nclient_2 Layer 88 weight diff: 2.5804519653\nclient_2 Layer 89 weight diff: 75.5851745605\nclient_2 Layer 90 weight diff: 62.2363624573\nclient_2 Layer 91 weight diff: 22.1929779053\nclient_2 Layer 92 weight diff: 1791.2546386719\nclient_2 Layer 93 weight diff: 2.4177308083\nclient_2 Layer 94 weight diff: 2.4200465679\nclient_2 Layer 95 weight diff: 28.8697433472\nclient_2 Layer 96 weight diff: 82.2600860596\nclient_2 Layer 97 weight diff: 22.6210250854\nclient_2 Layer 98 weight diff: 1838.2097167969\nclient_2 Layer 99 weight diff: 2.4937906265\nclient_2 Layer 100 weight diff: 2.5425305367\nclient_2 Layer 101 weight diff: 83.9439392090\nclient_2 Layer 102 weight diff: 73.5468750000\nclient_2 Layer 103 weight diff: 22.8470726013\nclient_2 Layer 104 weight diff: 1819.2395019531\nclient_2 Layer 105 weight diff: 2.5590281487\nclient_2 Layer 106 weight diff: 2.5704789162\nclient_2 Layer 107 weight diff: 14.7496376038\nclient_2 Layer 108 weight diff: 15.4633274078\nclient_2 Layer 109 weight diff: 22.4337196350\nclient_2 Layer 110 weight diff: 1803.1730957031\nclient_2 Layer 111 weight diff: 2.5089564323\nclient_2 Layer 112 weight diff: 2.3988089561\nclient_2 Layer 113 weight diff: 10.1347017288\nclient_2 Layer 114 weight diff: 18.3862571716\nclient_2 Layer 115 weight diff: 22.9096374512\nclient_2 Layer 116 weight diff: 1827.9248046875\nclient_2 Layer 117 weight diff: 2.3914327621\nclient_2 Layer 118 weight diff: 2.4698512554\nclient_2 Layer 119 weight diff: 57.1133728027\nclient_2 Layer 120 weight diff: 87.2621612549\nclient_2 Layer 121 weight diff: 22.6305465698\nclient_2 Layer 122 weight diff: 1809.1865234375\nclient_2 Layer 123 weight diff: 2.4657988548\nclient_2 Layer 124 weight diff: 2.5083475113\nclient_2 Layer 125 weight diff: 19.1446514130\nclient_2 Layer 126 weight diff: 15.8436660767\nclient_2 Layer 127 weight diff: 21.8396663666\nclient_2 Layer 128 weight diff: 1791.5844726562\nclient_2 Layer 129 weight diff: 2.4124891758\nclient_2 Layer 130 weight diff: 2.4610426426\nclient_2 Layer 131 weight diff: 11.8415451050\nclient_2 Layer 132 weight diff: 13.9054412842\nclient_2 Layer 133 weight diff: 22.2360935211\nclient_2 Layer 134 weight diff: 1798.6435546875\nclient_2 Layer 135 weight diff: 2.6629881859\nclient_2 Layer 136 weight diff: 2.6797213554\nclient_2 Layer 137 weight diff: 94.4989929199\nclient_2 Layer 138 weight diff: 109.2390136719\nclient_2 Layer 139 weight diff: 22.5071029663\nclient_2 Layer 140 weight diff: 1765.5943603516\nclient_2 Layer 141 weight diff: 2.4444394112\nclient_2 Layer 142 weight diff: 2.4508435726\nclient_2 Layer 143 weight diff: 16.5861244202\nclient_2 Layer 144 weight diff: 20.5352935791\nclient_2 Layer 145 weight diff: 21.7747573853\nclient_2 Layer 146 weight diff: 1754.6523437500\nclient_2 Layer 147 weight diff: 2.3913154602\nclient_2 Layer 148 weight diff: 2.4106111526\nclient_2 Layer 149 weight diff: 18.0561084747\nclient_2 Layer 150 weight diff: 10.2865362167\nclient_2 Layer 151 weight diff: 22.2732143402\nclient_2 Layer 152 weight diff: 1778.1168212891\nclient_2 Layer 153 weight diff: 2.4247355461\nclient_2 Layer 154 weight diff: 2.5176384449\nclient_2 Layer 155 weight diff: 67.5571365356\nclient_2 Layer 156 weight diff: 68.5650100708\nclient_2 Layer 157 weight diff: 22.1075172424\nclient_2 Layer 158 weight diff: 1751.9877929688\nclient_2 Layer 159 weight diff: 2.3732440472\nclient_2 Layer 160 weight diff: 2.4071092606\nclient_2 Layer 161 weight diff: 12.9903373718\nclient_2 Layer 162 weight diff: 12.9977684021\nclient_2 Layer 163 weight diff: 21.8533592224\nclient_2 Layer 164 weight diff: 1743.7471923828\nclient_2 Layer 165 weight diff: 2.3244071007\nclient_2 Layer 166 weight diff: 2.3294286728\nclient_2 Layer 167 weight diff: 13.3160896301\nclient_2 Layer 168 weight diff: 10.9534759521\nclient_2 Layer 169 weight diff: 21.8816184998\nclient_2 Layer 170 weight diff: 1762.9938964844\nclient_2 Layer 171 weight diff: 2.5031750202\nclient_2 Layer 172 weight diff: 2.5074517727\nclient_2 Layer 173 weight diff: 71.7701034546\nclient_2 Layer 174 weight diff: 88.1367263794\nclient_2 Layer 175 weight diff: 21.7903022766\nclient_2 Layer 176 weight diff: 1729.5834960938\nclient_2 Layer 177 weight diff: 2.3743221760\nclient_2 Layer 178 weight diff: 2.3495683670\nclient_2 Layer 179 weight diff: 13.8646173477\nclient_2 Layer 180 weight diff: 16.6155166626\nclient_2 Layer 181 weight diff: 21.2012405396\nclient_2 Layer 182 weight diff: 1726.9858398438\nclient_2 Layer 183 weight diff: 2.4555628300\nclient_2 Layer 184 weight diff: 2.3989691734\nclient_2 Layer 185 weight diff: 7.9584703445\nclient_2 Layer 186 weight diff: 8.5796546936\nclient_2 Layer 187 weight diff: 22.4587917328\nclient_2 Layer 188 weight diff: 1736.3673095703\nclient_2 Layer 189 weight diff: 2.3863325119\nclient_2 Layer 190 weight diff: 2.4179239273\nclient_2 Layer 191 weight diff: 94.4605407715\nclient_2 Layer 192 weight diff: 133.7458343506\nclient_2 Layer 193 weight diff: 21.3728160858\nclient_2 Layer 194 weight diff: 1716.8985595703\nclient_2 Layer 195 weight diff: 2.4055390358\nclient_2 Layer 196 weight diff: 2.4025797844\nclient_2 Layer 197 weight diff: 18.3109436035\nclient_2 Layer 198 weight diff: 14.4324369431\nclient_2 Layer 199 weight diff: 21.7527999878\nclient_2 Layer 200 weight diff: 1716.5717773438\nclient_2 Layer 201 weight diff: 2.2533321381\nclient_2 Layer 202 weight diff: 2.2965514660\nclient_2 Layer 203 weight diff: 8.8331146240\nclient_2 Layer 204 weight diff: 4.7709407806\nclient_2 Layer 205 weight diff: 21.3099212646\nclient_2 Layer 206 weight diff: 1701.6076660156\nclient_2 Layer 207 weight diff: 2.3571252823\nclient_2 Layer 208 weight diff: 2.3794095516\nclient_2 Layer 209 weight diff: 237.5836486816\nclient_2 Layer 210 weight diff: 444.4395446777\nclient_2 Layer 211 weight diff: 20.7846641541\nclient_2 Layer 212 weight diff: 2381.1108398438\nclient_2 Layer 213 weight diff: 3.3514039516\nclient_2 Layer 214 weight diff: 3.0021638870\nclient_2 Layer 215 weight diff: 42.7437973022\nclient_2 Layer 216 weight diff: 28.8916168213\nclient_2 Layer 217 weight diff: 2438.1479492188\nclient_2 Layer 218 weight diff: 3.3090057373\nclient_2 Layer 219 weight diff: 3.0021634102\nclient_2 Layer 220 weight diff: 1424.5780029297\nclient_2 Layer 221 weight diff: 34218.6562500000\nclient_2 Layer 222 weight diff: 30.3934688568\nclient_2 Layer 223 weight diff: 5131.1176757812\nclient_2 Layer 224 weight diff: 5.1396241188\nclient_2 Layer 225 weight diff: 5.1247558594\nclient_2 Layer 226 weight diff: 220.4494323730\nclient_2 Layer 227 weight diff: 630.1194458008\nclient_2 Layer 228 weight diff: 45.8543777466\nclient_2 Layer 229 weight diff: 9876.3037109375\nclient_2 Layer 230 weight diff: 6.9258203506\nclient_2 Layer 231 weight diff: 6.5130100250\nclient_2 Layer 232 weight diff: 332.2516174316\nclient_2 Layer 233 weight diff: 380.7167663574\nclient_2 Layer 234 weight diff: 0.0000000000\nclient_2 Layer 235 weight diff: 0.0000000000\nclient_2 Layer 236 weight diff: 0.0000000000\nclient_2 Layer 237 weight diff: 0.0000000000\nclient_2 training accuracy history: [0.7983193397521973, 0.924369752407074, 0.944327712059021, 0.9642857313156128, 0.9726890921592712]\nclient_2 total local-global weight diff: 97281.74279690\n\n📶 Training on client_3\nTraining client_3 for 5 epochs...\nSum of weights before training: 138648.625\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 922ms/step - accuracy: 0.7145 - loss: 0.8520 - precision_19: 0.7532 - recall_19: 0.6759\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 652ms/step - accuracy: 0.8910 - loss: 0.2978 - precision_19: 0.9165 - recall_19: 0.8819\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 674ms/step - accuracy: 0.9489 - loss: 0.1204 - precision_19: 0.9525 - recall_19: 0.9464\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 650ms/step - accuracy: 0.9588 - loss: 0.0848 - precision_19: 0.9692 - recall_19: 0.9560\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 634ms/step - accuracy: 0.9810 - loss: 0.0568 - precision_19: 0.9829 - recall_19: 0.9776\nSum of weights after training: 121698.070\nclient_3 Layer 0 weight diff: 0.0000000000\nclient_3 Layer 1 weight diff: 0.0000000000\nclient_3 Layer 2 weight diff: 0.0000000000\nclient_3 Layer 3 weight diff: 0.0000000000\nclient_3 Layer 4 weight diff: 0.0000000000\nclient_3 Layer 5 weight diff: 0.0000000000\nclient_3 Layer 6 weight diff: 0.0000000000\nclient_3 Layer 7 weight diff: 0.0000000000\nclient_3 Layer 8 weight diff: 0.0000000000\nclient_3 Layer 9 weight diff: 0.0000000000\nclient_3 Layer 10 weight diff: 0.0000000000\nclient_3 Layer 11 weight diff: 0.0000000000\nclient_3 Layer 12 weight diff: 0.0000000000\nclient_3 Layer 13 weight diff: 0.0000000000\nclient_3 Layer 14 weight diff: 0.0000000000\nclient_3 Layer 15 weight diff: 0.0000000000\nclient_3 Layer 16 weight diff: 0.0000000000\nclient_3 Layer 17 weight diff: 0.0000000000\nclient_3 Layer 18 weight diff: 0.0000000000\nclient_3 Layer 19 weight diff: 0.0000000000\nclient_3 Layer 20 weight diff: 0.0000000000\nclient_3 Layer 21 weight diff: 0.0000000000\nclient_3 Layer 22 weight diff: 0.0000000000\nclient_3 Layer 23 weight diff: 0.0000000000\nclient_3 Layer 24 weight diff: 0.0000000000\nclient_3 Layer 25 weight diff: 0.0000000000\nclient_3 Layer 26 weight diff: 0.0000000000\nclient_3 Layer 27 weight diff: 0.0000000000\nclient_3 Layer 28 weight diff: 0.0000000000\nclient_3 Layer 29 weight diff: 0.0000000000\nclient_3 Layer 30 weight diff: 0.0000000000\nclient_3 Layer 31 weight diff: 0.0000000000\nclient_3 Layer 32 weight diff: 0.0000000000\nclient_3 Layer 33 weight diff: 0.0000000000\nclient_3 Layer 34 weight diff: 0.0000000000\nclient_3 Layer 35 weight diff: 0.0000000000\nclient_3 Layer 36 weight diff: 0.0000000000\nclient_3 Layer 37 weight diff: 0.0000000000\nclient_3 Layer 38 weight diff: 0.0000000000\nclient_3 Layer 39 weight diff: 0.0000000000\nclient_3 Layer 40 weight diff: 0.0000000000\nclient_3 Layer 41 weight diff: 0.0000000000\nclient_3 Layer 42 weight diff: 0.0000000000\nclient_3 Layer 43 weight diff: 0.0000000000\nclient_3 Layer 44 weight diff: 0.0000000000\nclient_3 Layer 45 weight diff: 0.0000000000\nclient_3 Layer 46 weight diff: 0.0000000000\nclient_3 Layer 47 weight diff: 0.0000000000\nclient_3 Layer 48 weight diff: 0.0000000000\nclient_3 Layer 49 weight diff: 0.0000000000\nclient_3 Layer 50 weight diff: 0.0000000000\nclient_3 Layer 51 weight diff: 0.0000000000\nclient_3 Layer 52 weight diff: 0.0000000000\nclient_3 Layer 53 weight diff: 0.0000000000\nclient_3 Layer 54 weight diff: 0.0000000000\nclient_3 Layer 55 weight diff: 0.0000000000\nclient_3 Layer 56 weight diff: 0.0000000000\nclient_3 Layer 57 weight diff: 0.0000000000\nclient_3 Layer 58 weight diff: 0.0000000000\nclient_3 Layer 59 weight diff: 0.0000000000\nclient_3 Layer 60 weight diff: 0.0000000000\nclient_3 Layer 61 weight diff: 0.0000000000\nclient_3 Layer 62 weight diff: 0.0000000000\nclient_3 Layer 63 weight diff: 0.0000000000\nclient_3 Layer 64 weight diff: 0.0000000000\nclient_3 Layer 65 weight diff: 0.0000000000\nclient_3 Layer 66 weight diff: 0.0000000000\nclient_3 Layer 67 weight diff: 0.0000000000\nclient_3 Layer 68 weight diff: 0.0000000000\nclient_3 Layer 69 weight diff: 0.0000000000\nclient_3 Layer 70 weight diff: 0.0000000000\nclient_3 Layer 71 weight diff: 0.0000000000\nclient_3 Layer 72 weight diff: 0.0000000000\nclient_3 Layer 73 weight diff: 0.0000000000\nclient_3 Layer 74 weight diff: 0.0000000000\nclient_3 Layer 75 weight diff: 0.0000000000\nclient_3 Layer 76 weight diff: 0.0000000000\nclient_3 Layer 77 weight diff: 0.0000000000\nclient_3 Layer 78 weight diff: 0.0000000000\nclient_3 Layer 79 weight diff: 0.0000000000\nclient_3 Layer 80 weight diff: 0.0000000000\nclient_3 Layer 81 weight diff: 0.0000000000\nclient_3 Layer 82 weight diff: 0.0000000000\nclient_3 Layer 83 weight diff: 0.0000000000\nclient_3 Layer 84 weight diff: 0.0000000000\nclient_3 Layer 85 weight diff: 24.6171855927\nclient_3 Layer 86 weight diff: 1831.6461181641\nclient_3 Layer 87 weight diff: 2.6166706085\nclient_3 Layer 88 weight diff: 2.5912036896\nclient_3 Layer 89 weight diff: 76.4385375977\nclient_3 Layer 90 weight diff: 61.3222579956\nclient_3 Layer 91 weight diff: 22.7071571350\nclient_3 Layer 92 weight diff: 1760.2454833984\nclient_3 Layer 93 weight diff: 2.4577040672\nclient_3 Layer 94 weight diff: 2.4328842163\nclient_3 Layer 95 weight diff: 28.4163589478\nclient_3 Layer 96 weight diff: 74.3445816040\nclient_3 Layer 97 weight diff: 22.2553977966\nclient_3 Layer 98 weight diff: 1783.6081542969\nclient_3 Layer 99 weight diff: 2.3640074730\nclient_3 Layer 100 weight diff: 2.2512845993\nclient_3 Layer 101 weight diff: 85.8429183960\nclient_3 Layer 102 weight diff: 74.4093399048\nclient_3 Layer 103 weight diff: 21.5973472595\nclient_3 Layer 104 weight diff: 1768.0847167969\nclient_3 Layer 105 weight diff: 2.4080836773\nclient_3 Layer 106 weight diff: 2.4275162220\nclient_3 Layer 107 weight diff: 15.2155590057\nclient_3 Layer 108 weight diff: 14.1062116623\nclient_3 Layer 109 weight diff: 21.8691368103\nclient_3 Layer 110 weight diff: 1747.3906250000\nclient_3 Layer 111 weight diff: 2.3288879395\nclient_3 Layer 112 weight diff: 2.3807687759\nclient_3 Layer 113 weight diff: 9.2216768265\nclient_3 Layer 114 weight diff: 45.9351272583\nclient_3 Layer 115 weight diff: 22.0171051025\nclient_3 Layer 116 weight diff: 1758.9871826172\nclient_3 Layer 117 weight diff: 2.3076229095\nclient_3 Layer 118 weight diff: 2.4042947292\nclient_3 Layer 119 weight diff: 50.1869659424\nclient_3 Layer 120 weight diff: 87.8530502319\nclient_3 Layer 121 weight diff: 21.4494285583\nclient_3 Layer 122 weight diff: 1740.7448730469\nclient_3 Layer 123 weight diff: 2.3229892254\nclient_3 Layer 124 weight diff: 2.2773404121\nclient_3 Layer 125 weight diff: 16.2678070068\nclient_3 Layer 126 weight diff: 15.0061817169\nclient_3 Layer 127 weight diff: 20.8444900513\nclient_3 Layer 128 weight diff: 1728.3134765625\nclient_3 Layer 129 weight diff: 2.3892383575\nclient_3 Layer 130 weight diff: 2.3320288658\nclient_3 Layer 131 weight diff: 11.8955001831\nclient_3 Layer 132 weight diff: 9.6901283264\nclient_3 Layer 133 weight diff: 21.6729164124\nclient_3 Layer 134 weight diff: 1746.1533203125\nclient_3 Layer 135 weight diff: 2.4066004753\nclient_3 Layer 136 weight diff: 2.4146890640\nclient_3 Layer 137 weight diff: 99.6116790771\nclient_3 Layer 138 weight diff: 120.7084503174\nclient_3 Layer 139 weight diff: 21.4476623535\nclient_3 Layer 140 weight diff: 1712.6546630859\nclient_3 Layer 141 weight diff: 2.3810856342\nclient_3 Layer 142 weight diff: 2.3633260727\nclient_3 Layer 143 weight diff: 20.5390243530\nclient_3 Layer 144 weight diff: 22.6927146912\nclient_3 Layer 145 weight diff: 21.1237335205\nclient_3 Layer 146 weight diff: 1696.1606445312\nclient_3 Layer 147 weight diff: 2.3862009048\nclient_3 Layer 148 weight diff: 2.5126276016\nclient_3 Layer 149 weight diff: 20.3673667908\nclient_3 Layer 150 weight diff: 20.6952285767\nclient_3 Layer 151 weight diff: 21.1232414246\nclient_3 Layer 152 weight diff: 1699.1684570312\nclient_3 Layer 153 weight diff: 2.2511277199\nclient_3 Layer 154 weight diff: 2.2980294228\nclient_3 Layer 155 weight diff: 72.1939620972\nclient_3 Layer 156 weight diff: 73.0839385986\nclient_3 Layer 157 weight diff: 20.7084503174\nclient_3 Layer 158 weight diff: 1680.7043457031\nclient_3 Layer 159 weight diff: 2.1882026196\nclient_3 Layer 160 weight diff: 2.2104814053\nclient_3 Layer 161 weight diff: 13.8612422943\nclient_3 Layer 162 weight diff: 13.8771305084\nclient_3 Layer 163 weight diff: 19.9710350037\nclient_3 Layer 164 weight diff: 1672.7990722656\nclient_3 Layer 165 weight diff: 2.2034120560\nclient_3 Layer 166 weight diff: 2.4537174702\nclient_3 Layer 167 weight diff: 10.2700386047\nclient_3 Layer 168 weight diff: 6.5246896744\nclient_3 Layer 169 weight diff: 20.9742965698\nclient_3 Layer 170 weight diff: 1696.8414306641\nclient_3 Layer 171 weight diff: 2.3962063789\nclient_3 Layer 172 weight diff: 2.4262418747\nclient_3 Layer 173 weight diff: 72.5065841675\nclient_3 Layer 174 weight diff: 87.5173187256\nclient_3 Layer 175 weight diff: 20.6310634613\nclient_3 Layer 176 weight diff: 1672.4820556641\nclient_3 Layer 177 weight diff: 2.2642884254\nclient_3 Layer 178 weight diff: 2.2889914513\nclient_3 Layer 179 weight diff: 13.7081336975\nclient_3 Layer 180 weight diff: 12.0492992401\nclient_3 Layer 181 weight diff: 20.0560512543\nclient_3 Layer 182 weight diff: 1661.1276855469\nclient_3 Layer 183 weight diff: 2.2870371342\nclient_3 Layer 184 weight diff: 2.2838172913\nclient_3 Layer 185 weight diff: 8.2186298370\nclient_3 Layer 186 weight diff: 4.7219791412\nclient_3 Layer 187 weight diff: 20.5298423767\nclient_3 Layer 188 weight diff: 1669.8188476562\nclient_3 Layer 189 weight diff: 2.3319892883\nclient_3 Layer 190 weight diff: 2.3450200558\nclient_3 Layer 191 weight diff: 97.1961975098\nclient_3 Layer 192 weight diff: 138.3760070801\nclient_3 Layer 193 weight diff: 20.5627784729\nclient_3 Layer 194 weight diff: 1654.1730957031\nclient_3 Layer 195 weight diff: 2.1913893223\nclient_3 Layer 196 weight diff: 2.2351469994\nclient_3 Layer 197 weight diff: 18.2461776733\nclient_3 Layer 198 weight diff: 15.2571182251\nclient_3 Layer 199 weight diff: 19.8900909424\nclient_3 Layer 200 weight diff: 1657.3009033203\nclient_3 Layer 201 weight diff: 2.3709168434\nclient_3 Layer 202 weight diff: 2.3601450920\nclient_3 Layer 203 weight diff: 10.1215896606\nclient_3 Layer 204 weight diff: 8.8168964386\nclient_3 Layer 205 weight diff: 20.2502822876\nclient_3 Layer 206 weight diff: 1651.2823486328\nclient_3 Layer 207 weight diff: 2.3125126362\nclient_3 Layer 208 weight diff: 2.3074231148\nclient_3 Layer 209 weight diff: 184.2263793945\nclient_3 Layer 210 weight diff: 482.6903991699\nclient_3 Layer 211 weight diff: 20.9090461731\nclient_3 Layer 212 weight diff: 2341.7373046875\nclient_3 Layer 213 weight diff: 3.2874298096\nclient_3 Layer 214 weight diff: 2.9523339272\nclient_3 Layer 215 weight diff: 35.2183761597\nclient_3 Layer 216 weight diff: 21.5280551910\nclient_3 Layer 217 weight diff: 2333.7246093750\nclient_3 Layer 218 weight diff: 3.0766749382\nclient_3 Layer 219 weight diff: 2.9523344040\nclient_3 Layer 220 weight diff: 1152.3939208984\nclient_3 Layer 221 weight diff: 30869.2871093750\nclient_3 Layer 222 weight diff: 29.5659351349\nclient_3 Layer 223 weight diff: 4940.2900390625\nclient_3 Layer 224 weight diff: 4.8879375458\nclient_3 Layer 225 weight diff: 4.7755012512\nclient_3 Layer 226 weight diff: 232.8246765137\nclient_3 Layer 227 weight diff: 750.9274902344\nclient_3 Layer 228 weight diff: 43.9948043823\nclient_3 Layer 229 weight diff: 9568.4287109375\nclient_3 Layer 230 weight diff: 6.9056248665\nclient_3 Layer 231 weight diff: 6.9645195007\nclient_3 Layer 232 weight diff: 557.8610839844\nclient_3 Layer 233 weight diff: 608.4080810547\nclient_3 Layer 234 weight diff: 0.0000000000\nclient_3 Layer 235 weight diff: 0.0000000000\nclient_3 Layer 236 weight diff: 0.0000000000\nclient_3 Layer 237 weight diff: 0.0000000000\nclient_3 training accuracy history: [0.7878151535987854, 0.904411792755127, 0.944327712059021, 0.9642857313156128, 0.9768907427787781]\nclient_3 total local-global weight diff: 92401.88132238\n\n📶 Training on client_4\nTraining client_4 for 5 epochs...\nSum of weights before training: 138648.625\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 922ms/step - accuracy: 0.6938 - loss: 0.9704 - precision_20: 0.7199 - recall_20: 0.6328\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 684ms/step - accuracy: 0.8992 - loss: 0.2567 - precision_20: 0.9169 - recall_20: 0.8804\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 671ms/step - accuracy: 0.9561 - loss: 0.1417 - precision_20: 0.9602 - recall_20: 0.9552\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 665ms/step - accuracy: 0.9783 - loss: 0.0819 - precision_20: 0.9793 - recall_20: 0.9705\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 627ms/step - accuracy: 0.9673 - loss: 0.0746 - precision_20: 0.9719 - recall_20: 0.9666\nSum of weights after training: 168799.781\nclient_4 Layer 0 weight diff: 0.0000000000\nclient_4 Layer 1 weight diff: 0.0000000000\nclient_4 Layer 2 weight diff: 0.0000000000\nclient_4 Layer 3 weight diff: 0.0000000000\nclient_4 Layer 4 weight diff: 0.0000000000\nclient_4 Layer 5 weight diff: 0.0000000000\nclient_4 Layer 6 weight diff: 0.0000000000\nclient_4 Layer 7 weight diff: 0.0000000000\nclient_4 Layer 8 weight diff: 0.0000000000\nclient_4 Layer 9 weight diff: 0.0000000000\nclient_4 Layer 10 weight diff: 0.0000000000\nclient_4 Layer 11 weight diff: 0.0000000000\nclient_4 Layer 12 weight diff: 0.0000000000\nclient_4 Layer 13 weight diff: 0.0000000000\nclient_4 Layer 14 weight diff: 0.0000000000\nclient_4 Layer 15 weight diff: 0.0000000000\nclient_4 Layer 16 weight diff: 0.0000000000\nclient_4 Layer 17 weight diff: 0.0000000000\nclient_4 Layer 18 weight diff: 0.0000000000\nclient_4 Layer 19 weight diff: 0.0000000000\nclient_4 Layer 20 weight diff: 0.0000000000\nclient_4 Layer 21 weight diff: 0.0000000000\nclient_4 Layer 22 weight diff: 0.0000000000\nclient_4 Layer 23 weight diff: 0.0000000000\nclient_4 Layer 24 weight diff: 0.0000000000\nclient_4 Layer 25 weight diff: 0.0000000000\nclient_4 Layer 26 weight diff: 0.0000000000\nclient_4 Layer 27 weight diff: 0.0000000000\nclient_4 Layer 28 weight diff: 0.0000000000\nclient_4 Layer 29 weight diff: 0.0000000000\nclient_4 Layer 30 weight diff: 0.0000000000\nclient_4 Layer 31 weight diff: 0.0000000000\nclient_4 Layer 32 weight diff: 0.0000000000\nclient_4 Layer 33 weight diff: 0.0000000000\nclient_4 Layer 34 weight diff: 0.0000000000\nclient_4 Layer 35 weight diff: 0.0000000000\nclient_4 Layer 36 weight diff: 0.0000000000\nclient_4 Layer 37 weight diff: 0.0000000000\nclient_4 Layer 38 weight diff: 0.0000000000\nclient_4 Layer 39 weight diff: 0.0000000000\nclient_4 Layer 40 weight diff: 0.0000000000\nclient_4 Layer 41 weight diff: 0.0000000000\nclient_4 Layer 42 weight diff: 0.0000000000\nclient_4 Layer 43 weight diff: 0.0000000000\nclient_4 Layer 44 weight diff: 0.0000000000\nclient_4 Layer 45 weight diff: 0.0000000000\nclient_4 Layer 46 weight diff: 0.0000000000\nclient_4 Layer 47 weight diff: 0.0000000000\nclient_4 Layer 48 weight diff: 0.0000000000\nclient_4 Layer 49 weight diff: 0.0000000000\nclient_4 Layer 50 weight diff: 0.0000000000\nclient_4 Layer 51 weight diff: 0.0000000000\nclient_4 Layer 52 weight diff: 0.0000000000\nclient_4 Layer 53 weight diff: 0.0000000000\nclient_4 Layer 54 weight diff: 0.0000000000\nclient_4 Layer 55 weight diff: 0.0000000000\nclient_4 Layer 56 weight diff: 0.0000000000\nclient_4 Layer 57 weight diff: 0.0000000000\nclient_4 Layer 58 weight diff: 0.0000000000\nclient_4 Layer 59 weight diff: 0.0000000000\nclient_4 Layer 60 weight diff: 0.0000000000\nclient_4 Layer 61 weight diff: 0.0000000000\nclient_4 Layer 62 weight diff: 0.0000000000\nclient_4 Layer 63 weight diff: 0.0000000000\nclient_4 Layer 64 weight diff: 0.0000000000\nclient_4 Layer 65 weight diff: 0.0000000000\nclient_4 Layer 66 weight diff: 0.0000000000\nclient_4 Layer 67 weight diff: 0.0000000000\nclient_4 Layer 68 weight diff: 0.0000000000\nclient_4 Layer 69 weight diff: 0.0000000000\nclient_4 Layer 70 weight diff: 0.0000000000\nclient_4 Layer 71 weight diff: 0.0000000000\nclient_4 Layer 72 weight diff: 0.0000000000\nclient_4 Layer 73 weight diff: 0.0000000000\nclient_4 Layer 74 weight diff: 0.0000000000\nclient_4 Layer 75 weight diff: 0.0000000000\nclient_4 Layer 76 weight diff: 0.0000000000\nclient_4 Layer 77 weight diff: 0.0000000000\nclient_4 Layer 78 weight diff: 0.0000000000\nclient_4 Layer 79 weight diff: 0.0000000000\nclient_4 Layer 80 weight diff: 0.0000000000\nclient_4 Layer 81 weight diff: 0.0000000000\nclient_4 Layer 82 weight diff: 0.0000000000\nclient_4 Layer 83 weight diff: 0.0000000000\nclient_4 Layer 84 weight diff: 0.0000000000\nclient_4 Layer 85 weight diff: 23.2305068970\nclient_4 Layer 86 weight diff: 1766.0607910156\nclient_4 Layer 87 weight diff: 2.6243312359\nclient_4 Layer 88 weight diff: 2.5976800919\nclient_4 Layer 89 weight diff: 76.9088821411\nclient_4 Layer 90 weight diff: 62.5056648254\nclient_4 Layer 91 weight diff: 21.5863132477\nclient_4 Layer 92 weight diff: 1744.6933593750\nclient_4 Layer 93 weight diff: 2.4240899086\nclient_4 Layer 94 weight diff: 2.3798108101\nclient_4 Layer 95 weight diff: 30.9549980164\nclient_4 Layer 96 weight diff: 77.6703491211\nclient_4 Layer 97 weight diff: 22.2166290283\nclient_4 Layer 98 weight diff: 1786.7875976562\nclient_4 Layer 99 weight diff: 2.4735748768\nclient_4 Layer 100 weight diff: 2.3618886471\nclient_4 Layer 101 weight diff: 86.9124755859\nclient_4 Layer 102 weight diff: 71.6494598389\nclient_4 Layer 103 weight diff: 21.9266719818\nclient_4 Layer 104 weight diff: 1772.8868408203\nclient_4 Layer 105 weight diff: 2.5345876217\nclient_4 Layer 106 weight diff: 2.5870332718\nclient_4 Layer 107 weight diff: 13.4114274979\nclient_4 Layer 108 weight diff: 13.0828666687\nclient_4 Layer 109 weight diff: 22.6039905548\nclient_4 Layer 110 weight diff: 1750.2019042969\nclient_4 Layer 111 weight diff: 2.2913410664\nclient_4 Layer 112 weight diff: 2.3788251877\nclient_4 Layer 113 weight diff: 7.8935575485\nclient_4 Layer 114 weight diff: 15.7429695129\nclient_4 Layer 115 weight diff: 22.2450656891\nclient_4 Layer 116 weight diff: 1769.8610839844\nclient_4 Layer 117 weight diff: 2.4749064445\nclient_4 Layer 118 weight diff: 2.4616026878\nclient_4 Layer 119 weight diff: 50.8458099365\nclient_4 Layer 120 weight diff: 89.7046661377\nclient_4 Layer 121 weight diff: 21.5751266479\nclient_4 Layer 122 weight diff: 1742.2827148438\nclient_4 Layer 123 weight diff: 2.3604941368\nclient_4 Layer 124 weight diff: 2.3604035378\nclient_4 Layer 125 weight diff: 19.6222572327\nclient_4 Layer 126 weight diff: 15.7590894699\nclient_4 Layer 127 weight diff: 21.3315162659\nclient_4 Layer 128 weight diff: 1725.0765380859\nclient_4 Layer 129 weight diff: 2.4410386086\nclient_4 Layer 130 weight diff: 2.3309402466\nclient_4 Layer 131 weight diff: 12.7397766113\nclient_4 Layer 132 weight diff: 9.6215476990\nclient_4 Layer 133 weight diff: 21.4264945984\nclient_4 Layer 134 weight diff: 1735.0745849609\nclient_4 Layer 135 weight diff: 2.3852562904\nclient_4 Layer 136 weight diff: 2.4693708420\nclient_4 Layer 137 weight diff: 96.7276916504\nclient_4 Layer 138 weight diff: 113.4879760742\nclient_4 Layer 139 weight diff: 20.7548179626\nclient_4 Layer 140 weight diff: 1712.4781494141\nclient_4 Layer 141 weight diff: 2.3156704903\nclient_4 Layer 142 weight diff: 2.3494160175\nclient_4 Layer 143 weight diff: 19.0378398895\nclient_4 Layer 144 weight diff: 21.2693614960\nclient_4 Layer 145 weight diff: 20.6021347046\nclient_4 Layer 146 weight diff: 1693.1463623047\nclient_4 Layer 147 weight diff: 2.3161182404\nclient_4 Layer 148 weight diff: 2.4219112396\nclient_4 Layer 149 weight diff: 18.7947502136\nclient_4 Layer 150 weight diff: 11.8044958115\nclient_4 Layer 151 weight diff: 21.0018653870\nclient_4 Layer 152 weight diff: 1705.6018066406\nclient_4 Layer 153 weight diff: 2.3173165321\nclient_4 Layer 154 weight diff: 2.4283967018\nclient_4 Layer 155 weight diff: 68.6077728271\nclient_4 Layer 156 weight diff: 76.9946365356\nclient_4 Layer 157 weight diff: 21.1186199188\nclient_4 Layer 158 weight diff: 1679.3942871094\nclient_4 Layer 159 weight diff: 2.3158028126\nclient_4 Layer 160 weight diff: 2.2765860558\nclient_4 Layer 161 weight diff: 14.2914228439\nclient_4 Layer 162 weight diff: 13.7395057678\nclient_4 Layer 163 weight diff: 20.4313201904\nclient_4 Layer 164 weight diff: 1681.1586914062\nclient_4 Layer 165 weight diff: 2.2669408321\nclient_4 Layer 166 weight diff: 2.3235747814\nclient_4 Layer 167 weight diff: 11.5252904892\nclient_4 Layer 168 weight diff: 10.5642271042\nclient_4 Layer 169 weight diff: 21.1424179077\nclient_4 Layer 170 weight diff: 1699.1778564453\nclient_4 Layer 171 weight diff: 2.3571174145\nclient_4 Layer 172 weight diff: 2.4378538132\nclient_4 Layer 173 weight diff: 75.3160095215\nclient_4 Layer 174 weight diff: 83.6404418945\nclient_4 Layer 175 weight diff: 20.6950683594\nclient_4 Layer 176 weight diff: 1669.6665039062\nclient_4 Layer 177 weight diff: 2.4908857346\nclient_4 Layer 178 weight diff: 2.4679958820\nclient_4 Layer 179 weight diff: 13.4769515991\nclient_4 Layer 180 weight diff: 14.8737592697\nclient_4 Layer 181 weight diff: 20.7917137146\nclient_4 Layer 182 weight diff: 1671.2861328125\nclient_4 Layer 183 weight diff: 2.2307987213\nclient_4 Layer 184 weight diff: 2.3522071838\nclient_4 Layer 185 weight diff: 7.6516771317\nclient_4 Layer 186 weight diff: 5.1779856682\nclient_4 Layer 187 weight diff: 20.9327239990\nclient_4 Layer 188 weight diff: 1667.7189941406\nclient_4 Layer 189 weight diff: 2.1836056709\nclient_4 Layer 190 weight diff: 2.2475278378\nclient_4 Layer 191 weight diff: 104.2745666504\nclient_4 Layer 192 weight diff: 134.3808441162\nclient_4 Layer 193 weight diff: 19.5091857910\nclient_4 Layer 194 weight diff: 1655.4134521484\nclient_4 Layer 195 weight diff: 2.2171924114\nclient_4 Layer 196 weight diff: 2.2223854065\nclient_4 Layer 197 weight diff: 18.0436515808\nclient_4 Layer 198 weight diff: 14.5796766281\nclient_4 Layer 199 weight diff: 20.3330421448\nclient_4 Layer 200 weight diff: 1673.1552734375\nclient_4 Layer 201 weight diff: 2.2911682129\nclient_4 Layer 202 weight diff: 2.3403649330\nclient_4 Layer 203 weight diff: 8.4572029114\nclient_4 Layer 204 weight diff: 3.4755578041\nclient_4 Layer 205 weight diff: 20.5623512268\nclient_4 Layer 206 weight diff: 1656.8557128906\nclient_4 Layer 207 weight diff: 2.3116111755\nclient_4 Layer 208 weight diff: 2.3272807598\nclient_4 Layer 209 weight diff: 226.4017028809\nclient_4 Layer 210 weight diff: 493.1030273438\nclient_4 Layer 211 weight diff: 20.6321563721\nclient_4 Layer 212 weight diff: 2326.6201171875\nclient_4 Layer 213 weight diff: 3.3573169708\nclient_4 Layer 214 weight diff: 3.3135404587\nclient_4 Layer 215 weight diff: 39.2690048218\nclient_4 Layer 216 weight diff: 22.5307998657\nclient_4 Layer 217 weight diff: 2380.6508789062\nclient_4 Layer 218 weight diff: 3.3434205055\nclient_4 Layer 219 weight diff: 3.3135404587\nclient_4 Layer 220 weight diff: 1295.9428710938\nclient_4 Layer 221 weight diff: 37916.9882812500\nclient_4 Layer 222 weight diff: 29.9052124023\nclient_4 Layer 223 weight diff: 4985.6435546875\nclient_4 Layer 224 weight diff: 4.8881812096\nclient_4 Layer 225 weight diff: 4.8608760834\nclient_4 Layer 226 weight diff: 248.3694763184\nclient_4 Layer 227 weight diff: 587.2336425781\nclient_4 Layer 228 weight diff: 43.6981391907\nclient_4 Layer 229 weight diff: 9672.6005859375\nclient_4 Layer 230 weight diff: 7.2816467285\nclient_4 Layer 231 weight diff: 7.4538030624\nclient_4 Layer 232 weight diff: 366.7984008789\nclient_4 Layer 233 weight diff: 480.4916992188\nclient_4 Layer 234 weight diff: 0.0000000000\nclient_4 Layer 235 weight diff: 0.0000000000\nclient_4 Layer 236 weight diff: 0.0000000000\nclient_4 Layer 237 weight diff: 0.0000000000\nclient_4 training accuracy history: [0.7867646813392639, 0.9096638560295105, 0.9558823704719543, 0.9758403301239014, 0.973739504814148]\nclient_4 total local-global weight diff: 99293.65408802\n\n📶 Training on client_5\nTraining client_5 for 5 epochs...\nSum of weights before training: 138648.625\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 916ms/step - accuracy: 0.7186 - loss: 0.8422 - precision_21: 0.7549 - recall_21: 0.6608\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 635ms/step - accuracy: 0.8921 - loss: 0.2990 - precision_21: 0.9037 - recall_21: 0.8802\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 641ms/step - accuracy: 0.9626 - loss: 0.1383 - precision_21: 0.9658 - recall_21: 0.9573\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 653ms/step - accuracy: 0.9713 - loss: 0.0840 - precision_21: 0.9743 - recall_21: 0.9666\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 632ms/step - accuracy: 0.9695 - loss: 0.0912 - precision_21: 0.9695 - recall_21: 0.9681\nSum of weights after training: 150002.109\nclient_5 Layer 0 weight diff: 0.0000000000\nclient_5 Layer 1 weight diff: 0.0000000000\nclient_5 Layer 2 weight diff: 0.0000000000\nclient_5 Layer 3 weight diff: 0.0000000000\nclient_5 Layer 4 weight diff: 0.0000000000\nclient_5 Layer 5 weight diff: 0.0000000000\nclient_5 Layer 6 weight diff: 0.0000000000\nclient_5 Layer 7 weight diff: 0.0000000000\nclient_5 Layer 8 weight diff: 0.0000000000\nclient_5 Layer 9 weight diff: 0.0000000000\nclient_5 Layer 10 weight diff: 0.0000000000\nclient_5 Layer 11 weight diff: 0.0000000000\nclient_5 Layer 12 weight diff: 0.0000000000\nclient_5 Layer 13 weight diff: 0.0000000000\nclient_5 Layer 14 weight diff: 0.0000000000\nclient_5 Layer 15 weight diff: 0.0000000000\nclient_5 Layer 16 weight diff: 0.0000000000\nclient_5 Layer 17 weight diff: 0.0000000000\nclient_5 Layer 18 weight diff: 0.0000000000\nclient_5 Layer 19 weight diff: 0.0000000000\nclient_5 Layer 20 weight diff: 0.0000000000\nclient_5 Layer 21 weight diff: 0.0000000000\nclient_5 Layer 22 weight diff: 0.0000000000\nclient_5 Layer 23 weight diff: 0.0000000000\nclient_5 Layer 24 weight diff: 0.0000000000\nclient_5 Layer 25 weight diff: 0.0000000000\nclient_5 Layer 26 weight diff: 0.0000000000\nclient_5 Layer 27 weight diff: 0.0000000000\nclient_5 Layer 28 weight diff: 0.0000000000\nclient_5 Layer 29 weight diff: 0.0000000000\nclient_5 Layer 30 weight diff: 0.0000000000\nclient_5 Layer 31 weight diff: 0.0000000000\nclient_5 Layer 32 weight diff: 0.0000000000\nclient_5 Layer 33 weight diff: 0.0000000000\nclient_5 Layer 34 weight diff: 0.0000000000\nclient_5 Layer 35 weight diff: 0.0000000000\nclient_5 Layer 36 weight diff: 0.0000000000\nclient_5 Layer 37 weight diff: 0.0000000000\nclient_5 Layer 38 weight diff: 0.0000000000\nclient_5 Layer 39 weight diff: 0.0000000000\nclient_5 Layer 40 weight diff: 0.0000000000\nclient_5 Layer 41 weight diff: 0.0000000000\nclient_5 Layer 42 weight diff: 0.0000000000\nclient_5 Layer 43 weight diff: 0.0000000000\nclient_5 Layer 44 weight diff: 0.0000000000\nclient_5 Layer 45 weight diff: 0.0000000000\nclient_5 Layer 46 weight diff: 0.0000000000\nclient_5 Layer 47 weight diff: 0.0000000000\nclient_5 Layer 48 weight diff: 0.0000000000\nclient_5 Layer 49 weight diff: 0.0000000000\nclient_5 Layer 50 weight diff: 0.0000000000\nclient_5 Layer 51 weight diff: 0.0000000000\nclient_5 Layer 52 weight diff: 0.0000000000\nclient_5 Layer 53 weight diff: 0.0000000000\nclient_5 Layer 54 weight diff: 0.0000000000\nclient_5 Layer 55 weight diff: 0.0000000000\nclient_5 Layer 56 weight diff: 0.0000000000\nclient_5 Layer 57 weight diff: 0.0000000000\nclient_5 Layer 58 weight diff: 0.0000000000\nclient_5 Layer 59 weight diff: 0.0000000000\nclient_5 Layer 60 weight diff: 0.0000000000\nclient_5 Layer 61 weight diff: 0.0000000000\nclient_5 Layer 62 weight diff: 0.0000000000\nclient_5 Layer 63 weight diff: 0.0000000000\nclient_5 Layer 64 weight diff: 0.0000000000\nclient_5 Layer 65 weight diff: 0.0000000000\nclient_5 Layer 66 weight diff: 0.0000000000\nclient_5 Layer 67 weight diff: 0.0000000000\nclient_5 Layer 68 weight diff: 0.0000000000\nclient_5 Layer 69 weight diff: 0.0000000000\nclient_5 Layer 70 weight diff: 0.0000000000\nclient_5 Layer 71 weight diff: 0.0000000000\nclient_5 Layer 72 weight diff: 0.0000000000\nclient_5 Layer 73 weight diff: 0.0000000000\nclient_5 Layer 74 weight diff: 0.0000000000\nclient_5 Layer 75 weight diff: 0.0000000000\nclient_5 Layer 76 weight diff: 0.0000000000\nclient_5 Layer 77 weight diff: 0.0000000000\nclient_5 Layer 78 weight diff: 0.0000000000\nclient_5 Layer 79 weight diff: 0.0000000000\nclient_5 Layer 80 weight diff: 0.0000000000\nclient_5 Layer 81 weight diff: 0.0000000000\nclient_5 Layer 82 weight diff: 0.0000000000\nclient_5 Layer 83 weight diff: 0.0000000000\nclient_5 Layer 84 weight diff: 0.0000000000\nclient_5 Layer 85 weight diff: 24.9730186462\nclient_5 Layer 86 weight diff: 1855.1024169922\nclient_5 Layer 87 weight diff: 2.7397980690\nclient_5 Layer 88 weight diff: 2.7830915451\nclient_5 Layer 89 weight diff: 76.9463424683\nclient_5 Layer 90 weight diff: 62.5501747131\nclient_5 Layer 91 weight diff: 23.1521263123\nclient_5 Layer 92 weight diff: 1821.8460693359\nclient_5 Layer 93 weight diff: 2.6529893875\nclient_5 Layer 94 weight diff: 2.4649958611\nclient_5 Layer 95 weight diff: 30.9329719543\nclient_5 Layer 96 weight diff: 60.9768218994\nclient_5 Layer 97 weight diff: 22.6900062561\nclient_5 Layer 98 weight diff: 1831.7763671875\nclient_5 Layer 99 weight diff: 2.5234508514\nclient_5 Layer 100 weight diff: 2.6142606735\nclient_5 Layer 101 weight diff: 87.6329956055\nclient_5 Layer 102 weight diff: 77.2929687500\nclient_5 Layer 103 weight diff: 22.2805633545\nclient_5 Layer 104 weight diff: 1806.8616943359\nclient_5 Layer 105 weight diff: 2.5177237988\nclient_5 Layer 106 weight diff: 2.5162267685\nclient_5 Layer 107 weight diff: 16.7101707458\nclient_5 Layer 108 weight diff: 15.8121919632\nclient_5 Layer 109 weight diff: 22.8887634277\nclient_5 Layer 110 weight diff: 1792.3095703125\nclient_5 Layer 111 weight diff: 2.4180054665\nclient_5 Layer 112 weight diff: 2.3738350868\nclient_5 Layer 113 weight diff: 9.1997489929\nclient_5 Layer 114 weight diff: 46.3575439453\nclient_5 Layer 115 weight diff: 22.7196502686\nclient_5 Layer 116 weight diff: 1822.7222900391\nclient_5 Layer 117 weight diff: 2.5383729935\nclient_5 Layer 118 weight diff: 2.5936338902\nclient_5 Layer 119 weight diff: 49.2615852356\nclient_5 Layer 120 weight diff: 93.3238830566\nclient_5 Layer 121 weight diff: 22.3930034637\nclient_5 Layer 122 weight diff: 1792.5927734375\nclient_5 Layer 123 weight diff: 2.4704742432\nclient_5 Layer 124 weight diff: 2.5916318893\nclient_5 Layer 125 weight diff: 18.6737957001\nclient_5 Layer 126 weight diff: 15.5694313049\nclient_5 Layer 127 weight diff: 21.7288227081\nclient_5 Layer 128 weight diff: 1770.3852539062\nclient_5 Layer 129 weight diff: 2.4487271309\nclient_5 Layer 130 weight diff: 2.3144388199\nclient_5 Layer 131 weight diff: 12.6635828018\nclient_5 Layer 132 weight diff: 10.8502483368\nclient_5 Layer 133 weight diff: 22.0095558167\nclient_5 Layer 134 weight diff: 1776.6105957031\nclient_5 Layer 135 weight diff: 2.3962600231\nclient_5 Layer 136 weight diff: 2.4420905113\nclient_5 Layer 137 weight diff: 93.6403732300\nclient_5 Layer 138 weight diff: 109.4119186401\nclient_5 Layer 139 weight diff: 21.8093395233\nclient_5 Layer 140 weight diff: 1757.4870605469\nclient_5 Layer 141 weight diff: 2.4512200356\nclient_5 Layer 142 weight diff: 2.4271423817\nclient_5 Layer 143 weight diff: 31.4838066101\nclient_5 Layer 144 weight diff: 28.1583538055\nclient_5 Layer 145 weight diff: 21.9892826080\nclient_5 Layer 146 weight diff: 1744.2111816406\nclient_5 Layer 147 weight diff: 2.3766613007\nclient_5 Layer 148 weight diff: 2.3626899719\nclient_5 Layer 149 weight diff: 17.1855754852\nclient_5 Layer 150 weight diff: 14.9646368027\nclient_5 Layer 151 weight diff: 21.3969039917\nclient_5 Layer 152 weight diff: 1747.1833496094\nclient_5 Layer 153 weight diff: 2.4435362816\nclient_5 Layer 154 weight diff: 2.3860929012\nclient_5 Layer 155 weight diff: 65.2898788452\nclient_5 Layer 156 weight diff: 68.5195159912\nclient_5 Layer 157 weight diff: 22.0493774414\nclient_5 Layer 158 weight diff: 1721.5783691406\nclient_5 Layer 159 weight diff: 2.4217200279\nclient_5 Layer 160 weight diff: 2.4126482010\nclient_5 Layer 161 weight diff: 17.2399635315\nclient_5 Layer 162 weight diff: 13.0885200500\nclient_5 Layer 163 weight diff: 21.0980834961\nclient_5 Layer 164 weight diff: 1726.8288574219\nclient_5 Layer 165 weight diff: 2.3160891533\nclient_5 Layer 166 weight diff: 2.3766007423\nclient_5 Layer 167 weight diff: 12.4173088074\nclient_5 Layer 168 weight diff: 11.0289525986\nclient_5 Layer 169 weight diff: 21.8199272156\nclient_5 Layer 170 weight diff: 1736.0142822266\nclient_5 Layer 171 weight diff: 2.4636685848\nclient_5 Layer 172 weight diff: 2.5601308346\nclient_5 Layer 173 weight diff: 66.8011550903\nclient_5 Layer 174 weight diff: 90.3923492432\nclient_5 Layer 175 weight diff: 21.5689926147\nclient_5 Layer 176 weight diff: 1713.9191894531\nclient_5 Layer 177 weight diff: 2.3368153572\nclient_5 Layer 178 weight diff: 2.3648643494\nclient_5 Layer 179 weight diff: 15.4628114700\nclient_5 Layer 180 weight diff: 13.2203750610\nclient_5 Layer 181 weight diff: 20.1882972717\nclient_5 Layer 182 weight diff: 1714.8070068359\nclient_5 Layer 183 weight diff: 2.3581016064\nclient_5 Layer 184 weight diff: 2.3994715214\nclient_5 Layer 185 weight diff: 8.3976192474\nclient_5 Layer 186 weight diff: 5.3201746941\nclient_5 Layer 187 weight diff: 21.5534725189\nclient_5 Layer 188 weight diff: 1710.7780761719\nclient_5 Layer 189 weight diff: 2.2555274963\nclient_5 Layer 190 weight diff: 2.2750592232\nclient_5 Layer 191 weight diff: 93.5827178955\nclient_5 Layer 192 weight diff: 134.8468780518\nclient_5 Layer 193 weight diff: 20.4754981995\nclient_5 Layer 194 weight diff: 1692.7574462891\nclient_5 Layer 195 weight diff: 2.3896102905\nclient_5 Layer 196 weight diff: 2.4356455803\nclient_5 Layer 197 weight diff: 16.2138843536\nclient_5 Layer 198 weight diff: 15.1546783447\nclient_5 Layer 199 weight diff: 20.6939697266\nclient_5 Layer 200 weight diff: 1689.5820312500\nclient_5 Layer 201 weight diff: 2.3211135864\nclient_5 Layer 202 weight diff: 2.2567286491\nclient_5 Layer 203 weight diff: 8.5353641510\nclient_5 Layer 204 weight diff: 5.7869396210\nclient_5 Layer 205 weight diff: 20.7868938446\nclient_5 Layer 206 weight diff: 1662.4429931641\nclient_5 Layer 207 weight diff: 2.1788995266\nclient_5 Layer 208 weight diff: 2.1636147499\nclient_5 Layer 209 weight diff: 187.2970733643\nclient_5 Layer 210 weight diff: 404.1868286133\nclient_5 Layer 211 weight diff: 20.2992439270\nclient_5 Layer 212 weight diff: 2351.1113281250\nclient_5 Layer 213 weight diff: 3.3754587173\nclient_5 Layer 214 weight diff: 3.1402597427\nclient_5 Layer 215 weight diff: 33.2962722778\nclient_5 Layer 216 weight diff: 20.7223262787\nclient_5 Layer 217 weight diff: 2384.2622070312\nclient_5 Layer 218 weight diff: 3.2173538208\nclient_5 Layer 219 weight diff: 3.1402597427\nclient_5 Layer 220 weight diff: 1327.7424316406\nclient_5 Layer 221 weight diff: 29007.1230468750\nclient_5 Layer 222 weight diff: 30.2262802124\nclient_5 Layer 223 weight diff: 5072.8173828125\nclient_5 Layer 224 weight diff: 5.1261816025\nclient_5 Layer 225 weight diff: 5.0861492157\nclient_5 Layer 226 weight diff: 254.5045166016\nclient_5 Layer 227 weight diff: 453.9754028320\nclient_5 Layer 228 weight diff: 45.3346328735\nclient_5 Layer 229 weight diff: 9738.9951171875\nclient_5 Layer 230 weight diff: 6.9657058716\nclient_5 Layer 231 weight diff: 6.8073348999\nclient_5 Layer 232 weight diff: 240.4652252197\nclient_5 Layer 233 weight diff: 238.0407714844\nclient_5 Layer 234 weight diff: 0.0000000000\nclient_5 Layer 235 weight diff: 0.0000000000\nclient_5 Layer 236 weight diff: 0.0000000000\nclient_5 Layer 237 weight diff: 0.0000000000\nclient_5 training accuracy history: [0.8025209903717041, 0.9086134433746338, 0.9600840210914612, 0.973739504814148, 0.9695377945899963]\nclient_5 total local-global weight diff: 90938.35308313\n\n📶 Training on client_6\nTraining client_6 for 5 epochs...\nSum of weights before training: 138648.625\nEpoch 1/5\n\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 714ms/step - accuracy: 0.7010 - loss: 0.8279 - precision_22: 0.7470 - recall_22: 0.6568","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1749041425.744092      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749041425.890481      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749041426.655335      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749041426.794217      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749041427.177947      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1749041427.329534      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.7068 - loss: 0.8109 - precision_22: 0.7527 - recall_22: 0.6632\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 618ms/step - accuracy: 0.9229 - loss: 0.2090 - precision_22: 0.9398 - recall_22: 0.9107\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 652ms/step - accuracy: 0.9646 - loss: 0.1102 - precision_22: 0.9703 - recall_22: 0.9564\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 666ms/step - accuracy: 0.9727 - loss: 0.1071 - precision_22: 0.9767 - recall_22: 0.9713\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 623ms/step - accuracy: 0.9870 - loss: 0.0386 - precision_22: 0.9898 - recall_22: 0.9867\nSum of weights after training: 175213.875\nclient_6 Layer 0 weight diff: 0.0000000000\nclient_6 Layer 1 weight diff: 0.0000000000\nclient_6 Layer 2 weight diff: 0.0000000000\nclient_6 Layer 3 weight diff: 0.0000000000\nclient_6 Layer 4 weight diff: 0.0000000000\nclient_6 Layer 5 weight diff: 0.0000000000\nclient_6 Layer 6 weight diff: 0.0000000000\nclient_6 Layer 7 weight diff: 0.0000000000\nclient_6 Layer 8 weight diff: 0.0000000000\nclient_6 Layer 9 weight diff: 0.0000000000\nclient_6 Layer 10 weight diff: 0.0000000000\nclient_6 Layer 11 weight diff: 0.0000000000\nclient_6 Layer 12 weight diff: 0.0000000000\nclient_6 Layer 13 weight diff: 0.0000000000\nclient_6 Layer 14 weight diff: 0.0000000000\nclient_6 Layer 15 weight diff: 0.0000000000\nclient_6 Layer 16 weight diff: 0.0000000000\nclient_6 Layer 17 weight diff: 0.0000000000\nclient_6 Layer 18 weight diff: 0.0000000000\nclient_6 Layer 19 weight diff: 0.0000000000\nclient_6 Layer 20 weight diff: 0.0000000000\nclient_6 Layer 21 weight diff: 0.0000000000\nclient_6 Layer 22 weight diff: 0.0000000000\nclient_6 Layer 23 weight diff: 0.0000000000\nclient_6 Layer 24 weight diff: 0.0000000000\nclient_6 Layer 25 weight diff: 0.0000000000\nclient_6 Layer 26 weight diff: 0.0000000000\nclient_6 Layer 27 weight diff: 0.0000000000\nclient_6 Layer 28 weight diff: 0.0000000000\nclient_6 Layer 29 weight diff: 0.0000000000\nclient_6 Layer 30 weight diff: 0.0000000000\nclient_6 Layer 31 weight diff: 0.0000000000\nclient_6 Layer 32 weight diff: 0.0000000000\nclient_6 Layer 33 weight diff: 0.0000000000\nclient_6 Layer 34 weight diff: 0.0000000000\nclient_6 Layer 35 weight diff: 0.0000000000\nclient_6 Layer 36 weight diff: 0.0000000000\nclient_6 Layer 37 weight diff: 0.0000000000\nclient_6 Layer 38 weight diff: 0.0000000000\nclient_6 Layer 39 weight diff: 0.0000000000\nclient_6 Layer 40 weight diff: 0.0000000000\nclient_6 Layer 41 weight diff: 0.0000000000\nclient_6 Layer 42 weight diff: 0.0000000000\nclient_6 Layer 43 weight diff: 0.0000000000\nclient_6 Layer 44 weight diff: 0.0000000000\nclient_6 Layer 45 weight diff: 0.0000000000\nclient_6 Layer 46 weight diff: 0.0000000000\nclient_6 Layer 47 weight diff: 0.0000000000\nclient_6 Layer 48 weight diff: 0.0000000000\nclient_6 Layer 49 weight diff: 0.0000000000\nclient_6 Layer 50 weight diff: 0.0000000000\nclient_6 Layer 51 weight diff: 0.0000000000\nclient_6 Layer 52 weight diff: 0.0000000000\nclient_6 Layer 53 weight diff: 0.0000000000\nclient_6 Layer 54 weight diff: 0.0000000000\nclient_6 Layer 55 weight diff: 0.0000000000\nclient_6 Layer 56 weight diff: 0.0000000000\nclient_6 Layer 57 weight diff: 0.0000000000\nclient_6 Layer 58 weight diff: 0.0000000000\nclient_6 Layer 59 weight diff: 0.0000000000\nclient_6 Layer 60 weight diff: 0.0000000000\nclient_6 Layer 61 weight diff: 0.0000000000\nclient_6 Layer 62 weight diff: 0.0000000000\nclient_6 Layer 63 weight diff: 0.0000000000\nclient_6 Layer 64 weight diff: 0.0000000000\nclient_6 Layer 65 weight diff: 0.0000000000\nclient_6 Layer 66 weight diff: 0.0000000000\nclient_6 Layer 67 weight diff: 0.0000000000\nclient_6 Layer 68 weight diff: 0.0000000000\nclient_6 Layer 69 weight diff: 0.0000000000\nclient_6 Layer 70 weight diff: 0.0000000000\nclient_6 Layer 71 weight diff: 0.0000000000\nclient_6 Layer 72 weight diff: 0.0000000000\nclient_6 Layer 73 weight diff: 0.0000000000\nclient_6 Layer 74 weight diff: 0.0000000000\nclient_6 Layer 75 weight diff: 0.0000000000\nclient_6 Layer 76 weight diff: 0.0000000000\nclient_6 Layer 77 weight diff: 0.0000000000\nclient_6 Layer 78 weight diff: 0.0000000000\nclient_6 Layer 79 weight diff: 0.0000000000\nclient_6 Layer 80 weight diff: 0.0000000000\nclient_6 Layer 81 weight diff: 0.0000000000\nclient_6 Layer 82 weight diff: 0.0000000000\nclient_6 Layer 83 weight diff: 0.0000000000\nclient_6 Layer 84 weight diff: 0.0000000000\nclient_6 Layer 85 weight diff: 23.3033676147\nclient_6 Layer 86 weight diff: 1770.4516601562\nclient_6 Layer 87 weight diff: 2.4741230011\nclient_6 Layer 88 weight diff: 2.4713435173\nclient_6 Layer 89 weight diff: 76.8463287354\nclient_6 Layer 90 weight diff: 65.0849533081\nclient_6 Layer 91 weight diff: 21.9637374878\nclient_6 Layer 92 weight diff: 1779.0125732422\nclient_6 Layer 93 weight diff: 2.4628705978\nclient_6 Layer 94 weight diff: 2.4337892532\nclient_6 Layer 95 weight diff: 30.6508903503\nclient_6 Layer 96 weight diff: 74.6542892456\nclient_6 Layer 97 weight diff: 22.0843620300\nclient_6 Layer 98 weight diff: 1801.9140625000\nclient_6 Layer 99 weight diff: 2.4059031010\nclient_6 Layer 100 weight diff: 2.5014574528\nclient_6 Layer 101 weight diff: 84.3457641602\nclient_6 Layer 102 weight diff: 74.5834808350\nclient_6 Layer 103 weight diff: 21.8649044037\nclient_6 Layer 104 weight diff: 1786.4432373047\nclient_6 Layer 105 weight diff: 2.4330902100\nclient_6 Layer 106 weight diff: 2.4403419495\nclient_6 Layer 107 weight diff: 13.3125314713\nclient_6 Layer 108 weight diff: 14.8134841919\nclient_6 Layer 109 weight diff: 21.6245956421\nclient_6 Layer 110 weight diff: 1774.1563720703\nclient_6 Layer 111 weight diff: 2.3341932297\nclient_6 Layer 112 weight diff: 2.4868907928\nclient_6 Layer 113 weight diff: 9.0350027084\nclient_6 Layer 114 weight diff: 15.6484909058\nclient_6 Layer 115 weight diff: 22.2275161743\nclient_6 Layer 116 weight diff: 1788.3908691406\nclient_6 Layer 117 weight diff: 2.4409639835\nclient_6 Layer 118 weight diff: 2.3203253746\nclient_6 Layer 119 weight diff: 53.2709274292\nclient_6 Layer 120 weight diff: 89.4676895142\nclient_6 Layer 121 weight diff: 21.8808002472\nclient_6 Layer 122 weight diff: 1765.7382812500\nclient_6 Layer 123 weight diff: 2.4349672794\nclient_6 Layer 124 weight diff: 2.4597442150\nclient_6 Layer 125 weight diff: 19.5100841522\nclient_6 Layer 126 weight diff: 17.1589126587\nclient_6 Layer 127 weight diff: 21.5660457611\nclient_6 Layer 128 weight diff: 1746.9294433594\nclient_6 Layer 129 weight diff: 2.4673829079\nclient_6 Layer 130 weight diff: 2.4478077888\nclient_6 Layer 131 weight diff: 12.0784053802\nclient_6 Layer 132 weight diff: 10.7739410400\nclient_6 Layer 133 weight diff: 21.3658676147\nclient_6 Layer 134 weight diff: 1736.1864013672\nclient_6 Layer 135 weight diff: 2.3065309525\nclient_6 Layer 136 weight diff: 2.3618071079\nclient_6 Layer 137 weight diff: 96.3671722412\nclient_6 Layer 138 weight diff: 109.0846862793\nclient_6 Layer 139 weight diff: 21.2131614685\nclient_6 Layer 140 weight diff: 1711.5333251953\nclient_6 Layer 141 weight diff: 2.3723032475\nclient_6 Layer 142 weight diff: 2.3784008026\nclient_6 Layer 143 weight diff: 24.6703834534\nclient_6 Layer 144 weight diff: 22.1929683685\nclient_6 Layer 145 weight diff: 20.9309482574\nclient_6 Layer 146 weight diff: 1702.8703613281\nclient_6 Layer 147 weight diff: 2.3702149391\nclient_6 Layer 148 weight diff: 2.3757448196\nclient_6 Layer 149 weight diff: 19.2915992737\nclient_6 Layer 150 weight diff: 17.3324832916\nclient_6 Layer 151 weight diff: 21.8565177917\nclient_6 Layer 152 weight diff: 1724.5192871094\nclient_6 Layer 153 weight diff: 2.3284873962\nclient_6 Layer 154 weight diff: 2.4491236210\nclient_6 Layer 155 weight diff: 64.5865402222\nclient_6 Layer 156 weight diff: 73.5692901611\nclient_6 Layer 157 weight diff: 21.2090377808\nclient_6 Layer 158 weight diff: 1705.3850097656\nclient_6 Layer 159 weight diff: 2.2572479248\nclient_6 Layer 160 weight diff: 2.2787270546\nclient_6 Layer 161 weight diff: 14.2041893005\nclient_6 Layer 162 weight diff: 14.5550603867\nclient_6 Layer 163 weight diff: 20.5292778015\nclient_6 Layer 164 weight diff: 1699.5411376953\nclient_6 Layer 165 weight diff: 2.2101025581\nclient_6 Layer 166 weight diff: 2.3146400452\nclient_6 Layer 167 weight diff: 11.5124902725\nclient_6 Layer 168 weight diff: 9.8669595718\nclient_6 Layer 169 weight diff: 21.3215904236\nclient_6 Layer 170 weight diff: 1710.7722167969\nclient_6 Layer 171 weight diff: 2.3146896362\nclient_6 Layer 172 weight diff: 2.3394258022\nclient_6 Layer 173 weight diff: 66.2034912109\nclient_6 Layer 174 weight diff: 87.0019149780\nclient_6 Layer 175 weight diff: 20.5681648254\nclient_6 Layer 176 weight diff: 1700.7563476562\nclient_6 Layer 177 weight diff: 2.4382665157\nclient_6 Layer 178 weight diff: 2.5082638264\nclient_6 Layer 179 weight diff: 14.6947612762\nclient_6 Layer 180 weight diff: 13.8158893585\nclient_6 Layer 181 weight diff: 21.1553840637\nclient_6 Layer 182 weight diff: 1690.1264648438\nclient_6 Layer 183 weight diff: 2.3493199348\nclient_6 Layer 184 weight diff: 2.3611016273\nclient_6 Layer 185 weight diff: 9.5042972565\nclient_6 Layer 186 weight diff: 6.5090818405\nclient_6 Layer 187 weight diff: 21.6130180359\nclient_6 Layer 188 weight diff: 1700.2404785156\nclient_6 Layer 189 weight diff: 2.3358054161\nclient_6 Layer 190 weight diff: 2.2885088921\nclient_6 Layer 191 weight diff: 84.8920745850\nclient_6 Layer 192 weight diff: 132.7424468994\nclient_6 Layer 193 weight diff: 20.9879264832\nclient_6 Layer 194 weight diff: 1678.3515625000\nclient_6 Layer 195 weight diff: 2.3896560669\nclient_6 Layer 196 weight diff: 2.4051380157\nclient_6 Layer 197 weight diff: 18.2888278961\nclient_6 Layer 198 weight diff: 16.3452491760\nclient_6 Layer 199 weight diff: 21.1332206726\nclient_6 Layer 200 weight diff: 1680.0379638672\nclient_6 Layer 201 weight diff: 2.3306491375\nclient_6 Layer 202 weight diff: 2.3331103325\nclient_6 Layer 203 weight diff: 10.2753229141\nclient_6 Layer 204 weight diff: 6.3702759743\nclient_6 Layer 205 weight diff: 21.1641826630\nclient_6 Layer 206 weight diff: 1679.4179687500\nclient_6 Layer 207 weight diff: 2.2919473648\nclient_6 Layer 208 weight diff: 2.3029065132\nclient_6 Layer 209 weight diff: 169.5338439941\nclient_6 Layer 210 weight diff: 540.4005126953\nclient_6 Layer 211 weight diff: 20.9189586639\nclient_6 Layer 212 weight diff: 2364.8056640625\nclient_6 Layer 213 weight diff: 3.1621012688\nclient_6 Layer 214 weight diff: 3.1777181625\nclient_6 Layer 215 weight diff: 39.1792602539\nclient_6 Layer 216 weight diff: 28.7575321198\nclient_6 Layer 217 weight diff: 2381.0073242188\nclient_6 Layer 218 weight diff: 3.0570013523\nclient_6 Layer 219 weight diff: 3.1777181625\nclient_6 Layer 220 weight diff: 1290.5423583984\nclient_6 Layer 221 weight diff: 42283.4453125000\nclient_6 Layer 222 weight diff: 29.3257846832\nclient_6 Layer 223 weight diff: 5009.2841796875\nclient_6 Layer 224 weight diff: 4.9974431992\nclient_6 Layer 225 weight diff: 5.0326471329\nclient_6 Layer 226 weight diff: 183.7062988281\nclient_6 Layer 227 weight diff: 494.8258972168\nclient_6 Layer 228 weight diff: 44.1041870117\nclient_6 Layer 229 weight diff: 9542.1894531250\nclient_6 Layer 230 weight diff: 6.9993281364\nclient_6 Layer 231 weight diff: 7.0616865158\nclient_6 Layer 232 weight diff: 222.7514038086\nclient_6 Layer 233 weight diff: 272.2441406250\nclient_6 Layer 234 weight diff: 0.0000000000\nclient_6 Layer 235 weight diff: 0.0000000000\nclient_6 Layer 236 weight diff: 0.0000000000\nclient_6 Layer 237 weight diff: 0.0000000000\nclient_6 training accuracy history: [0.7905263304710388, 0.9294736981391907, 0.9684210419654846, 0.9715789556503296, 0.9842105507850647]\nclient_6 total local-global weight diff: 103443.14635396\n\n✅ Round 1 average client accuracy: 0.9743\n\n📈 Global model evaluation on test data: {'loss': 0.23792842030525208, 'compile_metrics': 0.9321128726005554}\n\n🔁 Federated Round 2\n\n📶 Training on client_1\nTraining client_1 for 5 epochs...\nSum of weights before training: 157863.375\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 951ms/step - accuracy: 0.8984 - loss: 0.3292 - precision_24: 0.9088 - recall_24: 0.8794\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 657ms/step - accuracy: 0.9590 - loss: 0.1277 - precision_24: 0.9631 - recall_24: 0.9490\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 0.9686 - loss: 0.0940 - precision_24: 0.9711 - recall_24: 0.9646\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 655ms/step - accuracy: 0.9838 - loss: 0.0524 - precision_24: 0.9856 - recall_24: 0.9826\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 658ms/step - accuracy: 0.9744 - loss: 0.0704 - precision_24: 0.9791 - recall_24: 0.9704\nSum of weights after training: 171837.625\nclient_1 Layer 0 weight diff: 0.0000000000\nclient_1 Layer 1 weight diff: 0.0000000000\nclient_1 Layer 2 weight diff: 0.0000000000\nclient_1 Layer 3 weight diff: 0.0000000000\nclient_1 Layer 4 weight diff: 0.0000000000\nclient_1 Layer 5 weight diff: 0.0000000000\nclient_1 Layer 6 weight diff: 0.0000000000\nclient_1 Layer 7 weight diff: 0.0000000000\nclient_1 Layer 8 weight diff: 0.0000000000\nclient_1 Layer 9 weight diff: 0.0000000000\nclient_1 Layer 10 weight diff: 0.0000000000\nclient_1 Layer 11 weight diff: 0.0000000000\nclient_1 Layer 12 weight diff: 0.0000000000\nclient_1 Layer 13 weight diff: 0.0000000000\nclient_1 Layer 14 weight diff: 0.0000000000\nclient_1 Layer 15 weight diff: 0.0000000000\nclient_1 Layer 16 weight diff: 0.0000000000\nclient_1 Layer 17 weight diff: 0.0000000000\nclient_1 Layer 18 weight diff: 0.0000000000\nclient_1 Layer 19 weight diff: 0.0000000000\nclient_1 Layer 20 weight diff: 0.0000000000\nclient_1 Layer 21 weight diff: 0.0000000000\nclient_1 Layer 22 weight diff: 0.0000000000\nclient_1 Layer 23 weight diff: 0.0000000000\nclient_1 Layer 24 weight diff: 0.0000000000\nclient_1 Layer 25 weight diff: 0.0000000000\nclient_1 Layer 26 weight diff: 0.0000000000\nclient_1 Layer 27 weight diff: 0.0000000000\nclient_1 Layer 28 weight diff: 0.0000000000\nclient_1 Layer 29 weight diff: 0.0000000000\nclient_1 Layer 30 weight diff: 0.0000000000\nclient_1 Layer 31 weight diff: 0.0000000000\nclient_1 Layer 32 weight diff: 0.0000000000\nclient_1 Layer 33 weight diff: 0.0000000000\nclient_1 Layer 34 weight diff: 0.0000000000\nclient_1 Layer 35 weight diff: 0.0000000000\nclient_1 Layer 36 weight diff: 0.0000000000\nclient_1 Layer 37 weight diff: 0.0000000000\nclient_1 Layer 38 weight diff: 0.0000000000\nclient_1 Layer 39 weight diff: 0.0000000000\nclient_1 Layer 40 weight diff: 0.0000000000\nclient_1 Layer 41 weight diff: 0.0000000000\nclient_1 Layer 42 weight diff: 0.0000000000\nclient_1 Layer 43 weight diff: 0.0000000000\nclient_1 Layer 44 weight diff: 0.0000000000\nclient_1 Layer 45 weight diff: 0.0000000000\nclient_1 Layer 46 weight diff: 0.0000000000\nclient_1 Layer 47 weight diff: 0.0000000000\nclient_1 Layer 48 weight diff: 0.0000000000\nclient_1 Layer 49 weight diff: 0.0000000000\nclient_1 Layer 50 weight diff: 0.0000000000\nclient_1 Layer 51 weight diff: 0.0000000000\nclient_1 Layer 52 weight diff: 0.0000000000\nclient_1 Layer 53 weight diff: 0.0000000000\nclient_1 Layer 54 weight diff: 0.0000000000\nclient_1 Layer 55 weight diff: 0.0000000000\nclient_1 Layer 56 weight diff: 0.0000000000\nclient_1 Layer 57 weight diff: 0.0000000000\nclient_1 Layer 58 weight diff: 0.0000000000\nclient_1 Layer 59 weight diff: 0.0000000000\nclient_1 Layer 60 weight diff: 0.0000000000\nclient_1 Layer 61 weight diff: 0.0000000000\nclient_1 Layer 62 weight diff: 0.0000000000\nclient_1 Layer 63 weight diff: 0.0000000000\nclient_1 Layer 64 weight diff: 0.0000000000\nclient_1 Layer 65 weight diff: 0.0000000000\nclient_1 Layer 66 weight diff: 0.0000000000\nclient_1 Layer 67 weight diff: 0.0000000000\nclient_1 Layer 68 weight diff: 0.0000000000\nclient_1 Layer 69 weight diff: 0.0000000000\nclient_1 Layer 70 weight diff: 0.0000000000\nclient_1 Layer 71 weight diff: 0.0000000000\nclient_1 Layer 72 weight diff: 0.0000000000\nclient_1 Layer 73 weight diff: 0.0000000000\nclient_1 Layer 74 weight diff: 0.0000000000\nclient_1 Layer 75 weight diff: 0.0000000000\nclient_1 Layer 76 weight diff: 0.0000000000\nclient_1 Layer 77 weight diff: 0.0000000000\nclient_1 Layer 78 weight diff: 0.0000000000\nclient_1 Layer 79 weight diff: 0.0000000000\nclient_1 Layer 80 weight diff: 0.0000000000\nclient_1 Layer 81 weight diff: 0.0000000000\nclient_1 Layer 82 weight diff: 0.0000000000\nclient_1 Layer 83 weight diff: 0.0000000000\nclient_1 Layer 84 weight diff: 0.0000000000\nclient_1 Layer 85 weight diff: 22.6984519958\nclient_1 Layer 86 weight diff: 1731.7231445312\nclient_1 Layer 87 weight diff: 2.3983466625\nclient_1 Layer 88 weight diff: 2.3997831345\nclient_1 Layer 89 weight diff: 25.0614261627\nclient_1 Layer 90 weight diff: 17.5205421448\nclient_1 Layer 91 weight diff: 21.4700298309\nclient_1 Layer 92 weight diff: 1750.1462402344\nclient_1 Layer 93 weight diff: 2.3386874199\nclient_1 Layer 94 weight diff: 2.3076176643\nclient_1 Layer 95 weight diff: 18.3530445099\nclient_1 Layer 96 weight diff: 47.4397239685\nclient_1 Layer 97 weight diff: 23.1654663086\nclient_1 Layer 98 weight diff: 1846.0358886719\nclient_1 Layer 99 weight diff: 2.5097734928\nclient_1 Layer 100 weight diff: 2.5338749886\nclient_1 Layer 101 weight diff: 42.7151260376\nclient_1 Layer 102 weight diff: 42.1691665649\nclient_1 Layer 103 weight diff: 22.3223972321\nclient_1 Layer 104 weight diff: 1819.7934570312\nclient_1 Layer 105 weight diff: 2.3762845993\nclient_1 Layer 106 weight diff: 2.3881235123\nclient_1 Layer 107 weight diff: 10.5808830261\nclient_1 Layer 108 weight diff: 9.9126472473\nclient_1 Layer 109 weight diff: 21.8154373169\nclient_1 Layer 110 weight diff: 1820.4709472656\nclient_1 Layer 111 weight diff: 2.4042735100\nclient_1 Layer 112 weight diff: 2.3806786537\nclient_1 Layer 113 weight diff: 9.0628461838\nclient_1 Layer 114 weight diff: 22.4653472900\nclient_1 Layer 115 weight diff: 22.5594654083\nclient_1 Layer 116 weight diff: 1843.9921875000\nclient_1 Layer 117 weight diff: 2.5010929108\nclient_1 Layer 118 weight diff: 2.4265310764\nclient_1 Layer 119 weight diff: 31.1819820404\nclient_1 Layer 120 weight diff: 47.6518402100\nclient_1 Layer 121 weight diff: 22.8196716309\nclient_1 Layer 122 weight diff: 1799.1362304688\nclient_1 Layer 123 weight diff: 2.4183878899\nclient_1 Layer 124 weight diff: 2.3609292507\nclient_1 Layer 125 weight diff: 13.6241664886\nclient_1 Layer 126 weight diff: 8.5629920959\nclient_1 Layer 127 weight diff: 21.9694309235\nclient_1 Layer 128 weight diff: 1794.8889160156\nclient_1 Layer 129 weight diff: 2.4272418022\nclient_1 Layer 130 weight diff: 2.3404102325\nclient_1 Layer 131 weight diff: 10.2448425293\nclient_1 Layer 132 weight diff: 6.7580909729\nclient_1 Layer 133 weight diff: 22.4404182434\nclient_1 Layer 134 weight diff: 1784.5805664062\nclient_1 Layer 135 weight diff: 2.4878053665\nclient_1 Layer 136 weight diff: 2.4894886017\nclient_1 Layer 137 weight diff: 52.7741699219\nclient_1 Layer 138 weight diff: 51.1454849243\nclient_1 Layer 139 weight diff: 22.0253067017\nclient_1 Layer 140 weight diff: 1737.2019042969\nclient_1 Layer 141 weight diff: 2.2989399433\nclient_1 Layer 142 weight diff: 2.3094048500\nclient_1 Layer 143 weight diff: 16.5759811401\nclient_1 Layer 144 weight diff: 12.4931974411\nclient_1 Layer 145 weight diff: 20.6892585754\nclient_1 Layer 146 weight diff: 1739.1152343750\nclient_1 Layer 147 weight diff: 2.3643991947\nclient_1 Layer 148 weight diff: 2.2815141678\nclient_1 Layer 149 weight diff: 19.5149269104\nclient_1 Layer 150 weight diff: 16.3711814880\nclient_1 Layer 151 weight diff: 22.1376800537\nclient_1 Layer 152 weight diff: 1787.5150146484\nclient_1 Layer 153 weight diff: 2.4063067436\nclient_1 Layer 154 weight diff: 2.5418148041\nclient_1 Layer 155 weight diff: 34.7788391113\nclient_1 Layer 156 weight diff: 42.1306381226\nclient_1 Layer 157 weight diff: 22.5158042908\nclient_1 Layer 158 weight diff: 1765.2524414062\nclient_1 Layer 159 weight diff: 2.3979415894\nclient_1 Layer 160 weight diff: 2.4024598598\nclient_1 Layer 161 weight diff: 14.2924871445\nclient_1 Layer 162 weight diff: 14.9588823318\nclient_1 Layer 163 weight diff: 21.2729873657\nclient_1 Layer 164 weight diff: 1739.5592041016\nclient_1 Layer 165 weight diff: 2.4031765461\nclient_1 Layer 166 weight diff: 2.2942919731\nclient_1 Layer 167 weight diff: 9.3247098923\nclient_1 Layer 168 weight diff: 10.3338489532\nclient_1 Layer 169 weight diff: 22.0478973389\nclient_1 Layer 170 weight diff: 1735.6738281250\nclient_1 Layer 171 weight diff: 2.3665790558\nclient_1 Layer 172 weight diff: 2.3309876919\nclient_1 Layer 173 weight diff: 41.2211532593\nclient_1 Layer 174 weight diff: 62.7834472656\nclient_1 Layer 175 weight diff: 21.1450824738\nclient_1 Layer 176 weight diff: 1706.0114746094\nclient_1 Layer 177 weight diff: 2.2428197861\nclient_1 Layer 178 weight diff: 2.2484889030\nclient_1 Layer 179 weight diff: 17.3331489563\nclient_1 Layer 180 weight diff: 40.8797836304\nclient_1 Layer 181 weight diff: 20.3214111328\nclient_1 Layer 182 weight diff: 1670.9461669922\nclient_1 Layer 183 weight diff: 2.4239177704\nclient_1 Layer 184 weight diff: 2.3093080521\nclient_1 Layer 185 weight diff: 13.8568916321\nclient_1 Layer 186 weight diff: 18.6909542084\nclient_1 Layer 187 weight diff: 21.6404647827\nclient_1 Layer 188 weight diff: 1718.7966308594\nclient_1 Layer 189 weight diff: 2.3364276886\nclient_1 Layer 190 weight diff: 2.3823466301\nclient_1 Layer 191 weight diff: 60.8091926575\nclient_1 Layer 192 weight diff: 99.4907989502\nclient_1 Layer 193 weight diff: 21.3505172729\nclient_1 Layer 194 weight diff: 1676.8128662109\nclient_1 Layer 195 weight diff: 2.2796401978\nclient_1 Layer 196 weight diff: 2.3023810387\nclient_1 Layer 197 weight diff: 22.5581550598\nclient_1 Layer 198 weight diff: 46.4315948486\nclient_1 Layer 199 weight diff: 19.9477729797\nclient_1 Layer 200 weight diff: 1638.8881835938\nclient_1 Layer 201 weight diff: 2.2701778412\nclient_1 Layer 202 weight diff: 2.2818689346\nclient_1 Layer 203 weight diff: 14.3627948761\nclient_1 Layer 204 weight diff: 20.3869209290\nclient_1 Layer 205 weight diff: 20.4813060760\nclient_1 Layer 206 weight diff: 1708.3332519531\nclient_1 Layer 207 weight diff: 2.1993417740\nclient_1 Layer 208 weight diff: 2.2035439014\nclient_1 Layer 209 weight diff: 120.9979324341\nclient_1 Layer 210 weight diff: 622.0674438477\nclient_1 Layer 211 weight diff: 20.6081600189\nclient_1 Layer 212 weight diff: 2307.9033203125\nclient_1 Layer 213 weight diff: 3.0244388580\nclient_1 Layer 214 weight diff: 2.8582334518\nclient_1 Layer 215 weight diff: 44.9567642212\nclient_1 Layer 216 weight diff: 46.4276008606\nclient_1 Layer 217 weight diff: 2369.7192382812\nclient_1 Layer 218 weight diff: 3.1397347450\nclient_1 Layer 219 weight diff: 2.8582329750\nclient_1 Layer 220 weight diff: 1022.3726806641\nclient_1 Layer 221 weight diff: 28043.5996093750\nclient_1 Layer 222 weight diff: 28.4238319397\nclient_1 Layer 223 weight diff: 4940.6894531250\nclient_1 Layer 224 weight diff: 4.4000415802\nclient_1 Layer 225 weight diff: 4.5089888573\nclient_1 Layer 226 weight diff: 163.5134887695\nclient_1 Layer 227 weight diff: 504.6469116211\nclient_1 Layer 228 weight diff: 40.3884162903\nclient_1 Layer 229 weight diff: 8982.3876953125\nclient_1 Layer 230 weight diff: 5.2689709663\nclient_1 Layer 231 weight diff: 5.4606981277\nclient_1 Layer 232 weight diff: 345.9338073730\nclient_1 Layer 233 weight diff: 797.6943969727\nclient_1 Layer 234 weight diff: 0.0000000000\nclient_1 Layer 235 weight diff: 0.0000000000\nclient_1 Layer 236 weight diff: 0.0000000000\nclient_1 Layer 237 weight diff: 0.0000000000\nclient_1 training accuracy history: [0.9098532199859619, 0.9601677060127258, 0.9716981053352356, 0.9769392013549805, 0.9821802973747253]\nclient_1 total local-global weight diff: 88921.73138905\n\n📶 Training on client_2\nTraining client_2 for 5 epochs...\nSum of weights before training: 157863.375\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 930ms/step - accuracy: 0.8954 - loss: 0.3011 - precision_25: 0.9091 - recall_25: 0.8767\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 642ms/step - accuracy: 0.9550 - loss: 0.1591 - precision_25: 0.9581 - recall_25: 0.9471\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 661ms/step - accuracy: 0.9611 - loss: 0.1227 - precision_25: 0.9614 - recall_25: 0.9589\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 652ms/step - accuracy: 0.9844 - loss: 0.0570 - precision_25: 0.9844 - recall_25: 0.9833\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 667ms/step - accuracy: 0.9969 - loss: 0.0207 - precision_25: 0.9969 - recall_25: 0.9953\nSum of weights after training: 175778.469\nclient_2 Layer 0 weight diff: 0.0000000000\nclient_2 Layer 1 weight diff: 0.0000000000\nclient_2 Layer 2 weight diff: 0.0000000000\nclient_2 Layer 3 weight diff: 0.0000000000\nclient_2 Layer 4 weight diff: 0.0000000000\nclient_2 Layer 5 weight diff: 0.0000000000\nclient_2 Layer 6 weight diff: 0.0000000000\nclient_2 Layer 7 weight diff: 0.0000000000\nclient_2 Layer 8 weight diff: 0.0000000000\nclient_2 Layer 9 weight diff: 0.0000000000\nclient_2 Layer 10 weight diff: 0.0000000000\nclient_2 Layer 11 weight diff: 0.0000000000\nclient_2 Layer 12 weight diff: 0.0000000000\nclient_2 Layer 13 weight diff: 0.0000000000\nclient_2 Layer 14 weight diff: 0.0000000000\nclient_2 Layer 15 weight diff: 0.0000000000\nclient_2 Layer 16 weight diff: 0.0000000000\nclient_2 Layer 17 weight diff: 0.0000000000\nclient_2 Layer 18 weight diff: 0.0000000000\nclient_2 Layer 19 weight diff: 0.0000000000\nclient_2 Layer 20 weight diff: 0.0000000000\nclient_2 Layer 21 weight diff: 0.0000000000\nclient_2 Layer 22 weight diff: 0.0000000000\nclient_2 Layer 23 weight diff: 0.0000000000\nclient_2 Layer 24 weight diff: 0.0000000000\nclient_2 Layer 25 weight diff: 0.0000000000\nclient_2 Layer 26 weight diff: 0.0000000000\nclient_2 Layer 27 weight diff: 0.0000000000\nclient_2 Layer 28 weight diff: 0.0000000000\nclient_2 Layer 29 weight diff: 0.0000000000\nclient_2 Layer 30 weight diff: 0.0000000000\nclient_2 Layer 31 weight diff: 0.0000000000\nclient_2 Layer 32 weight diff: 0.0000000000\nclient_2 Layer 33 weight diff: 0.0000000000\nclient_2 Layer 34 weight diff: 0.0000000000\nclient_2 Layer 35 weight diff: 0.0000000000\nclient_2 Layer 36 weight diff: 0.0000000000\nclient_2 Layer 37 weight diff: 0.0000000000\nclient_2 Layer 38 weight diff: 0.0000000000\nclient_2 Layer 39 weight diff: 0.0000000000\nclient_2 Layer 40 weight diff: 0.0000000000\nclient_2 Layer 41 weight diff: 0.0000000000\nclient_2 Layer 42 weight diff: 0.0000000000\nclient_2 Layer 43 weight diff: 0.0000000000\nclient_2 Layer 44 weight diff: 0.0000000000\nclient_2 Layer 45 weight diff: 0.0000000000\nclient_2 Layer 46 weight diff: 0.0000000000\nclient_2 Layer 47 weight diff: 0.0000000000\nclient_2 Layer 48 weight diff: 0.0000000000\nclient_2 Layer 49 weight diff: 0.0000000000\nclient_2 Layer 50 weight diff: 0.0000000000\nclient_2 Layer 51 weight diff: 0.0000000000\nclient_2 Layer 52 weight diff: 0.0000000000\nclient_2 Layer 53 weight diff: 0.0000000000\nclient_2 Layer 54 weight diff: 0.0000000000\nclient_2 Layer 55 weight diff: 0.0000000000\nclient_2 Layer 56 weight diff: 0.0000000000\nclient_2 Layer 57 weight diff: 0.0000000000\nclient_2 Layer 58 weight diff: 0.0000000000\nclient_2 Layer 59 weight diff: 0.0000000000\nclient_2 Layer 60 weight diff: 0.0000000000\nclient_2 Layer 61 weight diff: 0.0000000000\nclient_2 Layer 62 weight diff: 0.0000000000\nclient_2 Layer 63 weight diff: 0.0000000000\nclient_2 Layer 64 weight diff: 0.0000000000\nclient_2 Layer 65 weight diff: 0.0000000000\nclient_2 Layer 66 weight diff: 0.0000000000\nclient_2 Layer 67 weight diff: 0.0000000000\nclient_2 Layer 68 weight diff: 0.0000000000\nclient_2 Layer 69 weight diff: 0.0000000000\nclient_2 Layer 70 weight diff: 0.0000000000\nclient_2 Layer 71 weight diff: 0.0000000000\nclient_2 Layer 72 weight diff: 0.0000000000\nclient_2 Layer 73 weight diff: 0.0000000000\nclient_2 Layer 74 weight diff: 0.0000000000\nclient_2 Layer 75 weight diff: 0.0000000000\nclient_2 Layer 76 weight diff: 0.0000000000\nclient_2 Layer 77 weight diff: 0.0000000000\nclient_2 Layer 78 weight diff: 0.0000000000\nclient_2 Layer 79 weight diff: 0.0000000000\nclient_2 Layer 80 weight diff: 0.0000000000\nclient_2 Layer 81 weight diff: 0.0000000000\nclient_2 Layer 82 weight diff: 0.0000000000\nclient_2 Layer 83 weight diff: 0.0000000000\nclient_2 Layer 84 weight diff: 0.0000000000\nclient_2 Layer 85 weight diff: 22.1176071167\nclient_2 Layer 86 weight diff: 1698.1501464844\nclient_2 Layer 87 weight diff: 2.4054861069\nclient_2 Layer 88 weight diff: 2.3853235245\nclient_2 Layer 89 weight diff: 25.4488601685\nclient_2 Layer 90 weight diff: 16.4877319336\nclient_2 Layer 91 weight diff: 21.6306953430\nclient_2 Layer 92 weight diff: 1709.8410644531\nclient_2 Layer 93 weight diff: 2.3681581020\nclient_2 Layer 94 weight diff: 2.3264822960\nclient_2 Layer 95 weight diff: 18.5111465454\nclient_2 Layer 96 weight diff: 48.4525146484\nclient_2 Layer 97 weight diff: 21.6583423615\nclient_2 Layer 98 weight diff: 1749.2714843750\nclient_2 Layer 99 weight diff: 2.4342837334\nclient_2 Layer 100 weight diff: 2.3852374554\nclient_2 Layer 101 weight diff: 42.4670486450\nclient_2 Layer 102 weight diff: 40.2786636353\nclient_2 Layer 103 weight diff: 21.3279151917\nclient_2 Layer 104 weight diff: 1730.7103271484\nclient_2 Layer 105 weight diff: 2.2724475861\nclient_2 Layer 106 weight diff: 2.3024356365\nclient_2 Layer 107 weight diff: 10.8731994629\nclient_2 Layer 108 weight diff: 9.4954242706\nclient_2 Layer 109 weight diff: 21.7421169281\nclient_2 Layer 110 weight diff: 1718.3898925781\nclient_2 Layer 111 weight diff: 2.2883214951\nclient_2 Layer 112 weight diff: 2.1902723312\nclient_2 Layer 113 weight diff: 8.3707485199\nclient_2 Layer 114 weight diff: 33.3891258240\nclient_2 Layer 115 weight diff: 20.4906044006\nclient_2 Layer 116 weight diff: 1744.4677734375\nclient_2 Layer 117 weight diff: 2.3665382862\nclient_2 Layer 118 weight diff: 2.3259339333\nclient_2 Layer 119 weight diff: 26.3240394592\nclient_2 Layer 120 weight diff: 38.2448310852\nclient_2 Layer 121 weight diff: 21.2839508057\nclient_2 Layer 122 weight diff: 1725.9403076172\nclient_2 Layer 123 weight diff: 2.3826613426\nclient_2 Layer 124 weight diff: 2.4337978363\nclient_2 Layer 125 weight diff: 12.6959438324\nclient_2 Layer 126 weight diff: 7.6643657684\nclient_2 Layer 127 weight diff: 20.7553520203\nclient_2 Layer 128 weight diff: 1708.6508789062\nclient_2 Layer 129 weight diff: 2.2366075516\nclient_2 Layer 130 weight diff: 2.1449155807\nclient_2 Layer 131 weight diff: 9.1012277603\nclient_2 Layer 132 weight diff: 6.2785692215\nclient_2 Layer 133 weight diff: 21.3356933594\nclient_2 Layer 134 weight diff: 1683.3674316406\nclient_2 Layer 135 weight diff: 2.0896220207\nclient_2 Layer 136 weight diff: 2.0496196747\nclient_2 Layer 137 weight diff: 48.4397125244\nclient_2 Layer 138 weight diff: 46.2420768738\nclient_2 Layer 139 weight diff: 19.7500267029\nclient_2 Layer 140 weight diff: 1655.0725097656\nclient_2 Layer 141 weight diff: 2.1824235916\nclient_2 Layer 142 weight diff: 2.2413592339\nclient_2 Layer 143 weight diff: 16.3204040527\nclient_2 Layer 144 weight diff: 12.3371372223\nclient_2 Layer 145 weight diff: 19.3867778778\nclient_2 Layer 146 weight diff: 1663.4414062500\nclient_2 Layer 147 weight diff: 2.2391700745\nclient_2 Layer 148 weight diff: 2.2219018936\nclient_2 Layer 149 weight diff: 16.3929939270\nclient_2 Layer 150 weight diff: 12.2898035049\nclient_2 Layer 151 weight diff: 21.0645141602\nclient_2 Layer 152 weight diff: 1715.5375976562\nclient_2 Layer 153 weight diff: 2.3867039680\nclient_2 Layer 154 weight diff: 2.3836584091\nclient_2 Layer 155 weight diff: 34.6348571777\nclient_2 Layer 156 weight diff: 43.2101860046\nclient_2 Layer 157 weight diff: 21.5051097870\nclient_2 Layer 158 weight diff: 1685.7360839844\nclient_2 Layer 159 weight diff: 2.2769980431\nclient_2 Layer 160 weight diff: 2.3218770027\nclient_2 Layer 161 weight diff: 15.0465822220\nclient_2 Layer 162 weight diff: 13.2065639496\nclient_2 Layer 163 weight diff: 20.6579856873\nclient_2 Layer 164 weight diff: 1667.2487792969\nclient_2 Layer 165 weight diff: 2.2163763046\nclient_2 Layer 166 weight diff: 2.1930298805\nclient_2 Layer 167 weight diff: 10.3417978287\nclient_2 Layer 168 weight diff: 16.8680152893\nclient_2 Layer 169 weight diff: 21.1625823975\nclient_2 Layer 170 weight diff: 1673.6614990234\nclient_2 Layer 171 weight diff: 2.3662261963\nclient_2 Layer 172 weight diff: 2.3606355190\nclient_2 Layer 173 weight diff: 41.7081451416\nclient_2 Layer 174 weight diff: 73.3169097900\nclient_2 Layer 175 weight diff: 20.2679252625\nclient_2 Layer 176 weight diff: 1640.1997070312\nclient_2 Layer 177 weight diff: 2.2486979961\nclient_2 Layer 178 weight diff: 2.3092997074\nclient_2 Layer 179 weight diff: 15.9786100388\nclient_2 Layer 180 weight diff: 24.3408241272\nclient_2 Layer 181 weight diff: 19.6208000183\nclient_2 Layer 182 weight diff: 1608.9776611328\nclient_2 Layer 183 weight diff: 2.1845188141\nclient_2 Layer 184 weight diff: 2.1701560020\nclient_2 Layer 185 weight diff: 12.4774436951\nclient_2 Layer 186 weight diff: 5.4961223602\nclient_2 Layer 187 weight diff: 20.6408119202\nclient_2 Layer 188 weight diff: 1646.1842041016\nclient_2 Layer 189 weight diff: 2.2862045765\nclient_2 Layer 190 weight diff: 2.2554321289\nclient_2 Layer 191 weight diff: 55.0019035339\nclient_2 Layer 192 weight diff: 97.3250656128\nclient_2 Layer 193 weight diff: 19.9664611816\nclient_2 Layer 194 weight diff: 1620.6247558594\nclient_2 Layer 195 weight diff: 2.1946878433\nclient_2 Layer 196 weight diff: 2.2001912594\nclient_2 Layer 197 weight diff: 21.0566043854\nclient_2 Layer 198 weight diff: 34.9970741272\nclient_2 Layer 199 weight diff: 19.9562129974\nclient_2 Layer 200 weight diff: 1579.4020996094\nclient_2 Layer 201 weight diff: 2.1059744358\nclient_2 Layer 202 weight diff: 2.1023535728\nclient_2 Layer 203 weight diff: 13.5481042862\nclient_2 Layer 204 weight diff: 19.4740867615\nclient_2 Layer 205 weight diff: 19.3097496033\nclient_2 Layer 206 weight diff: 1619.2373046875\nclient_2 Layer 207 weight diff: 2.0867426395\nclient_2 Layer 208 weight diff: 2.0929052830\nclient_2 Layer 209 weight diff: 103.4081878662\nclient_2 Layer 210 weight diff: 342.6787414551\nclient_2 Layer 211 weight diff: 19.4157104492\nclient_2 Layer 212 weight diff: 2247.6164550781\nclient_2 Layer 213 weight diff: 2.9587876797\nclient_2 Layer 214 weight diff: 2.8992958069\nclient_2 Layer 215 weight diff: 41.9199371338\nclient_2 Layer 216 weight diff: 34.0782546997\nclient_2 Layer 217 weight diff: 2283.6716308594\nclient_2 Layer 218 weight diff: 2.9519948959\nclient_2 Layer 219 weight diff: 2.8992962837\nclient_2 Layer 220 weight diff: 959.1990966797\nclient_2 Layer 221 weight diff: 30277.6562500000\nclient_2 Layer 222 weight diff: 27.8528461456\nclient_2 Layer 223 weight diff: 4843.8876953125\nclient_2 Layer 224 weight diff: 4.4176297188\nclient_2 Layer 225 weight diff: 4.4903254509\nclient_2 Layer 226 weight diff: 171.6876525879\nclient_2 Layer 227 weight diff: 462.5459594727\nclient_2 Layer 228 weight diff: 40.5610771179\nclient_2 Layer 229 weight diff: 8561.9863281250\nclient_2 Layer 230 weight diff: 4.9227943420\nclient_2 Layer 231 weight diff: 4.9332981110\nclient_2 Layer 232 weight diff: 182.4865264893\nclient_2 Layer 233 weight diff: 363.2175598145\nclient_2 Layer 234 weight diff: 0.0000000000\nclient_2 Layer 235 weight diff: 0.0000000000\nclient_2 Layer 236 weight diff: 0.0000000000\nclient_2 Layer 237 weight diff: 0.0000000000\nclient_2 training accuracy history: [0.8897058963775635, 0.9527310729026794, 0.970588207244873, 0.9852941036224365, 0.9926470518112183]\nclient_2 total local-global weight diff: 87823.23761582\n\n📶 Training on client_3\nTraining client_3 for 5 epochs...\nSum of weights before training: 157863.375\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 958ms/step - accuracy: 0.9132 - loss: 0.3052 - precision_26: 0.9215 - recall_26: 0.9035\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 657ms/step - accuracy: 0.9446 - loss: 0.1538 - precision_26: 0.9541 - recall_26: 0.9355\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 672ms/step - accuracy: 0.9732 - loss: 0.0978 - precision_26: 0.9783 - recall_26: 0.9605\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 690ms/step - accuracy: 0.9792 - loss: 0.1038 - precision_26: 0.9795 - recall_26: 0.9792\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 649ms/step - accuracy: 0.9866 - loss: 0.0275 - precision_26: 0.9866 - recall_26: 0.9863\nSum of weights after training: 177985.797\nclient_3 Layer 0 weight diff: 0.0000000000\nclient_3 Layer 1 weight diff: 0.0000000000\nclient_3 Layer 2 weight diff: 0.0000000000\nclient_3 Layer 3 weight diff: 0.0000000000\nclient_3 Layer 4 weight diff: 0.0000000000\nclient_3 Layer 5 weight diff: 0.0000000000\nclient_3 Layer 6 weight diff: 0.0000000000\nclient_3 Layer 7 weight diff: 0.0000000000\nclient_3 Layer 8 weight diff: 0.0000000000\nclient_3 Layer 9 weight diff: 0.0000000000\nclient_3 Layer 10 weight diff: 0.0000000000\nclient_3 Layer 11 weight diff: 0.0000000000\nclient_3 Layer 12 weight diff: 0.0000000000\nclient_3 Layer 13 weight diff: 0.0000000000\nclient_3 Layer 14 weight diff: 0.0000000000\nclient_3 Layer 15 weight diff: 0.0000000000\nclient_3 Layer 16 weight diff: 0.0000000000\nclient_3 Layer 17 weight diff: 0.0000000000\nclient_3 Layer 18 weight diff: 0.0000000000\nclient_3 Layer 19 weight diff: 0.0000000000\nclient_3 Layer 20 weight diff: 0.0000000000\nclient_3 Layer 21 weight diff: 0.0000000000\nclient_3 Layer 22 weight diff: 0.0000000000\nclient_3 Layer 23 weight diff: 0.0000000000\nclient_3 Layer 24 weight diff: 0.0000000000\nclient_3 Layer 25 weight diff: 0.0000000000\nclient_3 Layer 26 weight diff: 0.0000000000\nclient_3 Layer 27 weight diff: 0.0000000000\nclient_3 Layer 28 weight diff: 0.0000000000\nclient_3 Layer 29 weight diff: 0.0000000000\nclient_3 Layer 30 weight diff: 0.0000000000\nclient_3 Layer 31 weight diff: 0.0000000000\nclient_3 Layer 32 weight diff: 0.0000000000\nclient_3 Layer 33 weight diff: 0.0000000000\nclient_3 Layer 34 weight diff: 0.0000000000\nclient_3 Layer 35 weight diff: 0.0000000000\nclient_3 Layer 36 weight diff: 0.0000000000\nclient_3 Layer 37 weight diff: 0.0000000000\nclient_3 Layer 38 weight diff: 0.0000000000\nclient_3 Layer 39 weight diff: 0.0000000000\nclient_3 Layer 40 weight diff: 0.0000000000\nclient_3 Layer 41 weight diff: 0.0000000000\nclient_3 Layer 42 weight diff: 0.0000000000\nclient_3 Layer 43 weight diff: 0.0000000000\nclient_3 Layer 44 weight diff: 0.0000000000\nclient_3 Layer 45 weight diff: 0.0000000000\nclient_3 Layer 46 weight diff: 0.0000000000\nclient_3 Layer 47 weight diff: 0.0000000000\nclient_3 Layer 48 weight diff: 0.0000000000\nclient_3 Layer 49 weight diff: 0.0000000000\nclient_3 Layer 50 weight diff: 0.0000000000\nclient_3 Layer 51 weight diff: 0.0000000000\nclient_3 Layer 52 weight diff: 0.0000000000\nclient_3 Layer 53 weight diff: 0.0000000000\nclient_3 Layer 54 weight diff: 0.0000000000\nclient_3 Layer 55 weight diff: 0.0000000000\nclient_3 Layer 56 weight diff: 0.0000000000\nclient_3 Layer 57 weight diff: 0.0000000000\nclient_3 Layer 58 weight diff: 0.0000000000\nclient_3 Layer 59 weight diff: 0.0000000000\nclient_3 Layer 60 weight diff: 0.0000000000\nclient_3 Layer 61 weight diff: 0.0000000000\nclient_3 Layer 62 weight diff: 0.0000000000\nclient_3 Layer 63 weight diff: 0.0000000000\nclient_3 Layer 64 weight diff: 0.0000000000\nclient_3 Layer 65 weight diff: 0.0000000000\nclient_3 Layer 66 weight diff: 0.0000000000\nclient_3 Layer 67 weight diff: 0.0000000000\nclient_3 Layer 68 weight diff: 0.0000000000\nclient_3 Layer 69 weight diff: 0.0000000000\nclient_3 Layer 70 weight diff: 0.0000000000\nclient_3 Layer 71 weight diff: 0.0000000000\nclient_3 Layer 72 weight diff: 0.0000000000\nclient_3 Layer 73 weight diff: 0.0000000000\nclient_3 Layer 74 weight diff: 0.0000000000\nclient_3 Layer 75 weight diff: 0.0000000000\nclient_3 Layer 76 weight diff: 0.0000000000\nclient_3 Layer 77 weight diff: 0.0000000000\nclient_3 Layer 78 weight diff: 0.0000000000\nclient_3 Layer 79 weight diff: 0.0000000000\nclient_3 Layer 80 weight diff: 0.0000000000\nclient_3 Layer 81 weight diff: 0.0000000000\nclient_3 Layer 82 weight diff: 0.0000000000\nclient_3 Layer 83 weight diff: 0.0000000000\nclient_3 Layer 84 weight diff: 0.0000000000\nclient_3 Layer 85 weight diff: 21.1422824860\nclient_3 Layer 86 weight diff: 1615.3411865234\nclient_3 Layer 87 weight diff: 2.2368469238\nclient_3 Layer 88 weight diff: 2.2013876438\nclient_3 Layer 89 weight diff: 24.6170654297\nclient_3 Layer 90 weight diff: 15.8016471863\nclient_3 Layer 91 weight diff: 20.1973648071\nclient_3 Layer 92 weight diff: 1642.3720703125\nclient_3 Layer 93 weight diff: 2.3644752502\nclient_3 Layer 94 weight diff: 2.1693906784\nclient_3 Layer 95 weight diff: 19.6360282898\nclient_3 Layer 96 weight diff: 41.6508636475\nclient_3 Layer 97 weight diff: 21.3786964417\nclient_3 Layer 98 weight diff: 1705.3625488281\nclient_3 Layer 99 weight diff: 2.3441057205\nclient_3 Layer 100 weight diff: 2.3503699303\nclient_3 Layer 101 weight diff: 40.2684249878\nclient_3 Layer 102 weight diff: 43.8043975830\nclient_3 Layer 103 weight diff: 20.5075187683\nclient_3 Layer 104 weight diff: 1679.1757812500\nclient_3 Layer 105 weight diff: 2.2507922649\nclient_3 Layer 106 weight diff: 2.2547543049\nclient_3 Layer 107 weight diff: 10.2352418900\nclient_3 Layer 108 weight diff: 11.0589475632\nclient_3 Layer 109 weight diff: 20.3147563934\nclient_3 Layer 110 weight diff: 1662.8466796875\nclient_3 Layer 111 weight diff: 2.2119810581\nclient_3 Layer 112 weight diff: 2.0461430550\nclient_3 Layer 113 weight diff: 8.2278127670\nclient_3 Layer 114 weight diff: 19.9641227722\nclient_3 Layer 115 weight diff: 20.7569084167\nclient_3 Layer 116 weight diff: 1708.1735839844\nclient_3 Layer 117 weight diff: 2.2767958641\nclient_3 Layer 118 weight diff: 2.2671451569\nclient_3 Layer 119 weight diff: 25.4820175171\nclient_3 Layer 120 weight diff: 43.8166809082\nclient_3 Layer 121 weight diff: 20.8765048981\nclient_3 Layer 122 weight diff: 1679.3725585938\nclient_3 Layer 123 weight diff: 2.2570662498\nclient_3 Layer 124 weight diff: 2.2617378235\nclient_3 Layer 125 weight diff: 12.5333681107\nclient_3 Layer 126 weight diff: 8.6655540466\nclient_3 Layer 127 weight diff: 20.5989913940\nclient_3 Layer 128 weight diff: 1653.0697021484\nclient_3 Layer 129 weight diff: 2.1881122589\nclient_3 Layer 130 weight diff: 2.0113840103\nclient_3 Layer 131 weight diff: 11.0288867950\nclient_3 Layer 132 weight diff: 11.2526235580\nclient_3 Layer 133 weight diff: 20.2810058594\nclient_3 Layer 134 weight diff: 1622.8549804688\nclient_3 Layer 135 weight diff: 2.2128188610\nclient_3 Layer 136 weight diff: 2.2190575600\nclient_3 Layer 137 weight diff: 50.3024368286\nclient_3 Layer 138 weight diff: 47.2600517273\nclient_3 Layer 139 weight diff: 19.7097702026\nclient_3 Layer 140 weight diff: 1585.9229736328\nclient_3 Layer 141 weight diff: 2.1071472168\nclient_3 Layer 142 weight diff: 2.2024760246\nclient_3 Layer 143 weight diff: 17.4541625977\nclient_3 Layer 144 weight diff: 14.5605745316\nclient_3 Layer 145 weight diff: 18.8873710632\nclient_3 Layer 146 weight diff: 1567.0720214844\nclient_3 Layer 147 weight diff: 2.1203920841\nclient_3 Layer 148 weight diff: 2.0136380196\nclient_3 Layer 149 weight diff: 22.8819084167\nclient_3 Layer 150 weight diff: 27.3138713837\nclient_3 Layer 151 weight diff: 20.6849479675\nclient_3 Layer 152 weight diff: 1620.2014160156\nclient_3 Layer 153 weight diff: 2.2585031986\nclient_3 Layer 154 weight diff: 2.3281886578\nclient_3 Layer 155 weight diff: 39.2537994385\nclient_3 Layer 156 weight diff: 46.2608718872\nclient_3 Layer 157 weight diff: 20.5082893372\nclient_3 Layer 158 weight diff: 1597.7561035156\nclient_3 Layer 159 weight diff: 2.1078181267\nclient_3 Layer 160 weight diff: 2.0776662827\nclient_3 Layer 161 weight diff: 14.5139474869\nclient_3 Layer 162 weight diff: 10.4886245728\nclient_3 Layer 163 weight diff: 19.1332988739\nclient_3 Layer 164 weight diff: 1567.1258544922\nclient_3 Layer 165 weight diff: 2.0913355350\nclient_3 Layer 166 weight diff: 2.0350866318\nclient_3 Layer 167 weight diff: 9.8832321167\nclient_3 Layer 168 weight diff: 14.9253902435\nclient_3 Layer 169 weight diff: 19.8334350586\nclient_3 Layer 170 weight diff: 1584.6879882812\nclient_3 Layer 171 weight diff: 2.1892101765\nclient_3 Layer 172 weight diff: 2.2405166626\nclient_3 Layer 173 weight diff: 45.2665138245\nclient_3 Layer 174 weight diff: 65.5467987061\nclient_3 Layer 175 weight diff: 19.8031101227\nclient_3 Layer 176 weight diff: 1556.8352050781\nclient_3 Layer 177 weight diff: 2.1031267643\nclient_3 Layer 178 weight diff: 2.0911717415\nclient_3 Layer 179 weight diff: 18.1563186646\nclient_3 Layer 180 weight diff: 35.8153610229\nclient_3 Layer 181 weight diff: 18.6334037781\nclient_3 Layer 182 weight diff: 1517.1052246094\nclient_3 Layer 183 weight diff: 2.1899321079\nclient_3 Layer 184 weight diff: 2.0032157898\nclient_3 Layer 185 weight diff: 12.4630622864\nclient_3 Layer 186 weight diff: 11.4073467255\nclient_3 Layer 187 weight diff: 19.9705581665\nclient_3 Layer 188 weight diff: 1593.0355224609\nclient_3 Layer 189 weight diff: 2.2927505970\nclient_3 Layer 190 weight diff: 2.3013584614\nclient_3 Layer 191 weight diff: 62.4353370667\nclient_3 Layer 192 weight diff: 118.0377044678\nclient_3 Layer 193 weight diff: 20.0183067322\nclient_3 Layer 194 weight diff: 1551.3669433594\nclient_3 Layer 195 weight diff: 2.1333627701\nclient_3 Layer 196 weight diff: 2.1445887089\nclient_3 Layer 197 weight diff: 21.1518058777\nclient_3 Layer 198 weight diff: 20.4284839630\nclient_3 Layer 199 weight diff: 18.5025253296\nclient_3 Layer 200 weight diff: 1520.7266845703\nclient_3 Layer 201 weight diff: 2.0933792591\nclient_3 Layer 202 weight diff: 2.1205663681\nclient_3 Layer 203 weight diff: 12.2505140305\nclient_3 Layer 204 weight diff: 18.0380287170\nclient_3 Layer 205 weight diff: 18.5521507263\nclient_3 Layer 206 weight diff: 1551.2160644531\nclient_3 Layer 207 weight diff: 1.9902429581\nclient_3 Layer 208 weight diff: 2.0325703621\nclient_3 Layer 209 weight diff: 117.9419555664\nclient_3 Layer 210 weight diff: 569.1098632812\nclient_3 Layer 211 weight diff: 18.7179355621\nclient_3 Layer 212 weight diff: 2141.1289062500\nclient_3 Layer 213 weight diff: 2.8323397636\nclient_3 Layer 214 weight diff: 2.6615772247\nclient_3 Layer 215 weight diff: 39.9039688110\nclient_3 Layer 216 weight diff: 44.6813888550\nclient_3 Layer 217 weight diff: 2166.4653320312\nclient_3 Layer 218 weight diff: 2.8798584938\nclient_3 Layer 219 weight diff: 2.6615779400\nclient_3 Layer 220 weight diff: 997.0269775391\nclient_3 Layer 221 weight diff: 30133.1621093750\nclient_3 Layer 222 weight diff: 26.7696762085\nclient_3 Layer 223 weight diff: 4545.0029296875\nclient_3 Layer 224 weight diff: 4.2213335037\nclient_3 Layer 225 weight diff: 4.2523527145\nclient_3 Layer 226 weight diff: 160.9212036133\nclient_3 Layer 227 weight diff: 557.1608886719\nclient_3 Layer 228 weight diff: 38.6823043823\nclient_3 Layer 229 weight diff: 8397.7421875000\nclient_3 Layer 230 weight diff: 4.9954075813\nclient_3 Layer 231 weight diff: 5.2999873161\nclient_3 Layer 232 weight diff: 225.1910705566\nclient_3 Layer 233 weight diff: 444.0386962891\nclient_3 Layer 234 weight diff: 0.0000000000\nclient_3 Layer 235 weight diff: 0.0000000000\nclient_3 Layer 236 weight diff: 0.0000000000\nclient_3 Layer 237 weight diff: 0.0000000000\nclient_3 training accuracy history: [0.9054622054100037, 0.950630247592926, 0.9758403301239014, 0.980042040348053, 0.9905462265014648]\nclient_3 total local-global weight diff: 86050.89655805\n\n📶 Training on client_4\nTraining client_4 for 5 epochs...\nSum of weights before training: 157863.375\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 910ms/step - accuracy: 0.9235 - loss: 0.3126 - precision_27: 0.9267 - recall_27: 0.9129\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 640ms/step - accuracy: 0.9584 - loss: 0.1289 - precision_27: 0.9601 - recall_27: 0.9416\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 662ms/step - accuracy: 0.9888 - loss: 0.0430 - precision_27: 0.9888 - recall_27: 0.9879\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 640ms/step - accuracy: 0.9876 - loss: 0.0554 - precision_27: 0.9876 - recall_27: 0.9844\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 686ms/step - accuracy: 0.9972 - loss: 0.0128 - precision_27: 0.9972 - recall_27: 0.9969\nSum of weights after training: 180000.672\nclient_4 Layer 0 weight diff: 0.0000000000\nclient_4 Layer 1 weight diff: 0.0000000000\nclient_4 Layer 2 weight diff: 0.0000000000\nclient_4 Layer 3 weight diff: 0.0000000000\nclient_4 Layer 4 weight diff: 0.0000000000\nclient_4 Layer 5 weight diff: 0.0000000000\nclient_4 Layer 6 weight diff: 0.0000000000\nclient_4 Layer 7 weight diff: 0.0000000000\nclient_4 Layer 8 weight diff: 0.0000000000\nclient_4 Layer 9 weight diff: 0.0000000000\nclient_4 Layer 10 weight diff: 0.0000000000\nclient_4 Layer 11 weight diff: 0.0000000000\nclient_4 Layer 12 weight diff: 0.0000000000\nclient_4 Layer 13 weight diff: 0.0000000000\nclient_4 Layer 14 weight diff: 0.0000000000\nclient_4 Layer 15 weight diff: 0.0000000000\nclient_4 Layer 16 weight diff: 0.0000000000\nclient_4 Layer 17 weight diff: 0.0000000000\nclient_4 Layer 18 weight diff: 0.0000000000\nclient_4 Layer 19 weight diff: 0.0000000000\nclient_4 Layer 20 weight diff: 0.0000000000\nclient_4 Layer 21 weight diff: 0.0000000000\nclient_4 Layer 22 weight diff: 0.0000000000\nclient_4 Layer 23 weight diff: 0.0000000000\nclient_4 Layer 24 weight diff: 0.0000000000\nclient_4 Layer 25 weight diff: 0.0000000000\nclient_4 Layer 26 weight diff: 0.0000000000\nclient_4 Layer 27 weight diff: 0.0000000000\nclient_4 Layer 28 weight diff: 0.0000000000\nclient_4 Layer 29 weight diff: 0.0000000000\nclient_4 Layer 30 weight diff: 0.0000000000\nclient_4 Layer 31 weight diff: 0.0000000000\nclient_4 Layer 32 weight diff: 0.0000000000\nclient_4 Layer 33 weight diff: 0.0000000000\nclient_4 Layer 34 weight diff: 0.0000000000\nclient_4 Layer 35 weight diff: 0.0000000000\nclient_4 Layer 36 weight diff: 0.0000000000\nclient_4 Layer 37 weight diff: 0.0000000000\nclient_4 Layer 38 weight diff: 0.0000000000\nclient_4 Layer 39 weight diff: 0.0000000000\nclient_4 Layer 40 weight diff: 0.0000000000\nclient_4 Layer 41 weight diff: 0.0000000000\nclient_4 Layer 42 weight diff: 0.0000000000\nclient_4 Layer 43 weight diff: 0.0000000000\nclient_4 Layer 44 weight diff: 0.0000000000\nclient_4 Layer 45 weight diff: 0.0000000000\nclient_4 Layer 46 weight diff: 0.0000000000\nclient_4 Layer 47 weight diff: 0.0000000000\nclient_4 Layer 48 weight diff: 0.0000000000\nclient_4 Layer 49 weight diff: 0.0000000000\nclient_4 Layer 50 weight diff: 0.0000000000\nclient_4 Layer 51 weight diff: 0.0000000000\nclient_4 Layer 52 weight diff: 0.0000000000\nclient_4 Layer 53 weight diff: 0.0000000000\nclient_4 Layer 54 weight diff: 0.0000000000\nclient_4 Layer 55 weight diff: 0.0000000000\nclient_4 Layer 56 weight diff: 0.0000000000\nclient_4 Layer 57 weight diff: 0.0000000000\nclient_4 Layer 58 weight diff: 0.0000000000\nclient_4 Layer 59 weight diff: 0.0000000000\nclient_4 Layer 60 weight diff: 0.0000000000\nclient_4 Layer 61 weight diff: 0.0000000000\nclient_4 Layer 62 weight diff: 0.0000000000\nclient_4 Layer 63 weight diff: 0.0000000000\nclient_4 Layer 64 weight diff: 0.0000000000\nclient_4 Layer 65 weight diff: 0.0000000000\nclient_4 Layer 66 weight diff: 0.0000000000\nclient_4 Layer 67 weight diff: 0.0000000000\nclient_4 Layer 68 weight diff: 0.0000000000\nclient_4 Layer 69 weight diff: 0.0000000000\nclient_4 Layer 70 weight diff: 0.0000000000\nclient_4 Layer 71 weight diff: 0.0000000000\nclient_4 Layer 72 weight diff: 0.0000000000\nclient_4 Layer 73 weight diff: 0.0000000000\nclient_4 Layer 74 weight diff: 0.0000000000\nclient_4 Layer 75 weight diff: 0.0000000000\nclient_4 Layer 76 weight diff: 0.0000000000\nclient_4 Layer 77 weight diff: 0.0000000000\nclient_4 Layer 78 weight diff: 0.0000000000\nclient_4 Layer 79 weight diff: 0.0000000000\nclient_4 Layer 80 weight diff: 0.0000000000\nclient_4 Layer 81 weight diff: 0.0000000000\nclient_4 Layer 82 weight diff: 0.0000000000\nclient_4 Layer 83 weight diff: 0.0000000000\nclient_4 Layer 84 weight diff: 0.0000000000\nclient_4 Layer 85 weight diff: 18.7138156891\nclient_4 Layer 86 weight diff: 1429.4022216797\nclient_4 Layer 87 weight diff: 1.9368383884\nclient_4 Layer 88 weight diff: 1.9128134251\nclient_4 Layer 89 weight diff: 23.2771949768\nclient_4 Layer 90 weight diff: 15.2593040466\nclient_4 Layer 91 weight diff: 17.2643070221\nclient_4 Layer 92 weight diff: 1405.8632812500\nclient_4 Layer 93 weight diff: 1.9204335213\nclient_4 Layer 94 weight diff: 1.8095469475\nclient_4 Layer 95 weight diff: 16.1639099121\nclient_4 Layer 96 weight diff: 36.3141708374\nclient_4 Layer 97 weight diff: 17.8957481384\nclient_4 Layer 98 weight diff: 1437.6303710938\nclient_4 Layer 99 weight diff: 1.9096696377\nclient_4 Layer 100 weight diff: 1.9160263538\nclient_4 Layer 101 weight diff: 38.6853942871\nclient_4 Layer 102 weight diff: 35.4999237061\nclient_4 Layer 103 weight diff: 16.8104438782\nclient_4 Layer 104 weight diff: 1426.8677978516\nclient_4 Layer 105 weight diff: 1.9548289776\nclient_4 Layer 106 weight diff: 1.9592382908\nclient_4 Layer 107 weight diff: 8.5069131851\nclient_4 Layer 108 weight diff: 7.6716661453\nclient_4 Layer 109 weight diff: 17.3652362823\nclient_4 Layer 110 weight diff: 1422.8636474609\nclient_4 Layer 111 weight diff: 1.9224953651\nclient_4 Layer 112 weight diff: 1.8454153538\nclient_4 Layer 113 weight diff: 6.9039030075\nclient_4 Layer 114 weight diff: 17.7331447601\nclient_4 Layer 115 weight diff: 16.8458118439\nclient_4 Layer 116 weight diff: 1418.8425292969\nclient_4 Layer 117 weight diff: 1.7988579273\nclient_4 Layer 118 weight diff: 1.9129197598\nclient_4 Layer 119 weight diff: 20.9053897858\nclient_4 Layer 120 weight diff: 37.7462768555\nclient_4 Layer 121 weight diff: 16.6142768860\nclient_4 Layer 122 weight diff: 1395.8927001953\nclient_4 Layer 123 weight diff: 1.8282256126\nclient_4 Layer 124 weight diff: 1.8964537382\nclient_4 Layer 125 weight diff: 9.6765575409\nclient_4 Layer 126 weight diff: 6.9107370377\nclient_4 Layer 127 weight diff: 17.0935382843\nclient_4 Layer 128 weight diff: 1393.1845703125\nclient_4 Layer 129 weight diff: 1.8728320599\nclient_4 Layer 130 weight diff: 1.7894282341\nclient_4 Layer 131 weight diff: 8.5326156616\nclient_4 Layer 132 weight diff: 5.4056482315\nclient_4 Layer 133 weight diff: 16.7124195099\nclient_4 Layer 134 weight diff: 1388.5400390625\nclient_4 Layer 135 weight diff: 1.8535523415\nclient_4 Layer 136 weight diff: 1.8641061783\nclient_4 Layer 137 weight diff: 43.3855209351\nclient_4 Layer 138 weight diff: 52.9749069214\nclient_4 Layer 139 weight diff: 17.0444030762\nclient_4 Layer 140 weight diff: 1379.0056152344\nclient_4 Layer 141 weight diff: 1.7783305645\nclient_4 Layer 142 weight diff: 1.8082334995\nclient_4 Layer 143 weight diff: 15.6743059158\nclient_4 Layer 144 weight diff: 10.5729055405\nclient_4 Layer 145 weight diff: 16.2995433807\nclient_4 Layer 146 weight diff: 1375.0207519531\nclient_4 Layer 147 weight diff: 1.9190884829\nclient_4 Layer 148 weight diff: 1.8235011101\nclient_4 Layer 149 weight diff: 17.3795089722\nclient_4 Layer 150 weight diff: 19.4941253662\nclient_4 Layer 151 weight diff: 17.4167709351\nclient_4 Layer 152 weight diff: 1391.1870117188\nclient_4 Layer 153 weight diff: 1.9758586884\nclient_4 Layer 154 weight diff: 2.0284757614\nclient_4 Layer 155 weight diff: 32.9657020569\nclient_4 Layer 156 weight diff: 41.7983551025\nclient_4 Layer 157 weight diff: 17.2701301575\nclient_4 Layer 158 weight diff: 1374.5180664062\nclient_4 Layer 159 weight diff: 1.8388929367\nclient_4 Layer 160 weight diff: 1.8476595879\nclient_4 Layer 161 weight diff: 12.8055906296\nclient_4 Layer 162 weight diff: 10.3458099365\nclient_4 Layer 163 weight diff: 16.2057418823\nclient_4 Layer 164 weight diff: 1356.2252197266\nclient_4 Layer 165 weight diff: 1.7945344448\nclient_4 Layer 166 weight diff: 1.8537337780\nclient_4 Layer 167 weight diff: 7.2168064117\nclient_4 Layer 168 weight diff: 11.2028369904\nclient_4 Layer 169 weight diff: 17.3499126434\nclient_4 Layer 170 weight diff: 1382.5889892578\nclient_4 Layer 171 weight diff: 1.9577121735\nclient_4 Layer 172 weight diff: 1.9114727974\nclient_4 Layer 173 weight diff: 36.0642700195\nclient_4 Layer 174 weight diff: 52.9406280518\nclient_4 Layer 175 weight diff: 17.2321414948\nclient_4 Layer 176 weight diff: 1371.7885742188\nclient_4 Layer 177 weight diff: 1.8337293863\nclient_4 Layer 178 weight diff: 1.8684099913\nclient_4 Layer 179 weight diff: 13.9953784943\nclient_4 Layer 180 weight diff: 23.5815010071\nclient_4 Layer 181 weight diff: 16.1027488708\nclient_4 Layer 182 weight diff: 1346.0590820312\nclient_4 Layer 183 weight diff: 1.7614455223\nclient_4 Layer 184 weight diff: 1.8137626648\nclient_4 Layer 185 weight diff: 10.0943489075\nclient_4 Layer 186 weight diff: 14.8229560852\nclient_4 Layer 187 weight diff: 16.9800643921\nclient_4 Layer 188 weight diff: 1386.6607666016\nclient_4 Layer 189 weight diff: 1.8622796535\nclient_4 Layer 190 weight diff: 1.8312165737\nclient_4 Layer 191 weight diff: 53.1214675903\nclient_4 Layer 192 weight diff: 97.6439666748\nclient_4 Layer 193 weight diff: 16.7439460754\nclient_4 Layer 194 weight diff: 1359.8134765625\nclient_4 Layer 195 weight diff: 1.8545243740\nclient_4 Layer 196 weight diff: 1.8941338062\nclient_4 Layer 197 weight diff: 18.5700244904\nclient_4 Layer 198 weight diff: 25.4111709595\nclient_4 Layer 199 weight diff: 16.2712821960\nclient_4 Layer 200 weight diff: 1329.4638671875\nclient_4 Layer 201 weight diff: 1.7300918102\nclient_4 Layer 202 weight diff: 1.7523539066\nclient_4 Layer 203 weight diff: 9.9712438583\nclient_4 Layer 204 weight diff: 10.8976783752\nclient_4 Layer 205 weight diff: 16.6497650146\nclient_4 Layer 206 weight diff: 1391.5672607422\nclient_4 Layer 207 weight diff: 1.7898467779\nclient_4 Layer 208 weight diff: 1.7774875164\nclient_4 Layer 209 weight diff: 102.7356643677\nclient_4 Layer 210 weight diff: 485.0479125977\nclient_4 Layer 211 weight diff: 16.9587287903\nclient_4 Layer 212 weight diff: 1909.8629150391\nclient_4 Layer 213 weight diff: 2.5775177479\nclient_4 Layer 214 weight diff: 2.1099393368\nclient_4 Layer 215 weight diff: 43.2931823730\nclient_4 Layer 216 weight diff: 47.1383972168\nclient_4 Layer 217 weight diff: 1817.9975585938\nclient_4 Layer 218 weight diff: 2.2835307121\nclient_4 Layer 219 weight diff: 2.1099390984\nclient_4 Layer 220 weight diff: 816.5899658203\nclient_4 Layer 221 weight diff: 28724.9804687500\nclient_4 Layer 222 weight diff: 22.9471111298\nclient_4 Layer 223 weight diff: 4108.5815429688\nclient_4 Layer 224 weight diff: 3.5555136204\nclient_4 Layer 225 weight diff: 3.5407662392\nclient_4 Layer 226 weight diff: 167.3209533691\nclient_4 Layer 227 weight diff: 375.2856445312\nclient_4 Layer 228 weight diff: 34.3908309937\nclient_4 Layer 229 weight diff: 7912.4580078125\nclient_4 Layer 230 weight diff: 4.2766041756\nclient_4 Layer 231 weight diff: 4.7998809814\nclient_4 Layer 232 weight diff: 125.1788635254\nclient_4 Layer 233 weight diff: 178.8786926270\nclient_4 Layer 234 weight diff: 0.0000000000\nclient_4 Layer 235 weight diff: 0.0000000000\nclient_4 Layer 236 weight diff: 0.0000000000\nclient_4 Layer 237 weight diff: 0.0000000000\nclient_4 training accuracy history: [0.924369752407074, 0.9537814855575562, 0.9821428656578064, 0.9894958138465881, 0.9947478771209717]\nclient_4 total local-global weight diff: 77451.10223711\n\n📶 Training on client_5\nTraining client_5 for 5 epochs...\nSum of weights before training: 157863.375\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 916ms/step - accuracy: 0.8894 - loss: 0.3583 - precision_28: 0.9059 - recall_28: 0.8666\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 670ms/step - accuracy: 0.9514 - loss: 0.1461 - precision_28: 0.9628 - recall_28: 0.9447\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 0.9792 - loss: 0.0738 - precision_28: 0.9792 - recall_28: 0.9787\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 693ms/step - accuracy: 0.9905 - loss: 0.0389 - precision_28: 0.9912 - recall_28: 0.9905\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 663ms/step - accuracy: 0.9879 - loss: 0.0372 - precision_28: 0.9884 - recall_28: 0.9845\nSum of weights after training: 168659.312\nclient_5 Layer 0 weight diff: 0.0000000000\nclient_5 Layer 1 weight diff: 0.0000000000\nclient_5 Layer 2 weight diff: 0.0000000000\nclient_5 Layer 3 weight diff: 0.0000000000\nclient_5 Layer 4 weight diff: 0.0000000000\nclient_5 Layer 5 weight diff: 0.0000000000\nclient_5 Layer 6 weight diff: 0.0000000000\nclient_5 Layer 7 weight diff: 0.0000000000\nclient_5 Layer 8 weight diff: 0.0000000000\nclient_5 Layer 9 weight diff: 0.0000000000\nclient_5 Layer 10 weight diff: 0.0000000000\nclient_5 Layer 11 weight diff: 0.0000000000\nclient_5 Layer 12 weight diff: 0.0000000000\nclient_5 Layer 13 weight diff: 0.0000000000\nclient_5 Layer 14 weight diff: 0.0000000000\nclient_5 Layer 15 weight diff: 0.0000000000\nclient_5 Layer 16 weight diff: 0.0000000000\nclient_5 Layer 17 weight diff: 0.0000000000\nclient_5 Layer 18 weight diff: 0.0000000000\nclient_5 Layer 19 weight diff: 0.0000000000\nclient_5 Layer 20 weight diff: 0.0000000000\nclient_5 Layer 21 weight diff: 0.0000000000\nclient_5 Layer 22 weight diff: 0.0000000000\nclient_5 Layer 23 weight diff: 0.0000000000\nclient_5 Layer 24 weight diff: 0.0000000000\nclient_5 Layer 25 weight diff: 0.0000000000\nclient_5 Layer 26 weight diff: 0.0000000000\nclient_5 Layer 27 weight diff: 0.0000000000\nclient_5 Layer 28 weight diff: 0.0000000000\nclient_5 Layer 29 weight diff: 0.0000000000\nclient_5 Layer 30 weight diff: 0.0000000000\nclient_5 Layer 31 weight diff: 0.0000000000\nclient_5 Layer 32 weight diff: 0.0000000000\nclient_5 Layer 33 weight diff: 0.0000000000\nclient_5 Layer 34 weight diff: 0.0000000000\nclient_5 Layer 35 weight diff: 0.0000000000\nclient_5 Layer 36 weight diff: 0.0000000000\nclient_5 Layer 37 weight diff: 0.0000000000\nclient_5 Layer 38 weight diff: 0.0000000000\nclient_5 Layer 39 weight diff: 0.0000000000\nclient_5 Layer 40 weight diff: 0.0000000000\nclient_5 Layer 41 weight diff: 0.0000000000\nclient_5 Layer 42 weight diff: 0.0000000000\nclient_5 Layer 43 weight diff: 0.0000000000\nclient_5 Layer 44 weight diff: 0.0000000000\nclient_5 Layer 45 weight diff: 0.0000000000\nclient_5 Layer 46 weight diff: 0.0000000000\nclient_5 Layer 47 weight diff: 0.0000000000\nclient_5 Layer 48 weight diff: 0.0000000000\nclient_5 Layer 49 weight diff: 0.0000000000\nclient_5 Layer 50 weight diff: 0.0000000000\nclient_5 Layer 51 weight diff: 0.0000000000\nclient_5 Layer 52 weight diff: 0.0000000000\nclient_5 Layer 53 weight diff: 0.0000000000\nclient_5 Layer 54 weight diff: 0.0000000000\nclient_5 Layer 55 weight diff: 0.0000000000\nclient_5 Layer 56 weight diff: 0.0000000000\nclient_5 Layer 57 weight diff: 0.0000000000\nclient_5 Layer 58 weight diff: 0.0000000000\nclient_5 Layer 59 weight diff: 0.0000000000\nclient_5 Layer 60 weight diff: 0.0000000000\nclient_5 Layer 61 weight diff: 0.0000000000\nclient_5 Layer 62 weight diff: 0.0000000000\nclient_5 Layer 63 weight diff: 0.0000000000\nclient_5 Layer 64 weight diff: 0.0000000000\nclient_5 Layer 65 weight diff: 0.0000000000\nclient_5 Layer 66 weight diff: 0.0000000000\nclient_5 Layer 67 weight diff: 0.0000000000\nclient_5 Layer 68 weight diff: 0.0000000000\nclient_5 Layer 69 weight diff: 0.0000000000\nclient_5 Layer 70 weight diff: 0.0000000000\nclient_5 Layer 71 weight diff: 0.0000000000\nclient_5 Layer 72 weight diff: 0.0000000000\nclient_5 Layer 73 weight diff: 0.0000000000\nclient_5 Layer 74 weight diff: 0.0000000000\nclient_5 Layer 75 weight diff: 0.0000000000\nclient_5 Layer 76 weight diff: 0.0000000000\nclient_5 Layer 77 weight diff: 0.0000000000\nclient_5 Layer 78 weight diff: 0.0000000000\nclient_5 Layer 79 weight diff: 0.0000000000\nclient_5 Layer 80 weight diff: 0.0000000000\nclient_5 Layer 81 weight diff: 0.0000000000\nclient_5 Layer 82 weight diff: 0.0000000000\nclient_5 Layer 83 weight diff: 0.0000000000\nclient_5 Layer 84 weight diff: 0.0000000000\nclient_5 Layer 85 weight diff: 20.8537273407\nclient_5 Layer 86 weight diff: 1613.9467773438\nclient_5 Layer 87 weight diff: 2.1047136784\nclient_5 Layer 88 weight diff: 2.1428382397\nclient_5 Layer 89 weight diff: 24.3766307831\nclient_5 Layer 90 weight diff: 16.1697425842\nclient_5 Layer 91 weight diff: 19.2029342651\nclient_5 Layer 92 weight diff: 1640.9958496094\nclient_5 Layer 93 weight diff: 2.2424852848\nclient_5 Layer 94 weight diff: 2.2312462330\nclient_5 Layer 95 weight diff: 18.8841209412\nclient_5 Layer 96 weight diff: 41.8270263672\nclient_5 Layer 97 weight diff: 20.7255783081\nclient_5 Layer 98 weight diff: 1672.1364746094\nclient_5 Layer 99 weight diff: 2.1902065277\nclient_5 Layer 100 weight diff: 2.2698283195\nclient_5 Layer 101 weight diff: 42.0403938293\nclient_5 Layer 102 weight diff: 44.0957412720\nclient_5 Layer 103 weight diff: 19.7382164001\nclient_5 Layer 104 weight diff: 1651.1569824219\nclient_5 Layer 105 weight diff: 2.1841545105\nclient_5 Layer 106 weight diff: 2.1411523819\nclient_5 Layer 107 weight diff: 12.2199001312\nclient_5 Layer 108 weight diff: 12.2267723083\nclient_5 Layer 109 weight diff: 20.0333728790\nclient_5 Layer 110 weight diff: 1641.8745117188\nclient_5 Layer 111 weight diff: 2.1244630814\nclient_5 Layer 112 weight diff: 2.1740653515\nclient_5 Layer 113 weight diff: 9.1070365906\nclient_5 Layer 114 weight diff: 23.7778167725\nclient_5 Layer 115 weight diff: 20.7506332397\nclient_5 Layer 116 weight diff: 1703.8508300781\nclient_5 Layer 117 weight diff: 2.3039598465\nclient_5 Layer 118 weight diff: 2.3629319668\nclient_5 Layer 119 weight diff: 24.7952995300\nclient_5 Layer 120 weight diff: 41.6927070618\nclient_5 Layer 121 weight diff: 20.7214393616\nclient_5 Layer 122 weight diff: 1689.4196777344\nclient_5 Layer 123 weight diff: 2.1662032604\nclient_5 Layer 124 weight diff: 2.1840229034\nclient_5 Layer 125 weight diff: 12.1426429749\nclient_5 Layer 126 weight diff: 8.0380544662\nclient_5 Layer 127 weight diff: 20.2507324219\nclient_5 Layer 128 weight diff: 1675.1329345703\nclient_5 Layer 129 weight diff: 2.3161506653\nclient_5 Layer 130 weight diff: 2.2325510979\nclient_5 Layer 131 weight diff: 9.7405691147\nclient_5 Layer 132 weight diff: 6.4447116852\nclient_5 Layer 133 weight diff: 20.8253593445\nclient_5 Layer 134 weight diff: 1640.3264160156\nclient_5 Layer 135 weight diff: 2.3518979549\nclient_5 Layer 136 weight diff: 2.3261818886\nclient_5 Layer 137 weight diff: 46.5187454224\nclient_5 Layer 138 weight diff: 45.7258911133\nclient_5 Layer 139 weight diff: 20.3096256256\nclient_5 Layer 140 weight diff: 1619.8426513672\nclient_5 Layer 141 weight diff: 2.2724547386\nclient_5 Layer 142 weight diff: 2.2513356209\nclient_5 Layer 143 weight diff: 17.0984764099\nclient_5 Layer 144 weight diff: 10.9968585968\nclient_5 Layer 145 weight diff: 19.4927978516\nclient_5 Layer 146 weight diff: 1621.3087158203\nclient_5 Layer 147 weight diff: 2.2691793442\nclient_5 Layer 148 weight diff: 2.1729497910\nclient_5 Layer 149 weight diff: 15.2818107605\nclient_5 Layer 150 weight diff: 11.7172212601\nclient_5 Layer 151 weight diff: 21.1343078613\nclient_5 Layer 152 weight diff: 1647.3154296875\nclient_5 Layer 153 weight diff: 2.2171278000\nclient_5 Layer 154 weight diff: 2.2268571854\nclient_5 Layer 155 weight diff: 35.0381355286\nclient_5 Layer 156 weight diff: 47.3635101318\nclient_5 Layer 157 weight diff: 19.9630317688\nclient_5 Layer 158 weight diff: 1616.8332519531\nclient_5 Layer 159 weight diff: 2.1915047169\nclient_5 Layer 160 weight diff: 2.1807823181\nclient_5 Layer 161 weight diff: 13.6339817047\nclient_5 Layer 162 weight diff: 22.7620468140\nclient_5 Layer 163 weight diff: 19.4354667664\nclient_5 Layer 164 weight diff: 1600.9874267578\nclient_5 Layer 165 weight diff: 2.0809297562\nclient_5 Layer 166 weight diff: 2.0739126205\nclient_5 Layer 167 weight diff: 10.2247800827\nclient_5 Layer 168 weight diff: 13.8910694122\nclient_5 Layer 169 weight diff: 20.1055202484\nclient_5 Layer 170 weight diff: 1598.5908203125\nclient_5 Layer 171 weight diff: 2.1749477386\nclient_5 Layer 172 weight diff: 2.1523342133\nclient_5 Layer 173 weight diff: 38.9359016418\nclient_5 Layer 174 weight diff: 59.8978767395\nclient_5 Layer 175 weight diff: 18.8591117859\nclient_5 Layer 176 weight diff: 1581.1396484375\nclient_5 Layer 177 weight diff: 2.1919989586\nclient_5 Layer 178 weight diff: 2.2120223045\nclient_5 Layer 179 weight diff: 16.0279197693\nclient_5 Layer 180 weight diff: 37.1144752502\nclient_5 Layer 181 weight diff: 18.4591541290\nclient_5 Layer 182 weight diff: 1560.9525146484\nclient_5 Layer 183 weight diff: 2.1735348701\nclient_5 Layer 184 weight diff: 2.0864210129\nclient_5 Layer 185 weight diff: 12.9461193085\nclient_5 Layer 186 weight diff: 17.9885673523\nclient_5 Layer 187 weight diff: 19.9145965576\nclient_5 Layer 188 weight diff: 1611.0942382812\nclient_5 Layer 189 weight diff: 2.2381694317\nclient_5 Layer 190 weight diff: 2.2880744934\nclient_5 Layer 191 weight diff: 55.7348785400\nclient_5 Layer 192 weight diff: 103.9255294800\nclient_5 Layer 193 weight diff: 20.2606163025\nclient_5 Layer 194 weight diff: 1581.2963867188\nclient_5 Layer 195 weight diff: 2.0631604195\nclient_5 Layer 196 weight diff: 2.1043424606\nclient_5 Layer 197 weight diff: 19.4258422852\nclient_5 Layer 198 weight diff: 16.7406578064\nclient_5 Layer 199 weight diff: 18.1758193970\nclient_5 Layer 200 weight diff: 1568.6767578125\nclient_5 Layer 201 weight diff: 2.0269632339\nclient_5 Layer 202 weight diff: 2.2019386292\nclient_5 Layer 203 weight diff: 10.4660902023\nclient_5 Layer 204 weight diff: 11.9865150452\nclient_5 Layer 205 weight diff: 19.3969020844\nclient_5 Layer 206 weight diff: 1580.3984375000\nclient_5 Layer 207 weight diff: 1.8716597557\nclient_5 Layer 208 weight diff: 1.9064900875\nclient_5 Layer 209 weight diff: 91.9066772461\nclient_5 Layer 210 weight diff: 506.2988891602\nclient_5 Layer 211 weight diff: 17.9845085144\nclient_5 Layer 212 weight diff: 2125.7448730469\nclient_5 Layer 213 weight diff: 2.8479566574\nclient_5 Layer 214 weight diff: 3.0047998428\nclient_5 Layer 215 weight diff: 44.0413551331\nclient_5 Layer 216 weight diff: 57.4528770447\nclient_5 Layer 217 weight diff: 2253.9768066406\nclient_5 Layer 218 weight diff: 2.9291903973\nclient_5 Layer 219 weight diff: 3.0047998428\nclient_5 Layer 220 weight diff: 941.3491821289\nclient_5 Layer 221 weight diff: 24186.9355468750\nclient_5 Layer 222 weight diff: 26.5808296204\nclient_5 Layer 223 weight diff: 4622.0834960938\nclient_5 Layer 224 weight diff: 4.1564402580\nclient_5 Layer 225 weight diff: 4.1911821365\nclient_5 Layer 226 weight diff: 162.1662597656\nclient_5 Layer 227 weight diff: 519.8518066406\nclient_5 Layer 228 weight diff: 38.4600181580\nclient_5 Layer 229 weight diff: 8370.6230468750\nclient_5 Layer 230 weight diff: 5.0516214371\nclient_5 Layer 231 weight diff: 5.0676927567\nclient_5 Layer 232 weight diff: 305.1455078125\nclient_5 Layer 233 weight diff: 529.1590576172\nclient_5 Layer 234 weight diff: 0.0000000000\nclient_5 Layer 235 weight diff: 0.0000000000\nclient_5 Layer 236 weight diff: 0.0000000000\nclient_5 Layer 237 weight diff: 0.0000000000\nclient_5 training accuracy history: [0.8886554837226868, 0.9537814855575562, 0.9716386795043945, 0.9842436909675598, 0.9789915680885315]\nclient_5 total local-global weight diff: 80496.60031080\n\n📶 Training on client_6\nTraining client_6 for 5 epochs...\nSum of weights before training: 157863.375\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 907ms/step - accuracy: 0.8867 - loss: 0.3138 - precision_29: 0.9143 - recall_29: 0.8757\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 674ms/step - accuracy: 0.9518 - loss: 0.1607 - precision_29: 0.9561 - recall_29: 0.9419\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 660ms/step - accuracy: 0.9668 - loss: 0.0860 - precision_29: 0.9727 - recall_29: 0.9646\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 658ms/step - accuracy: 0.9763 - loss: 0.0725 - precision_29: 0.9762 - recall_29: 0.9748\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 672ms/step - accuracy: 0.9859 - loss: 0.0566 - precision_29: 0.9859 - recall_29: 0.9844\nSum of weights after training: 190741.641\nclient_6 Layer 0 weight diff: 0.0000000000\nclient_6 Layer 1 weight diff: 0.0000000000\nclient_6 Layer 2 weight diff: 0.0000000000\nclient_6 Layer 3 weight diff: 0.0000000000\nclient_6 Layer 4 weight diff: 0.0000000000\nclient_6 Layer 5 weight diff: 0.0000000000\nclient_6 Layer 6 weight diff: 0.0000000000\nclient_6 Layer 7 weight diff: 0.0000000000\nclient_6 Layer 8 weight diff: 0.0000000000\nclient_6 Layer 9 weight diff: 0.0000000000\nclient_6 Layer 10 weight diff: 0.0000000000\nclient_6 Layer 11 weight diff: 0.0000000000\nclient_6 Layer 12 weight diff: 0.0000000000\nclient_6 Layer 13 weight diff: 0.0000000000\nclient_6 Layer 14 weight diff: 0.0000000000\nclient_6 Layer 15 weight diff: 0.0000000000\nclient_6 Layer 16 weight diff: 0.0000000000\nclient_6 Layer 17 weight diff: 0.0000000000\nclient_6 Layer 18 weight diff: 0.0000000000\nclient_6 Layer 19 weight diff: 0.0000000000\nclient_6 Layer 20 weight diff: 0.0000000000\nclient_6 Layer 21 weight diff: 0.0000000000\nclient_6 Layer 22 weight diff: 0.0000000000\nclient_6 Layer 23 weight diff: 0.0000000000\nclient_6 Layer 24 weight diff: 0.0000000000\nclient_6 Layer 25 weight diff: 0.0000000000\nclient_6 Layer 26 weight diff: 0.0000000000\nclient_6 Layer 27 weight diff: 0.0000000000\nclient_6 Layer 28 weight diff: 0.0000000000\nclient_6 Layer 29 weight diff: 0.0000000000\nclient_6 Layer 30 weight diff: 0.0000000000\nclient_6 Layer 31 weight diff: 0.0000000000\nclient_6 Layer 32 weight diff: 0.0000000000\nclient_6 Layer 33 weight diff: 0.0000000000\nclient_6 Layer 34 weight diff: 0.0000000000\nclient_6 Layer 35 weight diff: 0.0000000000\nclient_6 Layer 36 weight diff: 0.0000000000\nclient_6 Layer 37 weight diff: 0.0000000000\nclient_6 Layer 38 weight diff: 0.0000000000\nclient_6 Layer 39 weight diff: 0.0000000000\nclient_6 Layer 40 weight diff: 0.0000000000\nclient_6 Layer 41 weight diff: 0.0000000000\nclient_6 Layer 42 weight diff: 0.0000000000\nclient_6 Layer 43 weight diff: 0.0000000000\nclient_6 Layer 44 weight diff: 0.0000000000\nclient_6 Layer 45 weight diff: 0.0000000000\nclient_6 Layer 46 weight diff: 0.0000000000\nclient_6 Layer 47 weight diff: 0.0000000000\nclient_6 Layer 48 weight diff: 0.0000000000\nclient_6 Layer 49 weight diff: 0.0000000000\nclient_6 Layer 50 weight diff: 0.0000000000\nclient_6 Layer 51 weight diff: 0.0000000000\nclient_6 Layer 52 weight diff: 0.0000000000\nclient_6 Layer 53 weight diff: 0.0000000000\nclient_6 Layer 54 weight diff: 0.0000000000\nclient_6 Layer 55 weight diff: 0.0000000000\nclient_6 Layer 56 weight diff: 0.0000000000\nclient_6 Layer 57 weight diff: 0.0000000000\nclient_6 Layer 58 weight diff: 0.0000000000\nclient_6 Layer 59 weight diff: 0.0000000000\nclient_6 Layer 60 weight diff: 0.0000000000\nclient_6 Layer 61 weight diff: 0.0000000000\nclient_6 Layer 62 weight diff: 0.0000000000\nclient_6 Layer 63 weight diff: 0.0000000000\nclient_6 Layer 64 weight diff: 0.0000000000\nclient_6 Layer 65 weight diff: 0.0000000000\nclient_6 Layer 66 weight diff: 0.0000000000\nclient_6 Layer 67 weight diff: 0.0000000000\nclient_6 Layer 68 weight diff: 0.0000000000\nclient_6 Layer 69 weight diff: 0.0000000000\nclient_6 Layer 70 weight diff: 0.0000000000\nclient_6 Layer 71 weight diff: 0.0000000000\nclient_6 Layer 72 weight diff: 0.0000000000\nclient_6 Layer 73 weight diff: 0.0000000000\nclient_6 Layer 74 weight diff: 0.0000000000\nclient_6 Layer 75 weight diff: 0.0000000000\nclient_6 Layer 76 weight diff: 0.0000000000\nclient_6 Layer 77 weight diff: 0.0000000000\nclient_6 Layer 78 weight diff: 0.0000000000\nclient_6 Layer 79 weight diff: 0.0000000000\nclient_6 Layer 80 weight diff: 0.0000000000\nclient_6 Layer 81 weight diff: 0.0000000000\nclient_6 Layer 82 weight diff: 0.0000000000\nclient_6 Layer 83 weight diff: 0.0000000000\nclient_6 Layer 84 weight diff: 0.0000000000\nclient_6 Layer 85 weight diff: 22.1172103882\nclient_6 Layer 86 weight diff: 1698.3422851562\nclient_6 Layer 87 weight diff: 2.4569396973\nclient_6 Layer 88 weight diff: 2.4363126755\nclient_6 Layer 89 weight diff: 26.1246414185\nclient_6 Layer 90 weight diff: 17.8575839996\nclient_6 Layer 91 weight diff: 21.8786849976\nclient_6 Layer 92 weight diff: 1724.3378906250\nclient_6 Layer 93 weight diff: 2.4187269211\nclient_6 Layer 94 weight diff: 2.3170049191\nclient_6 Layer 95 weight diff: 19.2034778595\nclient_6 Layer 96 weight diff: 45.4493408203\nclient_6 Layer 97 weight diff: 22.6991424561\nclient_6 Layer 98 weight diff: 1815.5262451172\nclient_6 Layer 99 weight diff: 2.5071935654\nclient_6 Layer 100 weight diff: 2.6660575867\nclient_6 Layer 101 weight diff: 44.6409835815\nclient_6 Layer 102 weight diff: 42.7505912781\nclient_6 Layer 103 weight diff: 21.4193191528\nclient_6 Layer 104 weight diff: 1784.2741699219\nclient_6 Layer 105 weight diff: 2.4610581398\nclient_6 Layer 106 weight diff: 2.4944691658\nclient_6 Layer 107 weight diff: 11.2996225357\nclient_6 Layer 108 weight diff: 10.2238578796\nclient_6 Layer 109 weight diff: 21.9521102905\nclient_6 Layer 110 weight diff: 1779.0679931641\nclient_6 Layer 111 weight diff: 2.2920556068\nclient_6 Layer 112 weight diff: 2.1594812870\nclient_6 Layer 113 weight diff: 8.6140918732\nclient_6 Layer 114 weight diff: 23.2672271729\nclient_6 Layer 115 weight diff: 21.8012466431\nclient_6 Layer 116 weight diff: 1798.1791992188\nclient_6 Layer 117 weight diff: 2.3649981022\nclient_6 Layer 118 weight diff: 2.3938450813\nclient_6 Layer 119 weight diff: 28.2029304504\nclient_6 Layer 120 weight diff: 47.0207366943\nclient_6 Layer 121 weight diff: 21.4787406921\nclient_6 Layer 122 weight diff: 1770.7888183594\nclient_6 Layer 123 weight diff: 2.2460274696\nclient_6 Layer 124 weight diff: 2.2937252522\nclient_6 Layer 125 weight diff: 12.6394538879\nclient_6 Layer 126 weight diff: 8.2710914612\nclient_6 Layer 127 weight diff: 21.0741271973\nclient_6 Layer 128 weight diff: 1768.3607177734\nclient_6 Layer 129 weight diff: 2.2477149963\nclient_6 Layer 130 weight diff: 2.0699179173\nclient_6 Layer 131 weight diff: 10.0042886734\nclient_6 Layer 132 weight diff: 6.5158777237\nclient_6 Layer 133 weight diff: 21.4799137115\nclient_6 Layer 134 weight diff: 1732.5133056641\nclient_6 Layer 135 weight diff: 2.3532302380\nclient_6 Layer 136 weight diff: 2.3542561531\nclient_6 Layer 137 weight diff: 53.2684326172\nclient_6 Layer 138 weight diff: 58.3447227478\nclient_6 Layer 139 weight diff: 20.9454975128\nclient_6 Layer 140 weight diff: 1699.2829589844\nclient_6 Layer 141 weight diff: 2.2547621727\nclient_6 Layer 142 weight diff: 2.3465001583\nclient_6 Layer 143 weight diff: 17.1611804962\nclient_6 Layer 144 weight diff: 14.8381986618\nclient_6 Layer 145 weight diff: 19.9496345520\nclient_6 Layer 146 weight diff: 1698.7196044922\nclient_6 Layer 147 weight diff: 2.3619389534\nclient_6 Layer 148 weight diff: 2.1352694035\nclient_6 Layer 149 weight diff: 20.3044052124\nclient_6 Layer 150 weight diff: 24.8514595032\nclient_6 Layer 151 weight diff: 23.0058097839\nclient_6 Layer 152 weight diff: 1769.0861816406\nclient_6 Layer 153 weight diff: 2.3798232079\nclient_6 Layer 154 weight diff: 2.3966603279\nclient_6 Layer 155 weight diff: 39.2198257446\nclient_6 Layer 156 weight diff: 43.0420074463\nclient_6 Layer 157 weight diff: 21.2749023438\nclient_6 Layer 158 weight diff: 1749.7161865234\nclient_6 Layer 159 weight diff: 2.3317804337\nclient_6 Layer 160 weight diff: 2.3188433647\nclient_6 Layer 161 weight diff: 14.1772174835\nclient_6 Layer 162 weight diff: 12.6688814163\nclient_6 Layer 163 weight diff: 21.0034027100\nclient_6 Layer 164 weight diff: 1724.0446777344\nclient_6 Layer 165 weight diff: 2.2225174904\nclient_6 Layer 166 weight diff: 2.1599903107\nclient_6 Layer 167 weight diff: 10.3714160919\nclient_6 Layer 168 weight diff: 11.8480501175\nclient_6 Layer 169 weight diff: 21.5165061951\nclient_6 Layer 170 weight diff: 1715.3845214844\nclient_6 Layer 171 weight diff: 2.3985195160\nclient_6 Layer 172 weight diff: 2.4266979694\nclient_6 Layer 173 weight diff: 44.0649871826\nclient_6 Layer 174 weight diff: 66.5539855957\nclient_6 Layer 175 weight diff: 21.3545036316\nclient_6 Layer 176 weight diff: 1694.0810546875\nclient_6 Layer 177 weight diff: 2.3093500137\nclient_6 Layer 178 weight diff: 2.3583559990\nclient_6 Layer 179 weight diff: 16.1356105804\nclient_6 Layer 180 weight diff: 21.5829811096\nclient_6 Layer 181 weight diff: 20.2069778442\nclient_6 Layer 182 weight diff: 1672.5528564453\nclient_6 Layer 183 weight diff: 2.2965416908\nclient_6 Layer 184 weight diff: 2.1895043850\nclient_6 Layer 185 weight diff: 11.6237831116\nclient_6 Layer 186 weight diff: 14.7136869431\nclient_6 Layer 187 weight diff: 21.4498786926\nclient_6 Layer 188 weight diff: 1707.2958984375\nclient_6 Layer 189 weight diff: 2.4303941727\nclient_6 Layer 190 weight diff: 2.4213979244\nclient_6 Layer 191 weight diff: 59.8093643188\nclient_6 Layer 192 weight diff: 90.5320129395\nclient_6 Layer 193 weight diff: 21.2615394592\nclient_6 Layer 194 weight diff: 1668.0083007812\nclient_6 Layer 195 weight diff: 2.2304615974\nclient_6 Layer 196 weight diff: 2.2279891968\nclient_6 Layer 197 weight diff: 22.2709655762\nclient_6 Layer 198 weight diff: 50.0581512451\nclient_6 Layer 199 weight diff: 20.1071777344\nclient_6 Layer 200 weight diff: 1625.8449707031\nclient_6 Layer 201 weight diff: 2.2275314331\nclient_6 Layer 202 weight diff: 2.1924364567\nclient_6 Layer 203 weight diff: 15.2960596085\nclient_6 Layer 204 weight diff: 22.0968437195\nclient_6 Layer 205 weight diff: 19.8164424896\nclient_6 Layer 206 weight diff: 1671.3537597656\nclient_6 Layer 207 weight diff: 2.1390848160\nclient_6 Layer 208 weight diff: 2.1017792225\nclient_6 Layer 209 weight diff: 105.3843002319\nclient_6 Layer 210 weight diff: 432.9158935547\nclient_6 Layer 211 weight diff: 20.2930526733\nclient_6 Layer 212 weight diff: 2292.2971191406\nclient_6 Layer 213 weight diff: 3.1231908798\nclient_6 Layer 214 weight diff: 2.9241280556\nclient_6 Layer 215 weight diff: 44.5356407166\nclient_6 Layer 216 weight diff: 39.7262878418\nclient_6 Layer 217 weight diff: 2333.0456542969\nclient_6 Layer 218 weight diff: 3.0348410606\nclient_6 Layer 219 weight diff: 2.9241285324\nclient_6 Layer 220 weight diff: 1032.9442138672\nclient_6 Layer 221 weight diff: 38846.2031250000\nclient_6 Layer 222 weight diff: 29.0441684723\nclient_6 Layer 223 weight diff: 4884.0615234375\nclient_6 Layer 224 weight diff: 4.5922183990\nclient_6 Layer 225 weight diff: 4.7132797241\nclient_6 Layer 226 weight diff: 183.5020751953\nclient_6 Layer 227 weight diff: 615.2651367188\nclient_6 Layer 228 weight diff: 40.5542640686\nclient_6 Layer 229 weight diff: 8784.8115234375\nclient_6 Layer 230 weight diff: 5.1662096977\nclient_6 Layer 231 weight diff: 5.2220129967\nclient_6 Layer 232 weight diff: 251.2359008789\nclient_6 Layer 233 weight diff: 479.4106445312\nclient_6 Layer 234 weight diff: 0.0000000000\nclient_6 Layer 235 weight diff: 0.0000000000\nclient_6 Layer 236 weight diff: 0.0000000000\nclient_6 Layer 237 weight diff: 0.0000000000\nclient_6 training accuracy history: [0.8957894444465637, 0.9473684430122375, 0.9663158059120178, 0.9778947234153748, 0.9863157868385315]\nclient_6 total local-global weight diff: 98375.79607034\n\n✅ Round 2 average client accuracy: 0.9876\n\n📈 Global model evaluation on test data: {'loss': 0.12818098068237305, 'compile_metrics': 0.9717772603034973}\n\n🔁 Federated Round 3\n\n📶 Training on client_1\nTraining client_1 for 5 epochs...\nSum of weights before training: 177500.594\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 907ms/step - accuracy: 0.9455 - loss: 0.2424 - precision_31: 0.9490 - recall_31: 0.9426\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 652ms/step - accuracy: 0.9687 - loss: 0.1042 - precision_31: 0.9755 - recall_31: 0.9655\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 665ms/step - accuracy: 0.9873 - loss: 0.0451 - precision_31: 0.9890 - recall_31: 0.9860\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 643ms/step - accuracy: 0.9773 - loss: 0.0626 - precision_31: 0.9779 - recall_31: 0.9738\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 668ms/step - accuracy: 0.9839 - loss: 0.0348 - precision_31: 0.9843 - recall_31: 0.9839\nSum of weights after training: 193355.109\nclient_1 Layer 0 weight diff: 0.0000000000\nclient_1 Layer 1 weight diff: 0.0000000000\nclient_1 Layer 2 weight diff: 0.0000000000\nclient_1 Layer 3 weight diff: 0.0000000000\nclient_1 Layer 4 weight diff: 0.0000000000\nclient_1 Layer 5 weight diff: 0.0000000000\nclient_1 Layer 6 weight diff: 0.0000000000\nclient_1 Layer 7 weight diff: 0.0000000000\nclient_1 Layer 8 weight diff: 0.0000000000\nclient_1 Layer 9 weight diff: 0.0000000000\nclient_1 Layer 10 weight diff: 0.0000000000\nclient_1 Layer 11 weight diff: 0.0000000000\nclient_1 Layer 12 weight diff: 0.0000000000\nclient_1 Layer 13 weight diff: 0.0000000000\nclient_1 Layer 14 weight diff: 0.0000000000\nclient_1 Layer 15 weight diff: 0.0000000000\nclient_1 Layer 16 weight diff: 0.0000000000\nclient_1 Layer 17 weight diff: 0.0000000000\nclient_1 Layer 18 weight diff: 0.0000000000\nclient_1 Layer 19 weight diff: 0.0000000000\nclient_1 Layer 20 weight diff: 0.0000000000\nclient_1 Layer 21 weight diff: 0.0000000000\nclient_1 Layer 22 weight diff: 0.0000000000\nclient_1 Layer 23 weight diff: 0.0000000000\nclient_1 Layer 24 weight diff: 0.0000000000\nclient_1 Layer 25 weight diff: 0.0000000000\nclient_1 Layer 26 weight diff: 0.0000000000\nclient_1 Layer 27 weight diff: 0.0000000000\nclient_1 Layer 28 weight diff: 0.0000000000\nclient_1 Layer 29 weight diff: 0.0000000000\nclient_1 Layer 30 weight diff: 0.0000000000\nclient_1 Layer 31 weight diff: 0.0000000000\nclient_1 Layer 32 weight diff: 0.0000000000\nclient_1 Layer 33 weight diff: 0.0000000000\nclient_1 Layer 34 weight diff: 0.0000000000\nclient_1 Layer 35 weight diff: 0.0000000000\nclient_1 Layer 36 weight diff: 0.0000000000\nclient_1 Layer 37 weight diff: 0.0000000000\nclient_1 Layer 38 weight diff: 0.0000000000\nclient_1 Layer 39 weight diff: 0.0000000000\nclient_1 Layer 40 weight diff: 0.0000000000\nclient_1 Layer 41 weight diff: 0.0000000000\nclient_1 Layer 42 weight diff: 0.0000000000\nclient_1 Layer 43 weight diff: 0.0000000000\nclient_1 Layer 44 weight diff: 0.0000000000\nclient_1 Layer 45 weight diff: 0.0000000000\nclient_1 Layer 46 weight diff: 0.0000000000\nclient_1 Layer 47 weight diff: 0.0000000000\nclient_1 Layer 48 weight diff: 0.0000000000\nclient_1 Layer 49 weight diff: 0.0000000000\nclient_1 Layer 50 weight diff: 0.0000000000\nclient_1 Layer 51 weight diff: 0.0000000000\nclient_1 Layer 52 weight diff: 0.0000000000\nclient_1 Layer 53 weight diff: 0.0000000000\nclient_1 Layer 54 weight diff: 0.0000000000\nclient_1 Layer 55 weight diff: 0.0000000000\nclient_1 Layer 56 weight diff: 0.0000000000\nclient_1 Layer 57 weight diff: 0.0000000000\nclient_1 Layer 58 weight diff: 0.0000000000\nclient_1 Layer 59 weight diff: 0.0000000000\nclient_1 Layer 60 weight diff: 0.0000000000\nclient_1 Layer 61 weight diff: 0.0000000000\nclient_1 Layer 62 weight diff: 0.0000000000\nclient_1 Layer 63 weight diff: 0.0000000000\nclient_1 Layer 64 weight diff: 0.0000000000\nclient_1 Layer 65 weight diff: 0.0000000000\nclient_1 Layer 66 weight diff: 0.0000000000\nclient_1 Layer 67 weight diff: 0.0000000000\nclient_1 Layer 68 weight diff: 0.0000000000\nclient_1 Layer 69 weight diff: 0.0000000000\nclient_1 Layer 70 weight diff: 0.0000000000\nclient_1 Layer 71 weight diff: 0.0000000000\nclient_1 Layer 72 weight diff: 0.0000000000\nclient_1 Layer 73 weight diff: 0.0000000000\nclient_1 Layer 74 weight diff: 0.0000000000\nclient_1 Layer 75 weight diff: 0.0000000000\nclient_1 Layer 76 weight diff: 0.0000000000\nclient_1 Layer 77 weight diff: 0.0000000000\nclient_1 Layer 78 weight diff: 0.0000000000\nclient_1 Layer 79 weight diff: 0.0000000000\nclient_1 Layer 80 weight diff: 0.0000000000\nclient_1 Layer 81 weight diff: 0.0000000000\nclient_1 Layer 82 weight diff: 0.0000000000\nclient_1 Layer 83 weight diff: 0.0000000000\nclient_1 Layer 84 weight diff: 0.0000000000\nclient_1 Layer 85 weight diff: 15.6344013214\nclient_1 Layer 86 weight diff: 1279.8441162109\nclient_1 Layer 87 weight diff: 1.5965797901\nclient_1 Layer 88 weight diff: 1.6828300953\nclient_1 Layer 89 weight diff: 15.5615167618\nclient_1 Layer 90 weight diff: 9.3891887665\nclient_1 Layer 91 weight diff: 15.0908832550\nclient_1 Layer 92 weight diff: 1296.6914062500\nclient_1 Layer 93 weight diff: 1.8184940815\nclient_1 Layer 94 weight diff: 1.7010973692\nclient_1 Layer 95 weight diff: 13.2520227432\nclient_1 Layer 96 weight diff: 34.2482147217\nclient_1 Layer 97 weight diff: 16.4790325165\nclient_1 Layer 98 weight diff: 1314.9151611328\nclient_1 Layer 99 weight diff: 1.7465672493\nclient_1 Layer 100 weight diff: 1.7410469055\nclient_1 Layer 101 weight diff: 29.4516220093\nclient_1 Layer 102 weight diff: 31.9836483002\nclient_1 Layer 103 weight diff: 15.9852600098\nclient_1 Layer 104 weight diff: 1336.8625488281\nclient_1 Layer 105 weight diff: 1.7206752300\nclient_1 Layer 106 weight diff: 1.7390145063\nclient_1 Layer 107 weight diff: 9.2561826706\nclient_1 Layer 108 weight diff: 7.7061820030\nclient_1 Layer 109 weight diff: 16.0045433044\nclient_1 Layer 110 weight diff: 1353.7220458984\nclient_1 Layer 111 weight diff: 1.8391277790\nclient_1 Layer 112 weight diff: 1.6676797867\nclient_1 Layer 113 weight diff: 6.5711355209\nclient_1 Layer 114 weight diff: 22.4469585419\nclient_1 Layer 115 weight diff: 16.6443710327\nclient_1 Layer 116 weight diff: 1362.1241455078\nclient_1 Layer 117 weight diff: 1.7378695011\nclient_1 Layer 118 weight diff: 1.7395851612\nclient_1 Layer 119 weight diff: 18.5887832642\nclient_1 Layer 120 weight diff: 35.2763442993\nclient_1 Layer 121 weight diff: 16.3901062012\nclient_1 Layer 122 weight diff: 1359.1840820312\nclient_1 Layer 123 weight diff: 1.7871316671\nclient_1 Layer 124 weight diff: 1.7942199707\nclient_1 Layer 125 weight diff: 9.2635784149\nclient_1 Layer 126 weight diff: 6.6760578156\nclient_1 Layer 127 weight diff: 16.3109722137\nclient_1 Layer 128 weight diff: 1363.2629394531\nclient_1 Layer 129 weight diff: 1.8188468218\nclient_1 Layer 130 weight diff: 1.6775497198\nclient_1 Layer 131 weight diff: 8.7575569153\nclient_1 Layer 132 weight diff: 7.6084060669\nclient_1 Layer 133 weight diff: 16.5740623474\nclient_1 Layer 134 weight diff: 1342.3138427734\nclient_1 Layer 135 weight diff: 1.7161225080\nclient_1 Layer 136 weight diff: 1.6504774094\nclient_1 Layer 137 weight diff: 32.6578483582\nclient_1 Layer 138 weight diff: 29.7535896301\nclient_1 Layer 139 weight diff: 15.8180923462\nclient_1 Layer 140 weight diff: 1333.8729248047\nclient_1 Layer 141 weight diff: 1.7560291290\nclient_1 Layer 142 weight diff: 1.7532024384\nclient_1 Layer 143 weight diff: 14.5561323166\nclient_1 Layer 144 weight diff: 8.2399415970\nclient_1 Layer 145 weight diff: 15.7538022995\nclient_1 Layer 146 weight diff: 1325.5979003906\nclient_1 Layer 147 weight diff: 1.7132616043\nclient_1 Layer 148 weight diff: 1.7082095146\nclient_1 Layer 149 weight diff: 14.7203378677\nclient_1 Layer 150 weight diff: 10.2534618378\nclient_1 Layer 151 weight diff: 17.3298110962\nclient_1 Layer 152 weight diff: 1363.4244384766\nclient_1 Layer 153 weight diff: 1.7601850033\nclient_1 Layer 154 weight diff: 1.7578344345\nclient_1 Layer 155 weight diff: 27.0364723206\nclient_1 Layer 156 weight diff: 28.3010406494\nclient_1 Layer 157 weight diff: 16.6106300354\nclient_1 Layer 158 weight diff: 1353.5335693359\nclient_1 Layer 159 weight diff: 1.7585537434\nclient_1 Layer 160 weight diff: 1.7504210472\nclient_1 Layer 161 weight diff: 10.9252471924\nclient_1 Layer 162 weight diff: 8.8151359558\nclient_1 Layer 163 weight diff: 16.0047111511\nclient_1 Layer 164 weight diff: 1341.9565429688\nclient_1 Layer 165 weight diff: 1.7461463213\nclient_1 Layer 166 weight diff: 1.7125096321\nclient_1 Layer 167 weight diff: 7.9805822372\nclient_1 Layer 168 weight diff: 9.2760181427\nclient_1 Layer 169 weight diff: 16.4923343658\nclient_1 Layer 170 weight diff: 1340.1958007812\nclient_1 Layer 171 weight diff: 1.7193996906\nclient_1 Layer 172 weight diff: 1.7737408876\nclient_1 Layer 173 weight diff: 30.5204753876\nclient_1 Layer 174 weight diff: 38.1888237000\nclient_1 Layer 175 weight diff: 15.2941474915\nclient_1 Layer 176 weight diff: 1317.4177246094\nclient_1 Layer 177 weight diff: 1.7437566519\nclient_1 Layer 178 weight diff: 1.7369248867\nclient_1 Layer 179 weight diff: 12.8615875244\nclient_1 Layer 180 weight diff: 22.0354423523\nclient_1 Layer 181 weight diff: 15.6630725861\nclient_1 Layer 182 weight diff: 1317.4938964844\nclient_1 Layer 183 weight diff: 1.6614758968\nclient_1 Layer 184 weight diff: 1.6903902292\nclient_1 Layer 185 weight diff: 8.1690692902\nclient_1 Layer 186 weight diff: 11.8325719833\nclient_1 Layer 187 weight diff: 15.6142749786\nclient_1 Layer 188 weight diff: 1319.0827636719\nclient_1 Layer 189 weight diff: 1.5987601280\nclient_1 Layer 190 weight diff: 1.6855080128\nclient_1 Layer 191 weight diff: 36.8101119995\nclient_1 Layer 192 weight diff: 57.0413551331\nclient_1 Layer 193 weight diff: 15.1665267944\nclient_1 Layer 194 weight diff: 1298.6264648438\nclient_1 Layer 195 weight diff: 1.7024815083\nclient_1 Layer 196 weight diff: 1.6834781170\nclient_1 Layer 197 weight diff: 17.7511100769\nclient_1 Layer 198 weight diff: 34.1455574036\nclient_1 Layer 199 weight diff: 14.9784440994\nclient_1 Layer 200 weight diff: 1287.2373046875\nclient_1 Layer 201 weight diff: 1.7240283489\nclient_1 Layer 202 weight diff: 1.6787784100\nclient_1 Layer 203 weight diff: 10.8959636688\nclient_1 Layer 204 weight diff: 22.6459083557\nclient_1 Layer 205 weight diff: 15.5483798981\nclient_1 Layer 206 weight diff: 1342.5013427734\nclient_1 Layer 207 weight diff: 1.6143950224\nclient_1 Layer 208 weight diff: 1.6273829937\nclient_1 Layer 209 weight diff: 84.7330017090\nclient_1 Layer 210 weight diff: 286.6884155273\nclient_1 Layer 211 weight diff: 15.8125705719\nclient_1 Layer 212 weight diff: 1825.2340087891\nclient_1 Layer 213 weight diff: 2.3781981468\nclient_1 Layer 214 weight diff: 2.3198595047\nclient_1 Layer 215 weight diff: 27.5725536346\nclient_1 Layer 216 weight diff: 19.0692481995\nclient_1 Layer 217 weight diff: 1814.4940185547\nclient_1 Layer 218 weight diff: 2.4891786575\nclient_1 Layer 219 weight diff: 2.3198590279\nclient_1 Layer 220 weight diff: 789.8184814453\nclient_1 Layer 221 weight diff: 25043.7265625000\nclient_1 Layer 222 weight diff: 22.4958419800\nclient_1 Layer 223 weight diff: 3944.9404296875\nclient_1 Layer 224 weight diff: 3.4773874283\nclient_1 Layer 225 weight diff: 3.5035195351\nclient_1 Layer 226 weight diff: 182.6956939697\nclient_1 Layer 227 weight diff: 438.0116577148\nclient_1 Layer 228 weight diff: 32.8704757690\nclient_1 Layer 229 weight diff: 7419.2148437500\nclient_1 Layer 230 weight diff: 4.7383871078\nclient_1 Layer 231 weight diff: 5.2228040695\nclient_1 Layer 232 weight diff: 287.9049072266\nclient_1 Layer 233 weight diff: 707.6179199219\nclient_1 Layer 234 weight diff: 0.0000000000\nclient_1 Layer 235 weight diff: 0.0000000000\nclient_1 Layer 236 weight diff: 0.0000000000\nclient_1 Layer 237 weight diff: 0.0000000000\nclient_1 training accuracy history: [0.9423480033874512, 0.9706498980522156, 0.9895178079605103, 0.9790356159210205, 0.9853249192237854]\nclient_1 total local-global weight diff: 72098.28159869\n\n📶 Training on client_2\nTraining client_2 for 5 epochs...\nSum of weights before training: 177500.594\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 920ms/step - accuracy: 0.9166 - loss: 0.3563 - precision_32: 0.9297 - recall_32: 0.9029\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 703ms/step - accuracy: 0.9687 - loss: 0.0961 - precision_32: 0.9724 - recall_32: 0.9641\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 657ms/step - accuracy: 0.9894 - loss: 0.0419 - precision_32: 0.9918 - recall_32: 0.9857\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 635ms/step - accuracy: 0.9898 - loss: 0.0341 - precision_32: 0.9939 - recall_32: 0.9851\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 655ms/step - accuracy: 0.9958 - loss: 0.0078 - precision_32: 0.9958 - recall_32: 0.9958\nSum of weights after training: 191777.438\nclient_2 Layer 0 weight diff: 0.0000000000\nclient_2 Layer 1 weight diff: 0.0000000000\nclient_2 Layer 2 weight diff: 0.0000000000\nclient_2 Layer 3 weight diff: 0.0000000000\nclient_2 Layer 4 weight diff: 0.0000000000\nclient_2 Layer 5 weight diff: 0.0000000000\nclient_2 Layer 6 weight diff: 0.0000000000\nclient_2 Layer 7 weight diff: 0.0000000000\nclient_2 Layer 8 weight diff: 0.0000000000\nclient_2 Layer 9 weight diff: 0.0000000000\nclient_2 Layer 10 weight diff: 0.0000000000\nclient_2 Layer 11 weight diff: 0.0000000000\nclient_2 Layer 12 weight diff: 0.0000000000\nclient_2 Layer 13 weight diff: 0.0000000000\nclient_2 Layer 14 weight diff: 0.0000000000\nclient_2 Layer 15 weight diff: 0.0000000000\nclient_2 Layer 16 weight diff: 0.0000000000\nclient_2 Layer 17 weight diff: 0.0000000000\nclient_2 Layer 18 weight diff: 0.0000000000\nclient_2 Layer 19 weight diff: 0.0000000000\nclient_2 Layer 20 weight diff: 0.0000000000\nclient_2 Layer 21 weight diff: 0.0000000000\nclient_2 Layer 22 weight diff: 0.0000000000\nclient_2 Layer 23 weight diff: 0.0000000000\nclient_2 Layer 24 weight diff: 0.0000000000\nclient_2 Layer 25 weight diff: 0.0000000000\nclient_2 Layer 26 weight diff: 0.0000000000\nclient_2 Layer 27 weight diff: 0.0000000000\nclient_2 Layer 28 weight diff: 0.0000000000\nclient_2 Layer 29 weight diff: 0.0000000000\nclient_2 Layer 30 weight diff: 0.0000000000\nclient_2 Layer 31 weight diff: 0.0000000000\nclient_2 Layer 32 weight diff: 0.0000000000\nclient_2 Layer 33 weight diff: 0.0000000000\nclient_2 Layer 34 weight diff: 0.0000000000\nclient_2 Layer 35 weight diff: 0.0000000000\nclient_2 Layer 36 weight diff: 0.0000000000\nclient_2 Layer 37 weight diff: 0.0000000000\nclient_2 Layer 38 weight diff: 0.0000000000\nclient_2 Layer 39 weight diff: 0.0000000000\nclient_2 Layer 40 weight diff: 0.0000000000\nclient_2 Layer 41 weight diff: 0.0000000000\nclient_2 Layer 42 weight diff: 0.0000000000\nclient_2 Layer 43 weight diff: 0.0000000000\nclient_2 Layer 44 weight diff: 0.0000000000\nclient_2 Layer 45 weight diff: 0.0000000000\nclient_2 Layer 46 weight diff: 0.0000000000\nclient_2 Layer 47 weight diff: 0.0000000000\nclient_2 Layer 48 weight diff: 0.0000000000\nclient_2 Layer 49 weight diff: 0.0000000000\nclient_2 Layer 50 weight diff: 0.0000000000\nclient_2 Layer 51 weight diff: 0.0000000000\nclient_2 Layer 52 weight diff: 0.0000000000\nclient_2 Layer 53 weight diff: 0.0000000000\nclient_2 Layer 54 weight diff: 0.0000000000\nclient_2 Layer 55 weight diff: 0.0000000000\nclient_2 Layer 56 weight diff: 0.0000000000\nclient_2 Layer 57 weight diff: 0.0000000000\nclient_2 Layer 58 weight diff: 0.0000000000\nclient_2 Layer 59 weight diff: 0.0000000000\nclient_2 Layer 60 weight diff: 0.0000000000\nclient_2 Layer 61 weight diff: 0.0000000000\nclient_2 Layer 62 weight diff: 0.0000000000\nclient_2 Layer 63 weight diff: 0.0000000000\nclient_2 Layer 64 weight diff: 0.0000000000\nclient_2 Layer 65 weight diff: 0.0000000000\nclient_2 Layer 66 weight diff: 0.0000000000\nclient_2 Layer 67 weight diff: 0.0000000000\nclient_2 Layer 68 weight diff: 0.0000000000\nclient_2 Layer 69 weight diff: 0.0000000000\nclient_2 Layer 70 weight diff: 0.0000000000\nclient_2 Layer 71 weight diff: 0.0000000000\nclient_2 Layer 72 weight diff: 0.0000000000\nclient_2 Layer 73 weight diff: 0.0000000000\nclient_2 Layer 74 weight diff: 0.0000000000\nclient_2 Layer 75 weight diff: 0.0000000000\nclient_2 Layer 76 weight diff: 0.0000000000\nclient_2 Layer 77 weight diff: 0.0000000000\nclient_2 Layer 78 weight diff: 0.0000000000\nclient_2 Layer 79 weight diff: 0.0000000000\nclient_2 Layer 80 weight diff: 0.0000000000\nclient_2 Layer 81 weight diff: 0.0000000000\nclient_2 Layer 82 weight diff: 0.0000000000\nclient_2 Layer 83 weight diff: 0.0000000000\nclient_2 Layer 84 weight diff: 0.0000000000\nclient_2 Layer 85 weight diff: 16.4277935028\nclient_2 Layer 86 weight diff: 1363.3715820312\nclient_2 Layer 87 weight diff: 1.7991673946\nclient_2 Layer 88 weight diff: 1.8133345842\nclient_2 Layer 89 weight diff: 14.7374868393\nclient_2 Layer 90 weight diff: 8.2557735443\nclient_2 Layer 91 weight diff: 15.9121580124\nclient_2 Layer 92 weight diff: 1398.6252441406\nclient_2 Layer 93 weight diff: 1.8395917416\nclient_2 Layer 94 weight diff: 1.9570660591\nclient_2 Layer 95 weight diff: 15.0098323822\nclient_2 Layer 96 weight diff: 35.7807006836\nclient_2 Layer 97 weight diff: 18.0131149292\nclient_2 Layer 98 weight diff: 1446.1414794922\nclient_2 Layer 99 weight diff: 1.9403973818\nclient_2 Layer 100 weight diff: 1.9859111309\nclient_2 Layer 101 weight diff: 33.1942443848\nclient_2 Layer 102 weight diff: 31.8777046204\nclient_2 Layer 103 weight diff: 17.1671867371\nclient_2 Layer 104 weight diff: 1442.9890136719\nclient_2 Layer 105 weight diff: 1.9628570080\nclient_2 Layer 106 weight diff: 2.0138158798\nclient_2 Layer 107 weight diff: 8.6512594223\nclient_2 Layer 108 weight diff: 8.5748233795\nclient_2 Layer 109 weight diff: 17.4867630005\nclient_2 Layer 110 weight diff: 1429.9227294922\nclient_2 Layer 111 weight diff: 1.8995279074\nclient_2 Layer 112 weight diff: 1.7948433161\nclient_2 Layer 113 weight diff: 7.3233623505\nclient_2 Layer 114 weight diff: 23.3533744812\nclient_2 Layer 115 weight diff: 17.5831222534\nclient_2 Layer 116 weight diff: 1464.1984863281\nclient_2 Layer 117 weight diff: 1.9138157368\nclient_2 Layer 118 weight diff: 2.0296127796\nclient_2 Layer 119 weight diff: 20.9133720398\nclient_2 Layer 120 weight diff: 35.7000274658\nclient_2 Layer 121 weight diff: 17.6538829803\nclient_2 Layer 122 weight diff: 1453.3012695312\nclient_2 Layer 123 weight diff: 1.8663499355\nclient_2 Layer 124 weight diff: 1.9313552380\nclient_2 Layer 125 weight diff: 10.4466533661\nclient_2 Layer 126 weight diff: 5.5673437119\nclient_2 Layer 127 weight diff: 17.4616565704\nclient_2 Layer 128 weight diff: 1442.7851562500\nclient_2 Layer 129 weight diff: 1.8996851444\nclient_2 Layer 130 weight diff: 1.8056941032\nclient_2 Layer 131 weight diff: 8.0894079208\nclient_2 Layer 132 weight diff: 5.7612771988\nclient_2 Layer 133 weight diff: 17.1392211914\nclient_2 Layer 134 weight diff: 1421.9570312500\nclient_2 Layer 135 weight diff: 1.7630009651\nclient_2 Layer 136 weight diff: 1.7677092552\nclient_2 Layer 137 weight diff: 36.6529235840\nclient_2 Layer 138 weight diff: 36.4533538818\nclient_2 Layer 139 weight diff: 16.7752838135\nclient_2 Layer 140 weight diff: 1415.2449951172\nclient_2 Layer 141 weight diff: 1.8416045904\nclient_2 Layer 142 weight diff: 1.8015954494\nclient_2 Layer 143 weight diff: 18.8542938232\nclient_2 Layer 144 weight diff: 10.3177747726\nclient_2 Layer 145 weight diff: 16.7284202576\nclient_2 Layer 146 weight diff: 1417.8405761719\nclient_2 Layer 147 weight diff: 1.8650972843\nclient_2 Layer 148 weight diff: 1.8164622784\nclient_2 Layer 149 weight diff: 18.5104770660\nclient_2 Layer 150 weight diff: 18.3446807861\nclient_2 Layer 151 weight diff: 18.6250267029\nclient_2 Layer 152 weight diff: 1459.0898437500\nclient_2 Layer 153 weight diff: 2.0058913231\nclient_2 Layer 154 weight diff: 1.9125471115\nclient_2 Layer 155 weight diff: 33.1619415283\nclient_2 Layer 156 weight diff: 40.7102317810\nclient_2 Layer 157 weight diff: 18.4281158447\nclient_2 Layer 158 weight diff: 1446.8381347656\nclient_2 Layer 159 weight diff: 1.9624152184\nclient_2 Layer 160 weight diff: 1.9582545757\nclient_2 Layer 161 weight diff: 12.3041229248\nclient_2 Layer 162 weight diff: 15.5173530579\nclient_2 Layer 163 weight diff: 16.8685607910\nclient_2 Layer 164 weight diff: 1424.6826171875\nclient_2 Layer 165 weight diff: 1.8990962505\nclient_2 Layer 166 weight diff: 1.8825135231\nclient_2 Layer 167 weight diff: 8.9578533173\nclient_2 Layer 168 weight diff: 15.0056514740\nclient_2 Layer 169 weight diff: 18.1935939789\nclient_2 Layer 170 weight diff: 1451.4716796875\nclient_2 Layer 171 weight diff: 2.0440738201\nclient_2 Layer 172 weight diff: 2.0294089317\nclient_2 Layer 173 weight diff: 36.4753952026\nclient_2 Layer 174 weight diff: 54.5076828003\nclient_2 Layer 175 weight diff: 17.7948646545\nclient_2 Layer 176 weight diff: 1423.4594726562\nclient_2 Layer 177 weight diff: 1.8505406380\nclient_2 Layer 178 weight diff: 1.8516067266\nclient_2 Layer 179 weight diff: 16.7810821533\nclient_2 Layer 180 weight diff: 25.1957168579\nclient_2 Layer 181 weight diff: 17.1512641907\nclient_2 Layer 182 weight diff: 1402.3869628906\nclient_2 Layer 183 weight diff: 1.9106676579\nclient_2 Layer 184 weight diff: 1.9199609756\nclient_2 Layer 185 weight diff: 9.0464859009\nclient_2 Layer 186 weight diff: 9.6630153656\nclient_2 Layer 187 weight diff: 17.6510925293\nclient_2 Layer 188 weight diff: 1409.5065917969\nclient_2 Layer 189 weight diff: 1.8216805458\nclient_2 Layer 190 weight diff: 1.8754818439\nclient_2 Layer 191 weight diff: 43.5516433716\nclient_2 Layer 192 weight diff: 66.7977905273\nclient_2 Layer 193 weight diff: 16.6865348816\nclient_2 Layer 194 weight diff: 1401.0850830078\nclient_2 Layer 195 weight diff: 1.8792233467\nclient_2 Layer 196 weight diff: 1.8631680012\nclient_2 Layer 197 weight diff: 19.9993057251\nclient_2 Layer 198 weight diff: 41.0698394775\nclient_2 Layer 199 weight diff: 16.8565196991\nclient_2 Layer 200 weight diff: 1353.9370117188\nclient_2 Layer 201 weight diff: 1.8963568211\nclient_2 Layer 202 weight diff: 1.7575467825\nclient_2 Layer 203 weight diff: 12.3331193924\nclient_2 Layer 204 weight diff: 28.0689086914\nclient_2 Layer 205 weight diff: 16.7964897156\nclient_2 Layer 206 weight diff: 1424.1665039062\nclient_2 Layer 207 weight diff: 1.8727245331\nclient_2 Layer 208 weight diff: 1.8826605082\nclient_2 Layer 209 weight diff: 83.4115753174\nclient_2 Layer 210 weight diff: 346.0570678711\nclient_2 Layer 211 weight diff: 17.0805740356\nclient_2 Layer 212 weight diff: 1911.0650634766\nclient_2 Layer 213 weight diff: 2.3525269032\nclient_2 Layer 214 weight diff: 2.3353762627\nclient_2 Layer 215 weight diff: 30.3867187500\nclient_2 Layer 216 weight diff: 26.1361255646\nclient_2 Layer 217 weight diff: 1871.7602539062\nclient_2 Layer 218 weight diff: 2.5325570107\nclient_2 Layer 219 weight diff: 2.3353762627\nclient_2 Layer 220 weight diff: 884.1239013672\nclient_2 Layer 221 weight diff: 24767.3945312500\nclient_2 Layer 222 weight diff: 22.8606014252\nclient_2 Layer 223 weight diff: 4033.7841796875\nclient_2 Layer 224 weight diff: 3.5421128273\nclient_2 Layer 225 weight diff: 3.5696609020\nclient_2 Layer 226 weight diff: 147.5933532715\nclient_2 Layer 227 weight diff: 438.5780029297\nclient_2 Layer 228 weight diff: 33.0779953003\nclient_2 Layer 229 weight diff: 7666.8745117188\nclient_2 Layer 230 weight diff: 4.2230696678\nclient_2 Layer 231 weight diff: 4.4044141769\nclient_2 Layer 232 weight diff: 341.1778564453\nclient_2 Layer 233 weight diff: 750.0554199219\nclient_2 Layer 234 weight diff: 0.0000000000\nclient_2 Layer 235 weight diff: 0.0000000000\nclient_2 Layer 236 weight diff: 0.0000000000\nclient_2 Layer 237 weight diff: 0.0000000000\nclient_2 training accuracy history: [0.9107142686843872, 0.9684873819351196, 0.9831932783126831, 0.9926470518112183, 0.9947478771209717]\nclient_2 total local-global weight diff: 74634.01655889\n\n📶 Training on client_3\nTraining client_3 for 5 epochs...\nSum of weights before training: 177500.594\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 931ms/step - accuracy: 0.9578 - loss: 0.1427 - precision_33: 0.9705 - recall_33: 0.9488\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 692ms/step - accuracy: 0.9882 - loss: 0.0600 - precision_33: 0.9901 - recall_33: 0.9875\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 674ms/step - accuracy: 0.9817 - loss: 0.0552 - precision_33: 0.9816 - recall_33: 0.9778\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 645ms/step - accuracy: 0.9858 - loss: 0.0516 - precision_33: 0.9892 - recall_33: 0.9858\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 673ms/step - accuracy: 0.9910 - loss: 0.0322 - precision_33: 0.9923 - recall_33: 0.9908\nSum of weights after training: 199085.594\nclient_3 Layer 0 weight diff: 0.0000000000\nclient_3 Layer 1 weight diff: 0.0000000000\nclient_3 Layer 2 weight diff: 0.0000000000\nclient_3 Layer 3 weight diff: 0.0000000000\nclient_3 Layer 4 weight diff: 0.0000000000\nclient_3 Layer 5 weight diff: 0.0000000000\nclient_3 Layer 6 weight diff: 0.0000000000\nclient_3 Layer 7 weight diff: 0.0000000000\nclient_3 Layer 8 weight diff: 0.0000000000\nclient_3 Layer 9 weight diff: 0.0000000000\nclient_3 Layer 10 weight diff: 0.0000000000\nclient_3 Layer 11 weight diff: 0.0000000000\nclient_3 Layer 12 weight diff: 0.0000000000\nclient_3 Layer 13 weight diff: 0.0000000000\nclient_3 Layer 14 weight diff: 0.0000000000\nclient_3 Layer 15 weight diff: 0.0000000000\nclient_3 Layer 16 weight diff: 0.0000000000\nclient_3 Layer 17 weight diff: 0.0000000000\nclient_3 Layer 18 weight diff: 0.0000000000\nclient_3 Layer 19 weight diff: 0.0000000000\nclient_3 Layer 20 weight diff: 0.0000000000\nclient_3 Layer 21 weight diff: 0.0000000000\nclient_3 Layer 22 weight diff: 0.0000000000\nclient_3 Layer 23 weight diff: 0.0000000000\nclient_3 Layer 24 weight diff: 0.0000000000\nclient_3 Layer 25 weight diff: 0.0000000000\nclient_3 Layer 26 weight diff: 0.0000000000\nclient_3 Layer 27 weight diff: 0.0000000000\nclient_3 Layer 28 weight diff: 0.0000000000\nclient_3 Layer 29 weight diff: 0.0000000000\nclient_3 Layer 30 weight diff: 0.0000000000\nclient_3 Layer 31 weight diff: 0.0000000000\nclient_3 Layer 32 weight diff: 0.0000000000\nclient_3 Layer 33 weight diff: 0.0000000000\nclient_3 Layer 34 weight diff: 0.0000000000\nclient_3 Layer 35 weight diff: 0.0000000000\nclient_3 Layer 36 weight diff: 0.0000000000\nclient_3 Layer 37 weight diff: 0.0000000000\nclient_3 Layer 38 weight diff: 0.0000000000\nclient_3 Layer 39 weight diff: 0.0000000000\nclient_3 Layer 40 weight diff: 0.0000000000\nclient_3 Layer 41 weight diff: 0.0000000000\nclient_3 Layer 42 weight diff: 0.0000000000\nclient_3 Layer 43 weight diff: 0.0000000000\nclient_3 Layer 44 weight diff: 0.0000000000\nclient_3 Layer 45 weight diff: 0.0000000000\nclient_3 Layer 46 weight diff: 0.0000000000\nclient_3 Layer 47 weight diff: 0.0000000000\nclient_3 Layer 48 weight diff: 0.0000000000\nclient_3 Layer 49 weight diff: 0.0000000000\nclient_3 Layer 50 weight diff: 0.0000000000\nclient_3 Layer 51 weight diff: 0.0000000000\nclient_3 Layer 52 weight diff: 0.0000000000\nclient_3 Layer 53 weight diff: 0.0000000000\nclient_3 Layer 54 weight diff: 0.0000000000\nclient_3 Layer 55 weight diff: 0.0000000000\nclient_3 Layer 56 weight diff: 0.0000000000\nclient_3 Layer 57 weight diff: 0.0000000000\nclient_3 Layer 58 weight diff: 0.0000000000\nclient_3 Layer 59 weight diff: 0.0000000000\nclient_3 Layer 60 weight diff: 0.0000000000\nclient_3 Layer 61 weight diff: 0.0000000000\nclient_3 Layer 62 weight diff: 0.0000000000\nclient_3 Layer 63 weight diff: 0.0000000000\nclient_3 Layer 64 weight diff: 0.0000000000\nclient_3 Layer 65 weight diff: 0.0000000000\nclient_3 Layer 66 weight diff: 0.0000000000\nclient_3 Layer 67 weight diff: 0.0000000000\nclient_3 Layer 68 weight diff: 0.0000000000\nclient_3 Layer 69 weight diff: 0.0000000000\nclient_3 Layer 70 weight diff: 0.0000000000\nclient_3 Layer 71 weight diff: 0.0000000000\nclient_3 Layer 72 weight diff: 0.0000000000\nclient_3 Layer 73 weight diff: 0.0000000000\nclient_3 Layer 74 weight diff: 0.0000000000\nclient_3 Layer 75 weight diff: 0.0000000000\nclient_3 Layer 76 weight diff: 0.0000000000\nclient_3 Layer 77 weight diff: 0.0000000000\nclient_3 Layer 78 weight diff: 0.0000000000\nclient_3 Layer 79 weight diff: 0.0000000000\nclient_3 Layer 80 weight diff: 0.0000000000\nclient_3 Layer 81 weight diff: 0.0000000000\nclient_3 Layer 82 weight diff: 0.0000000000\nclient_3 Layer 83 weight diff: 0.0000000000\nclient_3 Layer 84 weight diff: 0.0000000000\nclient_3 Layer 85 weight diff: 19.0209426880\nclient_3 Layer 86 weight diff: 1457.5610351562\nclient_3 Layer 87 weight diff: 1.8306243420\nclient_3 Layer 88 weight diff: 1.8949820995\nclient_3 Layer 89 weight diff: 17.5130500793\nclient_3 Layer 90 weight diff: 7.4378356934\nclient_3 Layer 91 weight diff: 17.1418914795\nclient_3 Layer 92 weight diff: 1502.6586914062\nclient_3 Layer 93 weight diff: 1.9201560020\nclient_3 Layer 94 weight diff: 2.0228433609\nclient_3 Layer 95 weight diff: 15.2218370438\nclient_3 Layer 96 weight diff: 36.1156997681\nclient_3 Layer 97 weight diff: 20.0989112854\nclient_3 Layer 98 weight diff: 1631.7550048828\nclient_3 Layer 99 weight diff: 2.1457529068\nclient_3 Layer 100 weight diff: 2.2464513779\nclient_3 Layer 101 weight diff: 34.8042449951\nclient_3 Layer 102 weight diff: 33.5541763306\nclient_3 Layer 103 weight diff: 19.3060703278\nclient_3 Layer 104 weight diff: 1609.9707031250\nclient_3 Layer 105 weight diff: 2.0614178181\nclient_3 Layer 106 weight diff: 2.1130170822\nclient_3 Layer 107 weight diff: 9.3023376465\nclient_3 Layer 108 weight diff: 7.5588326454\nclient_3 Layer 109 weight diff: 19.2071685791\nclient_3 Layer 110 weight diff: 1612.8061523438\nclient_3 Layer 111 weight diff: 2.0280246735\nclient_3 Layer 112 weight diff: 2.0147247314\nclient_3 Layer 113 weight diff: 8.7863063812\nclient_3 Layer 114 weight diff: 23.1860370636\nclient_3 Layer 115 weight diff: 19.0349369049\nclient_3 Layer 116 weight diff: 1627.1470947266\nclient_3 Layer 117 weight diff: 2.1595375538\nclient_3 Layer 118 weight diff: 2.1222858429\nclient_3 Layer 119 weight diff: 21.4297637939\nclient_3 Layer 120 weight diff: 32.1605796814\nclient_3 Layer 121 weight diff: 19.9470539093\nclient_3 Layer 122 weight diff: 1597.1693115234\nclient_3 Layer 123 weight diff: 1.9874951839\nclient_3 Layer 124 weight diff: 2.0614795685\nclient_3 Layer 125 weight diff: 11.3568077087\nclient_3 Layer 126 weight diff: 6.2168302536\nclient_3 Layer 127 weight diff: 18.3929882050\nclient_3 Layer 128 weight diff: 1584.2082519531\nclient_3 Layer 129 weight diff: 2.0736761093\nclient_3 Layer 130 weight diff: 2.0223565102\nclient_3 Layer 131 weight diff: 9.4963693619\nclient_3 Layer 132 weight diff: 6.6449975967\nclient_3 Layer 133 weight diff: 18.8972854614\nclient_3 Layer 134 weight diff: 1550.3471679688\nclient_3 Layer 135 weight diff: 2.0186722279\nclient_3 Layer 136 weight diff: 1.9937236309\nclient_3 Layer 137 weight diff: 40.3140640259\nclient_3 Layer 138 weight diff: 33.5927047729\nclient_3 Layer 139 weight diff: 18.1414127350\nclient_3 Layer 140 weight diff: 1520.5195312500\nclient_3 Layer 141 weight diff: 2.0601868629\nclient_3 Layer 142 weight diff: 2.1388559341\nclient_3 Layer 143 weight diff: 16.0145645142\nclient_3 Layer 144 weight diff: 8.5999526978\nclient_3 Layer 145 weight diff: 18.7738132477\nclient_3 Layer 146 weight diff: 1541.6643066406\nclient_3 Layer 147 weight diff: 2.1578896046\nclient_3 Layer 148 weight diff: 2.1153392792\nclient_3 Layer 149 weight diff: 19.7693405151\nclient_3 Layer 150 weight diff: 14.5970897675\nclient_3 Layer 151 weight diff: 20.8510246277\nclient_3 Layer 152 weight diff: 1619.5917968750\nclient_3 Layer 153 weight diff: 2.3356838226\nclient_3 Layer 154 weight diff: 2.3663108349\nclient_3 Layer 155 weight diff: 32.1032218933\nclient_3 Layer 156 weight diff: 31.8988418579\nclient_3 Layer 157 weight diff: 19.7140884399\nclient_3 Layer 158 weight diff: 1586.9659423828\nclient_3 Layer 159 weight diff: 2.0988028049\nclient_3 Layer 160 weight diff: 2.1350407600\nclient_3 Layer 161 weight diff: 13.5616436005\nclient_3 Layer 162 weight diff: 8.3065109253\nclient_3 Layer 163 weight diff: 18.8101463318\nclient_3 Layer 164 weight diff: 1570.4291992188\nclient_3 Layer 165 weight diff: 2.1537494659\nclient_3 Layer 166 weight diff: 2.1123967171\nclient_3 Layer 167 weight diff: 9.2923717499\nclient_3 Layer 168 weight diff: 8.6522426605\nclient_3 Layer 169 weight diff: 20.3554039001\nclient_3 Layer 170 weight diff: 1562.5451660156\nclient_3 Layer 171 weight diff: 2.1104128361\nclient_3 Layer 172 weight diff: 2.1171607971\nclient_3 Layer 173 weight diff: 37.1226196289\nclient_3 Layer 174 weight diff: 48.2970352173\nclient_3 Layer 175 weight diff: 18.6668205261\nclient_3 Layer 176 weight diff: 1517.3852539062\nclient_3 Layer 177 weight diff: 2.0751585960\nclient_3 Layer 178 weight diff: 2.1120901108\nclient_3 Layer 179 weight diff: 14.6607971191\nclient_3 Layer 180 weight diff: 17.1529674530\nclient_3 Layer 181 weight diff: 17.6824798584\nclient_3 Layer 182 weight diff: 1507.1287841797\nclient_3 Layer 183 weight diff: 2.1119124889\nclient_3 Layer 184 weight diff: 2.1240041256\nclient_3 Layer 185 weight diff: 9.2714004517\nclient_3 Layer 186 weight diff: 10.1412992477\nclient_3 Layer 187 weight diff: 19.1532707214\nclient_3 Layer 188 weight diff: 1546.5905761719\nclient_3 Layer 189 weight diff: 2.0182158947\nclient_3 Layer 190 weight diff: 2.0939846039\nclient_3 Layer 191 weight diff: 45.7776412964\nclient_3 Layer 192 weight diff: 68.7084197998\nclient_3 Layer 193 weight diff: 18.9048118591\nclient_3 Layer 194 weight diff: 1511.8691406250\nclient_3 Layer 195 weight diff: 2.1218202114\nclient_3 Layer 196 weight diff: 2.1116201878\nclient_3 Layer 197 weight diff: 22.5781021118\nclient_3 Layer 198 weight diff: 37.6624145508\nclient_3 Layer 199 weight diff: 18.9207057953\nclient_3 Layer 200 weight diff: 1471.4658203125\nclient_3 Layer 201 weight diff: 1.9626431465\nclient_3 Layer 202 weight diff: 2.0350222588\nclient_3 Layer 203 weight diff: 13.3163108826\nclient_3 Layer 204 weight diff: 30.2448863983\nclient_3 Layer 205 weight diff: 18.6346244812\nclient_3 Layer 206 weight diff: 1488.3038330078\nclient_3 Layer 207 weight diff: 2.0020189285\nclient_3 Layer 208 weight diff: 1.9764199257\nclient_3 Layer 209 weight diff: 74.1200103760\nclient_3 Layer 210 weight diff: 228.7110137939\nclient_3 Layer 211 weight diff: 18.6460990906\nclient_3 Layer 212 weight diff: 2038.9041748047\nclient_3 Layer 213 weight diff: 2.7611806393\nclient_3 Layer 214 weight diff: 2.4420890808\nclient_3 Layer 215 weight diff: 34.8449974060\nclient_3 Layer 216 weight diff: 22.5410346985\nclient_3 Layer 217 weight diff: 2013.3070068359\nclient_3 Layer 218 weight diff: 2.6716489792\nclient_3 Layer 219 weight diff: 2.4420890808\nclient_3 Layer 220 weight diff: 904.2174072266\nclient_3 Layer 221 weight diff: 29283.8828125000\nclient_3 Layer 222 weight diff: 25.2339859009\nclient_3 Layer 223 weight diff: 4351.8481445312\nclient_3 Layer 224 weight diff: 3.9127547741\nclient_3 Layer 225 weight diff: 4.0373487473\nclient_3 Layer 226 weight diff: 154.6949462891\nclient_3 Layer 227 weight diff: 353.4159851074\nclient_3 Layer 228 weight diff: 35.6292343140\nclient_3 Layer 229 weight diff: 7650.9204101562\nclient_3 Layer 230 weight diff: 4.9716205597\nclient_3 Layer 231 weight diff: 5.0883932114\nclient_3 Layer 232 weight diff: 254.2841491699\nclient_3 Layer 233 weight diff: 1154.0847167969\nclient_3 Layer 234 weight diff: 0.0000000000\nclient_3 Layer 235 weight diff: 0.0000000000\nclient_3 Layer 236 weight diff: 0.0000000000\nclient_3 Layer 237 weight diff: 0.0000000000\nclient_3 training accuracy history: [0.9464285969734192, 0.9821428656578064, 0.9842436909675598, 0.9852941036224365, 0.9863445162773132]\nclient_3 total local-global weight diff: 82605.13797951\n\n📶 Training on client_4\nTraining client_4 for 5 epochs...\nSum of weights before training: 177500.594\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 953ms/step - accuracy: 0.9464 - loss: 0.2267 - precision_34: 0.9508 - recall_34: 0.9398\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 673ms/step - accuracy: 0.9800 - loss: 0.0932 - precision_34: 0.9821 - recall_34: 0.9766\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 662ms/step - accuracy: 0.9783 - loss: 0.1154 - precision_34: 0.9782 - recall_34: 0.9763\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 627ms/step - accuracy: 0.9943 - loss: 0.0276 - precision_34: 0.9943 - recall_34: 0.9943\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 649ms/step - accuracy: 0.9878 - loss: 0.0345 - precision_34: 0.9887 - recall_34: 0.9865\nSum of weights after training: 198192.047\nclient_4 Layer 0 weight diff: 0.0000000000\nclient_4 Layer 1 weight diff: 0.0000000000\nclient_4 Layer 2 weight diff: 0.0000000000\nclient_4 Layer 3 weight diff: 0.0000000000\nclient_4 Layer 4 weight diff: 0.0000000000\nclient_4 Layer 5 weight diff: 0.0000000000\nclient_4 Layer 6 weight diff: 0.0000000000\nclient_4 Layer 7 weight diff: 0.0000000000\nclient_4 Layer 8 weight diff: 0.0000000000\nclient_4 Layer 9 weight diff: 0.0000000000\nclient_4 Layer 10 weight diff: 0.0000000000\nclient_4 Layer 11 weight diff: 0.0000000000\nclient_4 Layer 12 weight diff: 0.0000000000\nclient_4 Layer 13 weight diff: 0.0000000000\nclient_4 Layer 14 weight diff: 0.0000000000\nclient_4 Layer 15 weight diff: 0.0000000000\nclient_4 Layer 16 weight diff: 0.0000000000\nclient_4 Layer 17 weight diff: 0.0000000000\nclient_4 Layer 18 weight diff: 0.0000000000\nclient_4 Layer 19 weight diff: 0.0000000000\nclient_4 Layer 20 weight diff: 0.0000000000\nclient_4 Layer 21 weight diff: 0.0000000000\nclient_4 Layer 22 weight diff: 0.0000000000\nclient_4 Layer 23 weight diff: 0.0000000000\nclient_4 Layer 24 weight diff: 0.0000000000\nclient_4 Layer 25 weight diff: 0.0000000000\nclient_4 Layer 26 weight diff: 0.0000000000\nclient_4 Layer 27 weight diff: 0.0000000000\nclient_4 Layer 28 weight diff: 0.0000000000\nclient_4 Layer 29 weight diff: 0.0000000000\nclient_4 Layer 30 weight diff: 0.0000000000\nclient_4 Layer 31 weight diff: 0.0000000000\nclient_4 Layer 32 weight diff: 0.0000000000\nclient_4 Layer 33 weight diff: 0.0000000000\nclient_4 Layer 34 weight diff: 0.0000000000\nclient_4 Layer 35 weight diff: 0.0000000000\nclient_4 Layer 36 weight diff: 0.0000000000\nclient_4 Layer 37 weight diff: 0.0000000000\nclient_4 Layer 38 weight diff: 0.0000000000\nclient_4 Layer 39 weight diff: 0.0000000000\nclient_4 Layer 40 weight diff: 0.0000000000\nclient_4 Layer 41 weight diff: 0.0000000000\nclient_4 Layer 42 weight diff: 0.0000000000\nclient_4 Layer 43 weight diff: 0.0000000000\nclient_4 Layer 44 weight diff: 0.0000000000\nclient_4 Layer 45 weight diff: 0.0000000000\nclient_4 Layer 46 weight diff: 0.0000000000\nclient_4 Layer 47 weight diff: 0.0000000000\nclient_4 Layer 48 weight diff: 0.0000000000\nclient_4 Layer 49 weight diff: 0.0000000000\nclient_4 Layer 50 weight diff: 0.0000000000\nclient_4 Layer 51 weight diff: 0.0000000000\nclient_4 Layer 52 weight diff: 0.0000000000\nclient_4 Layer 53 weight diff: 0.0000000000\nclient_4 Layer 54 weight diff: 0.0000000000\nclient_4 Layer 55 weight diff: 0.0000000000\nclient_4 Layer 56 weight diff: 0.0000000000\nclient_4 Layer 57 weight diff: 0.0000000000\nclient_4 Layer 58 weight diff: 0.0000000000\nclient_4 Layer 59 weight diff: 0.0000000000\nclient_4 Layer 60 weight diff: 0.0000000000\nclient_4 Layer 61 weight diff: 0.0000000000\nclient_4 Layer 62 weight diff: 0.0000000000\nclient_4 Layer 63 weight diff: 0.0000000000\nclient_4 Layer 64 weight diff: 0.0000000000\nclient_4 Layer 65 weight diff: 0.0000000000\nclient_4 Layer 66 weight diff: 0.0000000000\nclient_4 Layer 67 weight diff: 0.0000000000\nclient_4 Layer 68 weight diff: 0.0000000000\nclient_4 Layer 69 weight diff: 0.0000000000\nclient_4 Layer 70 weight diff: 0.0000000000\nclient_4 Layer 71 weight diff: 0.0000000000\nclient_4 Layer 72 weight diff: 0.0000000000\nclient_4 Layer 73 weight diff: 0.0000000000\nclient_4 Layer 74 weight diff: 0.0000000000\nclient_4 Layer 75 weight diff: 0.0000000000\nclient_4 Layer 76 weight diff: 0.0000000000\nclient_4 Layer 77 weight diff: 0.0000000000\nclient_4 Layer 78 weight diff: 0.0000000000\nclient_4 Layer 79 weight diff: 0.0000000000\nclient_4 Layer 80 weight diff: 0.0000000000\nclient_4 Layer 81 weight diff: 0.0000000000\nclient_4 Layer 82 weight diff: 0.0000000000\nclient_4 Layer 83 weight diff: 0.0000000000\nclient_4 Layer 84 weight diff: 0.0000000000\nclient_4 Layer 85 weight diff: 17.0682220459\nclient_4 Layer 86 weight diff: 1345.9224853516\nclient_4 Layer 87 weight diff: 1.7946624756\nclient_4 Layer 88 weight diff: 1.7536244392\nclient_4 Layer 89 weight diff: 15.4086933136\nclient_4 Layer 90 weight diff: 7.5082254410\nclient_4 Layer 91 weight diff: 16.6505317688\nclient_4 Layer 92 weight diff: 1365.9653320312\nclient_4 Layer 93 weight diff: 1.8757926226\nclient_4 Layer 94 weight diff: 1.8191871643\nclient_4 Layer 95 weight diff: 14.9259395599\nclient_4 Layer 96 weight diff: 36.1761436462\nclient_4 Layer 97 weight diff: 17.8339424133\nclient_4 Layer 98 weight diff: 1437.6292724609\nclient_4 Layer 99 weight diff: 1.9477337599\nclient_4 Layer 100 weight diff: 1.8722586632\nclient_4 Layer 101 weight diff: 31.4575099945\nclient_4 Layer 102 weight diff: 31.4294586182\nclient_4 Layer 103 weight diff: 17.3566284180\nclient_4 Layer 104 weight diff: 1432.2661132812\nclient_4 Layer 105 weight diff: 1.9404785633\nclient_4 Layer 106 weight diff: 2.0005064011\nclient_4 Layer 107 weight diff: 9.5805187225\nclient_4 Layer 108 weight diff: 7.3386502266\nclient_4 Layer 109 weight diff: 17.4931488037\nclient_4 Layer 110 weight diff: 1434.6401367188\nclient_4 Layer 111 weight diff: 1.8944792747\nclient_4 Layer 112 weight diff: 1.8832926750\nclient_4 Layer 113 weight diff: 7.2420153618\nclient_4 Layer 114 weight diff: 17.0548210144\nclient_4 Layer 115 weight diff: 17.3514041901\nclient_4 Layer 116 weight diff: 1433.4215087891\nclient_4 Layer 117 weight diff: 1.8955035210\nclient_4 Layer 118 weight diff: 1.9812078476\nclient_4 Layer 119 weight diff: 20.0220718384\nclient_4 Layer 120 weight diff: 28.7539672852\nclient_4 Layer 121 weight diff: 17.5819931030\nclient_4 Layer 122 weight diff: 1416.6508789062\nclient_4 Layer 123 weight diff: 1.7744975090\nclient_4 Layer 124 weight diff: 1.8044288158\nclient_4 Layer 125 weight diff: 10.4040470123\nclient_4 Layer 126 weight diff: 6.1830034256\nclient_4 Layer 127 weight diff: 16.9092521667\nclient_4 Layer 128 weight diff: 1407.5218505859\nclient_4 Layer 129 weight diff: 1.8727469444\nclient_4 Layer 130 weight diff: 1.8690061569\nclient_4 Layer 131 weight diff: 9.2804660797\nclient_4 Layer 132 weight diff: 6.9092388153\nclient_4 Layer 133 weight diff: 17.7455940247\nclient_4 Layer 134 weight diff: 1386.8759765625\nclient_4 Layer 135 weight diff: 1.8741023540\nclient_4 Layer 136 weight diff: 1.8822684288\nclient_4 Layer 137 weight diff: 41.4448928833\nclient_4 Layer 138 weight diff: 33.5994262695\nclient_4 Layer 139 weight diff: 17.0045585632\nclient_4 Layer 140 weight diff: 1362.9272460938\nclient_4 Layer 141 weight diff: 1.8422502279\nclient_4 Layer 142 weight diff: 1.8677982092\nclient_4 Layer 143 weight diff: 17.8513984680\nclient_4 Layer 144 weight diff: 9.8235912323\nclient_4 Layer 145 weight diff: 16.7923202515\nclient_4 Layer 146 weight diff: 1377.8321533203\nclient_4 Layer 147 weight diff: 1.9131491184\nclient_4 Layer 148 weight diff: 1.9403731823\nclient_4 Layer 149 weight diff: 17.5946502686\nclient_4 Layer 150 weight diff: 10.6599884033\nclient_4 Layer 151 weight diff: 17.3955554962\nclient_4 Layer 152 weight diff: 1425.9821777344\nclient_4 Layer 153 weight diff: 2.0069999695\nclient_4 Layer 154 weight diff: 2.0604877472\nclient_4 Layer 155 weight diff: 30.3879623413\nclient_4 Layer 156 weight diff: 33.5889434814\nclient_4 Layer 157 weight diff: 17.8039016724\nclient_4 Layer 158 weight diff: 1405.2770996094\nclient_4 Layer 159 weight diff: 1.9173744917\nclient_4 Layer 160 weight diff: 1.9235799313\nclient_4 Layer 161 weight diff: 12.3914527893\nclient_4 Layer 162 weight diff: 8.9095439911\nclient_4 Layer 163 weight diff: 16.5862312317\nclient_4 Layer 164 weight diff: 1392.5161132812\nclient_4 Layer 165 weight diff: 1.8531960249\nclient_4 Layer 166 weight diff: 1.8686387539\nclient_4 Layer 167 weight diff: 9.6490116119\nclient_4 Layer 168 weight diff: 8.6095762253\nclient_4 Layer 169 weight diff: 17.7824153900\nclient_4 Layer 170 weight diff: 1401.9611816406\nclient_4 Layer 171 weight diff: 1.9261784554\nclient_4 Layer 172 weight diff: 1.8717207909\nclient_4 Layer 173 weight diff: 35.1336441040\nclient_4 Layer 174 weight diff: 43.4617004395\nclient_4 Layer 175 weight diff: 17.7992248535\nclient_4 Layer 176 weight diff: 1373.9687500000\nclient_4 Layer 177 weight diff: 1.8845237494\nclient_4 Layer 178 weight diff: 1.8690090179\nclient_4 Layer 179 weight diff: 14.5674724579\nclient_4 Layer 180 weight diff: 15.8463201523\nclient_4 Layer 181 weight diff: 16.7281513214\nclient_4 Layer 182 weight diff: 1379.3315429688\nclient_4 Layer 183 weight diff: 1.8989351988\nclient_4 Layer 184 weight diff: 1.8307985067\nclient_4 Layer 185 weight diff: 9.5371465683\nclient_4 Layer 186 weight diff: 6.2055759430\nclient_4 Layer 187 weight diff: 17.7993965149\nclient_4 Layer 188 weight diff: 1401.4265136719\nclient_4 Layer 189 weight diff: 1.9724500179\nclient_4 Layer 190 weight diff: 1.9808919430\nclient_4 Layer 191 weight diff: 49.1808013916\nclient_4 Layer 192 weight diff: 60.2024688721\nclient_4 Layer 193 weight diff: 17.1515731812\nclient_4 Layer 194 weight diff: 1368.9665527344\nclient_4 Layer 195 weight diff: 1.9017682076\nclient_4 Layer 196 weight diff: 1.9211807251\nclient_4 Layer 197 weight diff: 17.1262226105\nclient_4 Layer 198 weight diff: 17.8383407593\nclient_4 Layer 199 weight diff: 16.8863487244\nclient_4 Layer 200 weight diff: 1372.1613769531\nclient_4 Layer 201 weight diff: 1.8857955933\nclient_4 Layer 202 weight diff: 1.8700517416\nclient_4 Layer 203 weight diff: 10.4468994141\nclient_4 Layer 204 weight diff: 6.9357852936\nclient_4 Layer 205 weight diff: 16.7530097961\nclient_4 Layer 206 weight diff: 1365.5683593750\nclient_4 Layer 207 weight diff: 1.7637223005\nclient_4 Layer 208 weight diff: 1.7820272446\nclient_4 Layer 209 weight diff: 126.7742309570\nclient_4 Layer 210 weight diff: 321.0586547852\nclient_4 Layer 211 weight diff: 16.4467964172\nclient_4 Layer 212 weight diff: 1862.5385742188\nclient_4 Layer 213 weight diff: 2.5636854172\nclient_4 Layer 214 weight diff: 2.2598276138\nclient_4 Layer 215 weight diff: 34.3114547729\nclient_4 Layer 216 weight diff: 22.4363861084\nclient_4 Layer 217 weight diff: 1833.5627441406\nclient_4 Layer 218 weight diff: 2.5008273125\nclient_4 Layer 219 weight diff: 2.2598276138\nclient_4 Layer 220 weight diff: 848.6557617188\nclient_4 Layer 221 weight diff: 27778.4609375000\nclient_4 Layer 222 weight diff: 23.3993549347\nclient_4 Layer 223 weight diff: 3936.9440917969\nclient_4 Layer 224 weight diff: 3.7274932861\nclient_4 Layer 225 weight diff: 3.6745147705\nclient_4 Layer 226 weight diff: 139.1737670898\nclient_4 Layer 227 weight diff: 578.1594238281\nclient_4 Layer 228 weight diff: 35.1489906311\nclient_4 Layer 229 weight diff: 7590.6411132812\nclient_4 Layer 230 weight diff: 4.5724210739\nclient_4 Layer 231 weight diff: 4.7512984276\nclient_4 Layer 232 weight diff: 243.4766082764\nclient_4 Layer 233 weight diff: 387.5860900879\nclient_4 Layer 234 weight diff: 0.0000000000\nclient_4 Layer 235 weight diff: 0.0000000000\nclient_4 Layer 236 weight diff: 0.0000000000\nclient_4 Layer 237 weight diff: 0.0000000000\nclient_4 training accuracy history: [0.9401260614395142, 0.9747899174690247, 0.9821428656578064, 0.9926470518112183, 0.9852941036224365]\nclient_4 total local-global weight diff: 76316.32716715\n\n📶 Training on client_5\nTraining client_5 for 5 epochs...\nSum of weights before training: 177500.594\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 921ms/step - accuracy: 0.9480 - loss: 0.2087 - precision_35: 0.9546 - recall_35: 0.9389\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 657ms/step - accuracy: 0.9701 - loss: 0.1039 - precision_35: 0.9700 - recall_35: 0.9661\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 669ms/step - accuracy: 0.9893 - loss: 0.0378 - precision_35: 0.9893 - recall_35: 0.9881\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 630ms/step - accuracy: 0.9934 - loss: 0.0268 - precision_35: 0.9934 - recall_35: 0.9934\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 636ms/step - accuracy: 0.9944 - loss: 0.0201 - precision_35: 0.9944 - recall_35: 0.9944\nSum of weights after training: 193226.297\nclient_5 Layer 0 weight diff: 0.0000000000\nclient_5 Layer 1 weight diff: 0.0000000000\nclient_5 Layer 2 weight diff: 0.0000000000\nclient_5 Layer 3 weight diff: 0.0000000000\nclient_5 Layer 4 weight diff: 0.0000000000\nclient_5 Layer 5 weight diff: 0.0000000000\nclient_5 Layer 6 weight diff: 0.0000000000\nclient_5 Layer 7 weight diff: 0.0000000000\nclient_5 Layer 8 weight diff: 0.0000000000\nclient_5 Layer 9 weight diff: 0.0000000000\nclient_5 Layer 10 weight diff: 0.0000000000\nclient_5 Layer 11 weight diff: 0.0000000000\nclient_5 Layer 12 weight diff: 0.0000000000\nclient_5 Layer 13 weight diff: 0.0000000000\nclient_5 Layer 14 weight diff: 0.0000000000\nclient_5 Layer 15 weight diff: 0.0000000000\nclient_5 Layer 16 weight diff: 0.0000000000\nclient_5 Layer 17 weight diff: 0.0000000000\nclient_5 Layer 18 weight diff: 0.0000000000\nclient_5 Layer 19 weight diff: 0.0000000000\nclient_5 Layer 20 weight diff: 0.0000000000\nclient_5 Layer 21 weight diff: 0.0000000000\nclient_5 Layer 22 weight diff: 0.0000000000\nclient_5 Layer 23 weight diff: 0.0000000000\nclient_5 Layer 24 weight diff: 0.0000000000\nclient_5 Layer 25 weight diff: 0.0000000000\nclient_5 Layer 26 weight diff: 0.0000000000\nclient_5 Layer 27 weight diff: 0.0000000000\nclient_5 Layer 28 weight diff: 0.0000000000\nclient_5 Layer 29 weight diff: 0.0000000000\nclient_5 Layer 30 weight diff: 0.0000000000\nclient_5 Layer 31 weight diff: 0.0000000000\nclient_5 Layer 32 weight diff: 0.0000000000\nclient_5 Layer 33 weight diff: 0.0000000000\nclient_5 Layer 34 weight diff: 0.0000000000\nclient_5 Layer 35 weight diff: 0.0000000000\nclient_5 Layer 36 weight diff: 0.0000000000\nclient_5 Layer 37 weight diff: 0.0000000000\nclient_5 Layer 38 weight diff: 0.0000000000\nclient_5 Layer 39 weight diff: 0.0000000000\nclient_5 Layer 40 weight diff: 0.0000000000\nclient_5 Layer 41 weight diff: 0.0000000000\nclient_5 Layer 42 weight diff: 0.0000000000\nclient_5 Layer 43 weight diff: 0.0000000000\nclient_5 Layer 44 weight diff: 0.0000000000\nclient_5 Layer 45 weight diff: 0.0000000000\nclient_5 Layer 46 weight diff: 0.0000000000\nclient_5 Layer 47 weight diff: 0.0000000000\nclient_5 Layer 48 weight diff: 0.0000000000\nclient_5 Layer 49 weight diff: 0.0000000000\nclient_5 Layer 50 weight diff: 0.0000000000\nclient_5 Layer 51 weight diff: 0.0000000000\nclient_5 Layer 52 weight diff: 0.0000000000\nclient_5 Layer 53 weight diff: 0.0000000000\nclient_5 Layer 54 weight diff: 0.0000000000\nclient_5 Layer 55 weight diff: 0.0000000000\nclient_5 Layer 56 weight diff: 0.0000000000\nclient_5 Layer 57 weight diff: 0.0000000000\nclient_5 Layer 58 weight diff: 0.0000000000\nclient_5 Layer 59 weight diff: 0.0000000000\nclient_5 Layer 60 weight diff: 0.0000000000\nclient_5 Layer 61 weight diff: 0.0000000000\nclient_5 Layer 62 weight diff: 0.0000000000\nclient_5 Layer 63 weight diff: 0.0000000000\nclient_5 Layer 64 weight diff: 0.0000000000\nclient_5 Layer 65 weight diff: 0.0000000000\nclient_5 Layer 66 weight diff: 0.0000000000\nclient_5 Layer 67 weight diff: 0.0000000000\nclient_5 Layer 68 weight diff: 0.0000000000\nclient_5 Layer 69 weight diff: 0.0000000000\nclient_5 Layer 70 weight diff: 0.0000000000\nclient_5 Layer 71 weight diff: 0.0000000000\nclient_5 Layer 72 weight diff: 0.0000000000\nclient_5 Layer 73 weight diff: 0.0000000000\nclient_5 Layer 74 weight diff: 0.0000000000\nclient_5 Layer 75 weight diff: 0.0000000000\nclient_5 Layer 76 weight diff: 0.0000000000\nclient_5 Layer 77 weight diff: 0.0000000000\nclient_5 Layer 78 weight diff: 0.0000000000\nclient_5 Layer 79 weight diff: 0.0000000000\nclient_5 Layer 80 weight diff: 0.0000000000\nclient_5 Layer 81 weight diff: 0.0000000000\nclient_5 Layer 82 weight diff: 0.0000000000\nclient_5 Layer 83 weight diff: 0.0000000000\nclient_5 Layer 84 weight diff: 0.0000000000\nclient_5 Layer 85 weight diff: 18.0724506378\nclient_5 Layer 86 weight diff: 1423.8476562500\nclient_5 Layer 87 weight diff: 1.8986580372\nclient_5 Layer 88 weight diff: 1.9267194271\nclient_5 Layer 89 weight diff: 16.5529670715\nclient_5 Layer 90 weight diff: 7.4898462296\nclient_5 Layer 91 weight diff: 17.4585380554\nclient_5 Layer 92 weight diff: 1440.2622070312\nclient_5 Layer 93 weight diff: 1.9357045889\nclient_5 Layer 94 weight diff: 1.9288597107\nclient_5 Layer 95 weight diff: 15.5994930267\nclient_5 Layer 96 weight diff: 35.8225326538\nclient_5 Layer 97 weight diff: 18.3907642365\nclient_5 Layer 98 weight diff: 1474.2216796875\nclient_5 Layer 99 weight diff: 1.9484262466\nclient_5 Layer 100 weight diff: 1.9730632305\nclient_5 Layer 101 weight diff: 30.6298923492\nclient_5 Layer 102 weight diff: 31.5211219788\nclient_5 Layer 103 weight diff: 17.8877696991\nclient_5 Layer 104 weight diff: 1473.6748046875\nclient_5 Layer 105 weight diff: 1.8153162003\nclient_5 Layer 106 weight diff: 1.8747599125\nclient_5 Layer 107 weight diff: 8.6815805435\nclient_5 Layer 108 weight diff: 7.9754600525\nclient_5 Layer 109 weight diff: 17.3391151428\nclient_5 Layer 110 weight diff: 1478.1325683594\nclient_5 Layer 111 weight diff: 1.8779120445\nclient_5 Layer 112 weight diff: 1.9278390408\nclient_5 Layer 113 weight diff: 7.8247127533\nclient_5 Layer 114 weight diff: 15.3201398849\nclient_5 Layer 115 weight diff: 18.5445938110\nclient_5 Layer 116 weight diff: 1511.2460937500\nclient_5 Layer 117 weight diff: 1.9746471643\nclient_5 Layer 118 weight diff: 2.0796542168\nclient_5 Layer 119 weight diff: 20.2546806335\nclient_5 Layer 120 weight diff: 30.8021144867\nclient_5 Layer 121 weight diff: 18.3831520081\nclient_5 Layer 122 weight diff: 1511.2872314453\nclient_5 Layer 123 weight diff: 1.9235186577\nclient_5 Layer 124 weight diff: 1.9201343060\nclient_5 Layer 125 weight diff: 9.7497854233\nclient_5 Layer 126 weight diff: 6.3701739311\nclient_5 Layer 127 weight diff: 17.8367538452\nclient_5 Layer 128 weight diff: 1499.2569580078\nclient_5 Layer 129 weight diff: 1.9647183418\nclient_5 Layer 130 weight diff: 1.9607635736\nclient_5 Layer 131 weight diff: 9.1416206360\nclient_5 Layer 132 weight diff: 5.9417071342\nclient_5 Layer 133 weight diff: 17.6981220245\nclient_5 Layer 134 weight diff: 1490.3764648438\nclient_5 Layer 135 weight diff: 1.9392905235\nclient_5 Layer 136 weight diff: 1.9620954990\nclient_5 Layer 137 weight diff: 37.3412399292\nclient_5 Layer 138 weight diff: 32.2604484558\nclient_5 Layer 139 weight diff: 17.7973041534\nclient_5 Layer 140 weight diff: 1455.3415527344\nclient_5 Layer 141 weight diff: 1.7765822411\nclient_5 Layer 142 weight diff: 1.8470396996\nclient_5 Layer 143 weight diff: 14.7397766113\nclient_5 Layer 144 weight diff: 10.9036293030\nclient_5 Layer 145 weight diff: 17.2431201935\nclient_5 Layer 146 weight diff: 1463.0281982422\nclient_5 Layer 147 weight diff: 1.9666608572\nclient_5 Layer 148 weight diff: 1.9483195543\nclient_5 Layer 149 weight diff: 16.9349346161\nclient_5 Layer 150 weight diff: 11.0878753662\nclient_5 Layer 151 weight diff: 18.8576850891\nclient_5 Layer 152 weight diff: 1501.7573242188\nclient_5 Layer 153 weight diff: 2.0394539833\nclient_5 Layer 154 weight diff: 2.0670590401\nclient_5 Layer 155 weight diff: 27.0371704102\nclient_5 Layer 156 weight diff: 29.5960922241\nclient_5 Layer 157 weight diff: 18.6563358307\nclient_5 Layer 158 weight diff: 1480.2541503906\nclient_5 Layer 159 weight diff: 1.9832398891\nclient_5 Layer 160 weight diff: 1.9893813133\nclient_5 Layer 161 weight diff: 12.5567827225\nclient_5 Layer 162 weight diff: 7.3484878540\nclient_5 Layer 163 weight diff: 18.4297637939\nclient_5 Layer 164 weight diff: 1481.0866699219\nclient_5 Layer 165 weight diff: 1.9729499817\nclient_5 Layer 166 weight diff: 1.9515645504\nclient_5 Layer 167 weight diff: 9.0240173340\nclient_5 Layer 168 weight diff: 5.3086690903\nclient_5 Layer 169 weight diff: 18.1437110901\nclient_5 Layer 170 weight diff: 1482.6469726562\nclient_5 Layer 171 weight diff: 1.9780193567\nclient_5 Layer 172 weight diff: 1.9807454348\nclient_5 Layer 173 weight diff: 32.2696800232\nclient_5 Layer 174 weight diff: 43.9025115967\nclient_5 Layer 175 weight diff: 18.4007072449\nclient_5 Layer 176 weight diff: 1466.2950439453\nclient_5 Layer 177 weight diff: 1.9307572842\nclient_5 Layer 178 weight diff: 1.9798175097\nclient_5 Layer 179 weight diff: 15.1994285583\nclient_5 Layer 180 weight diff: 15.9929084778\nclient_5 Layer 181 weight diff: 17.4709205627\nclient_5 Layer 182 weight diff: 1456.1459960938\nclient_5 Layer 183 weight diff: 2.0062537193\nclient_5 Layer 184 weight diff: 1.8971990347\nclient_5 Layer 185 weight diff: 10.0068044662\nclient_5 Layer 186 weight diff: 18.5727119446\nclient_5 Layer 187 weight diff: 17.7126770020\nclient_5 Layer 188 weight diff: 1448.1562500000\nclient_5 Layer 189 weight diff: 1.8625426292\nclient_5 Layer 190 weight diff: 1.8978071213\nclient_5 Layer 191 weight diff: 42.7905654907\nclient_5 Layer 192 weight diff: 70.9439163208\nclient_5 Layer 193 weight diff: 17.0033035278\nclient_5 Layer 194 weight diff: 1437.9176025391\nclient_5 Layer 195 weight diff: 1.9160467386\nclient_5 Layer 196 weight diff: 1.9120028019\nclient_5 Layer 197 weight diff: 19.6076374054\nclient_5 Layer 198 weight diff: 18.6383247375\nclient_5 Layer 199 weight diff: 17.1524524689\nclient_5 Layer 200 weight diff: 1415.9487304688\nclient_5 Layer 201 weight diff: 1.8482568264\nclient_5 Layer 202 weight diff: 1.9170904160\nclient_5 Layer 203 weight diff: 11.6372480392\nclient_5 Layer 204 weight diff: 23.9218158722\nclient_5 Layer 205 weight diff: 17.5731830597\nclient_5 Layer 206 weight diff: 1436.6459960938\nclient_5 Layer 207 weight diff: 1.8709948063\nclient_5 Layer 208 weight diff: 1.8768948317\nclient_5 Layer 209 weight diff: 78.6166076660\nclient_5 Layer 210 weight diff: 301.7572631836\nclient_5 Layer 211 weight diff: 17.4020404816\nclient_5 Layer 212 weight diff: 1958.1550292969\nclient_5 Layer 213 weight diff: 2.6495261192\nclient_5 Layer 214 weight diff: 2.5377407074\nclient_5 Layer 215 weight diff: 30.6650695801\nclient_5 Layer 216 weight diff: 21.9127006531\nclient_5 Layer 217 weight diff: 1965.0753173828\nclient_5 Layer 218 weight diff: 2.5782580376\nclient_5 Layer 219 weight diff: 2.5377402306\nclient_5 Layer 220 weight diff: 922.7312011719\nclient_5 Layer 221 weight diff: 26813.3535156250\nclient_5 Layer 222 weight diff: 24.3308086395\nclient_5 Layer 223 weight diff: 4251.0688476562\nclient_5 Layer 224 weight diff: 3.8357806206\nclient_5 Layer 225 weight diff: 3.9810452461\nclient_5 Layer 226 weight diff: 178.9348144531\nclient_5 Layer 227 weight diff: 359.2174682617\nclient_5 Layer 228 weight diff: 35.3890304565\nclient_5 Layer 229 weight diff: 7610.6269531250\nclient_5 Layer 230 weight diff: 4.2165460587\nclient_5 Layer 231 weight diff: 4.4935197830\nclient_5 Layer 232 weight diff: 288.4850463867\nclient_5 Layer 233 weight diff: 649.2580566406\nclient_5 Layer 234 weight diff: 0.0000000000\nclient_5 Layer 235 weight diff: 0.0000000000\nclient_5 Layer 236 weight diff: 0.0000000000\nclient_5 Layer 237 weight diff: 0.0000000000\nclient_5 training accuracy history: [0.9401260614395142, 0.9663865566253662, 0.9873949289321899, 0.993697464466095, 0.9905462265014648]\nclient_5 total local-global weight diff: 77615.94176829\n\n📶 Training on client_6\nTraining client_6 for 5 epochs...\nSum of weights before training: 177500.594\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 953ms/step - accuracy: 0.9331 - loss: 0.3188 - precision_36: 0.9363 - recall_36: 0.9212\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 667ms/step - accuracy: 0.9481 - loss: 0.1787 - precision_36: 0.9517 - recall_36: 0.9435\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 658ms/step - accuracy: 0.9843 - loss: 0.0373 - precision_36: 0.9918 - recall_36: 0.9810\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 637ms/step - accuracy: 0.9893 - loss: 0.0336 - precision_36: 0.9893 - recall_36: 0.9893\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 672ms/step - accuracy: 0.9918 - loss: 0.0217 - precision_36: 0.9949 - recall_36: 0.9918\nSum of weights after training: 187905.547\nclient_6 Layer 0 weight diff: 0.0000000000\nclient_6 Layer 1 weight diff: 0.0000000000\nclient_6 Layer 2 weight diff: 0.0000000000\nclient_6 Layer 3 weight diff: 0.0000000000\nclient_6 Layer 4 weight diff: 0.0000000000\nclient_6 Layer 5 weight diff: 0.0000000000\nclient_6 Layer 6 weight diff: 0.0000000000\nclient_6 Layer 7 weight diff: 0.0000000000\nclient_6 Layer 8 weight diff: 0.0000000000\nclient_6 Layer 9 weight diff: 0.0000000000\nclient_6 Layer 10 weight diff: 0.0000000000\nclient_6 Layer 11 weight diff: 0.0000000000\nclient_6 Layer 12 weight diff: 0.0000000000\nclient_6 Layer 13 weight diff: 0.0000000000\nclient_6 Layer 14 weight diff: 0.0000000000\nclient_6 Layer 15 weight diff: 0.0000000000\nclient_6 Layer 16 weight diff: 0.0000000000\nclient_6 Layer 17 weight diff: 0.0000000000\nclient_6 Layer 18 weight diff: 0.0000000000\nclient_6 Layer 19 weight diff: 0.0000000000\nclient_6 Layer 20 weight diff: 0.0000000000\nclient_6 Layer 21 weight diff: 0.0000000000\nclient_6 Layer 22 weight diff: 0.0000000000\nclient_6 Layer 23 weight diff: 0.0000000000\nclient_6 Layer 24 weight diff: 0.0000000000\nclient_6 Layer 25 weight diff: 0.0000000000\nclient_6 Layer 26 weight diff: 0.0000000000\nclient_6 Layer 27 weight diff: 0.0000000000\nclient_6 Layer 28 weight diff: 0.0000000000\nclient_6 Layer 29 weight diff: 0.0000000000\nclient_6 Layer 30 weight diff: 0.0000000000\nclient_6 Layer 31 weight diff: 0.0000000000\nclient_6 Layer 32 weight diff: 0.0000000000\nclient_6 Layer 33 weight diff: 0.0000000000\nclient_6 Layer 34 weight diff: 0.0000000000\nclient_6 Layer 35 weight diff: 0.0000000000\nclient_6 Layer 36 weight diff: 0.0000000000\nclient_6 Layer 37 weight diff: 0.0000000000\nclient_6 Layer 38 weight diff: 0.0000000000\nclient_6 Layer 39 weight diff: 0.0000000000\nclient_6 Layer 40 weight diff: 0.0000000000\nclient_6 Layer 41 weight diff: 0.0000000000\nclient_6 Layer 42 weight diff: 0.0000000000\nclient_6 Layer 43 weight diff: 0.0000000000\nclient_6 Layer 44 weight diff: 0.0000000000\nclient_6 Layer 45 weight diff: 0.0000000000\nclient_6 Layer 46 weight diff: 0.0000000000\nclient_6 Layer 47 weight diff: 0.0000000000\nclient_6 Layer 48 weight diff: 0.0000000000\nclient_6 Layer 49 weight diff: 0.0000000000\nclient_6 Layer 50 weight diff: 0.0000000000\nclient_6 Layer 51 weight diff: 0.0000000000\nclient_6 Layer 52 weight diff: 0.0000000000\nclient_6 Layer 53 weight diff: 0.0000000000\nclient_6 Layer 54 weight diff: 0.0000000000\nclient_6 Layer 55 weight diff: 0.0000000000\nclient_6 Layer 56 weight diff: 0.0000000000\nclient_6 Layer 57 weight diff: 0.0000000000\nclient_6 Layer 58 weight diff: 0.0000000000\nclient_6 Layer 59 weight diff: 0.0000000000\nclient_6 Layer 60 weight diff: 0.0000000000\nclient_6 Layer 61 weight diff: 0.0000000000\nclient_6 Layer 62 weight diff: 0.0000000000\nclient_6 Layer 63 weight diff: 0.0000000000\nclient_6 Layer 64 weight diff: 0.0000000000\nclient_6 Layer 65 weight diff: 0.0000000000\nclient_6 Layer 66 weight diff: 0.0000000000\nclient_6 Layer 67 weight diff: 0.0000000000\nclient_6 Layer 68 weight diff: 0.0000000000\nclient_6 Layer 69 weight diff: 0.0000000000\nclient_6 Layer 70 weight diff: 0.0000000000\nclient_6 Layer 71 weight diff: 0.0000000000\nclient_6 Layer 72 weight diff: 0.0000000000\nclient_6 Layer 73 weight diff: 0.0000000000\nclient_6 Layer 74 weight diff: 0.0000000000\nclient_6 Layer 75 weight diff: 0.0000000000\nclient_6 Layer 76 weight diff: 0.0000000000\nclient_6 Layer 77 weight diff: 0.0000000000\nclient_6 Layer 78 weight diff: 0.0000000000\nclient_6 Layer 79 weight diff: 0.0000000000\nclient_6 Layer 80 weight diff: 0.0000000000\nclient_6 Layer 81 weight diff: 0.0000000000\nclient_6 Layer 82 weight diff: 0.0000000000\nclient_6 Layer 83 weight diff: 0.0000000000\nclient_6 Layer 84 weight diff: 0.0000000000\nclient_6 Layer 85 weight diff: 16.8810424805\nclient_6 Layer 86 weight diff: 1321.5095214844\nclient_6 Layer 87 weight diff: 1.7275416851\nclient_6 Layer 88 weight diff: 1.7171134949\nclient_6 Layer 89 weight diff: 14.8594999313\nclient_6 Layer 90 weight diff: 7.5734524727\nclient_6 Layer 91 weight diff: 15.7267570496\nclient_6 Layer 92 weight diff: 1337.2866210938\nclient_6 Layer 93 weight diff: 1.7697890997\nclient_6 Layer 94 weight diff: 1.7936939001\nclient_6 Layer 95 weight diff: 12.7630100250\nclient_6 Layer 96 weight diff: 33.4937286377\nclient_6 Layer 97 weight diff: 17.5908203125\nclient_6 Layer 98 weight diff: 1420.2008056641\nclient_6 Layer 99 weight diff: 1.9274024963\nclient_6 Layer 100 weight diff: 1.9333393574\nclient_6 Layer 101 weight diff: 32.0695457458\nclient_6 Layer 102 weight diff: 30.5645008087\nclient_6 Layer 103 weight diff: 16.3150463104\nclient_6 Layer 104 weight diff: 1399.9841308594\nclient_6 Layer 105 weight diff: 1.7554861307\nclient_6 Layer 106 weight diff: 1.7518594265\nclient_6 Layer 107 weight diff: 8.0076942444\nclient_6 Layer 108 weight diff: 8.1008129120\nclient_6 Layer 109 weight diff: 16.5933761597\nclient_6 Layer 110 weight diff: 1397.1274414062\nclient_6 Layer 111 weight diff: 1.7982199192\nclient_6 Layer 112 weight diff: 1.8015855551\nclient_6 Layer 113 weight diff: 7.5246601105\nclient_6 Layer 114 weight diff: 19.6663742065\nclient_6 Layer 115 weight diff: 16.4555091858\nclient_6 Layer 116 weight diff: 1410.6882324219\nclient_6 Layer 117 weight diff: 1.9219889641\nclient_6 Layer 118 weight diff: 1.9347791672\nclient_6 Layer 119 weight diff: 20.7819824219\nclient_6 Layer 120 weight diff: 32.5415878296\nclient_6 Layer 121 weight diff: 16.7875785828\nclient_6 Layer 122 weight diff: 1394.2888183594\nclient_6 Layer 123 weight diff: 1.7975590229\nclient_6 Layer 124 weight diff: 1.7933907509\nclient_6 Layer 125 weight diff: 9.6193132401\nclient_6 Layer 126 weight diff: 6.3445701599\nclient_6 Layer 127 weight diff: 16.5698146820\nclient_6 Layer 128 weight diff: 1369.8649902344\nclient_6 Layer 129 weight diff: 1.7942498922\nclient_6 Layer 130 weight diff: 1.7877717018\nclient_6 Layer 131 weight diff: 8.9799175262\nclient_6 Layer 132 weight diff: 5.4251832962\nclient_6 Layer 133 weight diff: 16.7771396637\nclient_6 Layer 134 weight diff: 1360.4017333984\nclient_6 Layer 135 weight diff: 1.7517511845\nclient_6 Layer 136 weight diff: 1.7196615934\nclient_6 Layer 137 weight diff: 36.0159988403\nclient_6 Layer 138 weight diff: 32.8906707764\nclient_6 Layer 139 weight diff: 16.3382110596\nclient_6 Layer 140 weight diff: 1337.6722412109\nclient_6 Layer 141 weight diff: 1.7052686214\nclient_6 Layer 142 weight diff: 1.7421813011\nclient_6 Layer 143 weight diff: 12.7129364014\nclient_6 Layer 144 weight diff: 9.1045246124\nclient_6 Layer 145 weight diff: 15.3348445892\nclient_6 Layer 146 weight diff: 1326.7348632812\nclient_6 Layer 147 weight diff: 1.8239693642\nclient_6 Layer 148 weight diff: 1.7858316898\nclient_6 Layer 149 weight diff: 14.1866798401\nclient_6 Layer 150 weight diff: 12.0629873276\nclient_6 Layer 151 weight diff: 17.4060554504\nclient_6 Layer 152 weight diff: 1393.0850830078\nclient_6 Layer 153 weight diff: 1.7960982323\nclient_6 Layer 154 weight diff: 1.9046961069\nclient_6 Layer 155 weight diff: 28.5063705444\nclient_6 Layer 156 weight diff: 34.3227081299\nclient_6 Layer 157 weight diff: 16.1317615509\nclient_6 Layer 158 weight diff: 1373.1274414062\nclient_6 Layer 159 weight diff: 1.8482003212\nclient_6 Layer 160 weight diff: 1.8968174458\nclient_6 Layer 161 weight diff: 10.7124195099\nclient_6 Layer 162 weight diff: 11.8971099854\nclient_6 Layer 163 weight diff: 16.5378494263\nclient_6 Layer 164 weight diff: 1346.1081542969\nclient_6 Layer 165 weight diff: 1.8388029337\nclient_6 Layer 166 weight diff: 1.6851677895\nclient_6 Layer 167 weight diff: 7.2800922394\nclient_6 Layer 168 weight diff: 7.0079269409\nclient_6 Layer 169 weight diff: 16.9855995178\nclient_6 Layer 170 weight diff: 1368.5563964844\nclient_6 Layer 171 weight diff: 1.7570929527\nclient_6 Layer 172 weight diff: 1.8439066410\nclient_6 Layer 173 weight diff: 30.3576908112\nclient_6 Layer 174 weight diff: 51.8452835083\nclient_6 Layer 175 weight diff: 16.5463676453\nclient_6 Layer 176 weight diff: 1340.5102539062\nclient_6 Layer 177 weight diff: 1.8119069338\nclient_6 Layer 178 weight diff: 1.8538968563\nclient_6 Layer 179 weight diff: 14.3214912415\nclient_6 Layer 180 weight diff: 16.6874523163\nclient_6 Layer 181 weight diff: 16.0928115845\nclient_6 Layer 182 weight diff: 1311.3276367188\nclient_6 Layer 183 weight diff: 1.7224388123\nclient_6 Layer 184 weight diff: 1.6781680584\nclient_6 Layer 185 weight diff: 8.1475448608\nclient_6 Layer 186 weight diff: 6.8261008263\nclient_6 Layer 187 weight diff: 16.7856864929\nclient_6 Layer 188 weight diff: 1335.1564941406\nclient_6 Layer 189 weight diff: 1.7660140991\nclient_6 Layer 190 weight diff: 1.8416103125\nclient_6 Layer 191 weight diff: 41.6587066650\nclient_6 Layer 192 weight diff: 75.7806091309\nclient_6 Layer 193 weight diff: 15.6006336212\nclient_6 Layer 194 weight diff: 1308.8305664062\nclient_6 Layer 195 weight diff: 1.6967047453\nclient_6 Layer 196 weight diff: 1.7289220095\nclient_6 Layer 197 weight diff: 22.2093296051\nclient_6 Layer 198 weight diff: 64.7365875244\nclient_6 Layer 199 weight diff: 15.5883293152\nclient_6 Layer 200 weight diff: 1251.2055664062\nclient_6 Layer 201 weight diff: 1.7085311413\nclient_6 Layer 202 weight diff: 1.6226372719\nclient_6 Layer 203 weight diff: 13.4834833145\nclient_6 Layer 204 weight diff: 32.4506149292\nclient_6 Layer 205 weight diff: 15.9202785492\nclient_6 Layer 206 weight diff: 1324.7546386719\nclient_6 Layer 207 weight diff: 1.6014502048\nclient_6 Layer 208 weight diff: 1.5723265409\nclient_6 Layer 209 weight diff: 67.7230529785\nclient_6 Layer 210 weight diff: 309.1381225586\nclient_6 Layer 211 weight diff: 15.7253417969\nclient_6 Layer 212 weight diff: 1756.4470214844\nclient_6 Layer 213 weight diff: 2.2568671703\nclient_6 Layer 214 weight diff: 2.0076467991\nclient_6 Layer 215 weight diff: 32.7215499878\nclient_6 Layer 216 weight diff: 27.8947029114\nclient_6 Layer 217 weight diff: 1697.4766845703\nclient_6 Layer 218 weight diff: 2.1024136543\nclient_6 Layer 219 weight diff: 2.0076470375\nclient_6 Layer 220 weight diff: 745.5014038086\nclient_6 Layer 221 weight diff: 22260.7031250000\nclient_6 Layer 222 weight diff: 21.2161521912\nclient_6 Layer 223 weight diff: 3894.7431640625\nclient_6 Layer 224 weight diff: 3.3514578342\nclient_6 Layer 225 weight diff: 3.5452079773\nclient_6 Layer 226 weight diff: 161.3146972656\nclient_6 Layer 227 weight diff: 541.1893310547\nclient_6 Layer 228 weight diff: 30.6178398132\nclient_6 Layer 229 weight diff: 7097.9526367188\nclient_6 Layer 230 weight diff: 3.5903730392\nclient_6 Layer 231 weight diff: 3.7167596817\nclient_6 Layer 232 weight diff: 154.7067260742\nclient_6 Layer 233 weight diff: 152.2370605469\nclient_6 Layer 234 weight diff: 0.0000000000\nclient_6 Layer 235 weight diff: 0.0000000000\nclient_6 Layer 236 weight diff: 0.0000000000\nclient_6 Layer 237 weight diff: 0.0000000000\nclient_6 training accuracy history: [0.942105233669281, 0.969473659992218, 0.9852631688117981, 0.9905263185501099, 0.9894737005233765]\nclient_6 total local-global weight diff: 68691.50510728\n\n✅ Round 3 average client accuracy: 0.9886\n\n📈 Global model evaluation on test data: {'loss': 0.06505270302295685, 'compile_metrics': 0.9824561476707458}\n\n🔁 Federated Round 4\n\n📶 Training on client_1\nTraining client_1 for 5 epochs...\nSum of weights before training: 193923.656\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 945ms/step - accuracy: 0.9674 - loss: 0.1239 - precision_38: 0.9698 - recall_38: 0.9622\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 649ms/step - accuracy: 0.9797 - loss: 0.0709 - precision_38: 0.9797 - recall_38: 0.9764\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 650ms/step - accuracy: 0.9849 - loss: 0.0453 - precision_38: 0.9849 - recall_38: 0.9844\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 661ms/step - accuracy: 0.9883 - loss: 0.0519 - precision_38: 0.9899 - recall_38: 0.9842\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 642ms/step - accuracy: 0.9971 - loss: 0.0219 - precision_38: 0.9971 - recall_38: 0.9967\nSum of weights after training: 218441.219\nclient_1 Layer 0 weight diff: 0.0000000000\nclient_1 Layer 1 weight diff: 0.0000000000\nclient_1 Layer 2 weight diff: 0.0000000000\nclient_1 Layer 3 weight diff: 0.0000000000\nclient_1 Layer 4 weight diff: 0.0000000000\nclient_1 Layer 5 weight diff: 0.0000000000\nclient_1 Layer 6 weight diff: 0.0000000000\nclient_1 Layer 7 weight diff: 0.0000000000\nclient_1 Layer 8 weight diff: 0.0000000000\nclient_1 Layer 9 weight diff: 0.0000000000\nclient_1 Layer 10 weight diff: 0.0000000000\nclient_1 Layer 11 weight diff: 0.0000000000\nclient_1 Layer 12 weight diff: 0.0000000000\nclient_1 Layer 13 weight diff: 0.0000000000\nclient_1 Layer 14 weight diff: 0.0000000000\nclient_1 Layer 15 weight diff: 0.0000000000\nclient_1 Layer 16 weight diff: 0.0000000000\nclient_1 Layer 17 weight diff: 0.0000000000\nclient_1 Layer 18 weight diff: 0.0000000000\nclient_1 Layer 19 weight diff: 0.0000000000\nclient_1 Layer 20 weight diff: 0.0000000000\nclient_1 Layer 21 weight diff: 0.0000000000\nclient_1 Layer 22 weight diff: 0.0000000000\nclient_1 Layer 23 weight diff: 0.0000000000\nclient_1 Layer 24 weight diff: 0.0000000000\nclient_1 Layer 25 weight diff: 0.0000000000\nclient_1 Layer 26 weight diff: 0.0000000000\nclient_1 Layer 27 weight diff: 0.0000000000\nclient_1 Layer 28 weight diff: 0.0000000000\nclient_1 Layer 29 weight diff: 0.0000000000\nclient_1 Layer 30 weight diff: 0.0000000000\nclient_1 Layer 31 weight diff: 0.0000000000\nclient_1 Layer 32 weight diff: 0.0000000000\nclient_1 Layer 33 weight diff: 0.0000000000\nclient_1 Layer 34 weight diff: 0.0000000000\nclient_1 Layer 35 weight diff: 0.0000000000\nclient_1 Layer 36 weight diff: 0.0000000000\nclient_1 Layer 37 weight diff: 0.0000000000\nclient_1 Layer 38 weight diff: 0.0000000000\nclient_1 Layer 39 weight diff: 0.0000000000\nclient_1 Layer 40 weight diff: 0.0000000000\nclient_1 Layer 41 weight diff: 0.0000000000\nclient_1 Layer 42 weight diff: 0.0000000000\nclient_1 Layer 43 weight diff: 0.0000000000\nclient_1 Layer 44 weight diff: 0.0000000000\nclient_1 Layer 45 weight diff: 0.0000000000\nclient_1 Layer 46 weight diff: 0.0000000000\nclient_1 Layer 47 weight diff: 0.0000000000\nclient_1 Layer 48 weight diff: 0.0000000000\nclient_1 Layer 49 weight diff: 0.0000000000\nclient_1 Layer 50 weight diff: 0.0000000000\nclient_1 Layer 51 weight diff: 0.0000000000\nclient_1 Layer 52 weight diff: 0.0000000000\nclient_1 Layer 53 weight diff: 0.0000000000\nclient_1 Layer 54 weight diff: 0.0000000000\nclient_1 Layer 55 weight diff: 0.0000000000\nclient_1 Layer 56 weight diff: 0.0000000000\nclient_1 Layer 57 weight diff: 0.0000000000\nclient_1 Layer 58 weight diff: 0.0000000000\nclient_1 Layer 59 weight diff: 0.0000000000\nclient_1 Layer 60 weight diff: 0.0000000000\nclient_1 Layer 61 weight diff: 0.0000000000\nclient_1 Layer 62 weight diff: 0.0000000000\nclient_1 Layer 63 weight diff: 0.0000000000\nclient_1 Layer 64 weight diff: 0.0000000000\nclient_1 Layer 65 weight diff: 0.0000000000\nclient_1 Layer 66 weight diff: 0.0000000000\nclient_1 Layer 67 weight diff: 0.0000000000\nclient_1 Layer 68 weight diff: 0.0000000000\nclient_1 Layer 69 weight diff: 0.0000000000\nclient_1 Layer 70 weight diff: 0.0000000000\nclient_1 Layer 71 weight diff: 0.0000000000\nclient_1 Layer 72 weight diff: 0.0000000000\nclient_1 Layer 73 weight diff: 0.0000000000\nclient_1 Layer 74 weight diff: 0.0000000000\nclient_1 Layer 75 weight diff: 0.0000000000\nclient_1 Layer 76 weight diff: 0.0000000000\nclient_1 Layer 77 weight diff: 0.0000000000\nclient_1 Layer 78 weight diff: 0.0000000000\nclient_1 Layer 79 weight diff: 0.0000000000\nclient_1 Layer 80 weight diff: 0.0000000000\nclient_1 Layer 81 weight diff: 0.0000000000\nclient_1 Layer 82 weight diff: 0.0000000000\nclient_1 Layer 83 weight diff: 0.0000000000\nclient_1 Layer 84 weight diff: 0.0000000000\nclient_1 Layer 85 weight diff: 17.3918113708\nclient_1 Layer 86 weight diff: 1411.9779052734\nclient_1 Layer 87 weight diff: 1.8746534586\nclient_1 Layer 88 weight diff: 1.7990615368\nclient_1 Layer 89 weight diff: 15.2489337921\nclient_1 Layer 90 weight diff: 7.9771595001\nclient_1 Layer 91 weight diff: 17.0661525726\nclient_1 Layer 92 weight diff: 1464.6224365234\nclient_1 Layer 93 weight diff: 1.9984854460\nclient_1 Layer 94 weight diff: 1.9210034609\nclient_1 Layer 95 weight diff: 14.5373859406\nclient_1 Layer 96 weight diff: 36.1952362061\nclient_1 Layer 97 weight diff: 18.9085350037\nclient_1 Layer 98 weight diff: 1528.2290039062\nclient_1 Layer 99 weight diff: 1.9661238194\nclient_1 Layer 100 weight diff: 1.9921830893\nclient_1 Layer 101 weight diff: 32.1500549316\nclient_1 Layer 102 weight diff: 33.1267547607\nclient_1 Layer 103 weight diff: 18.2850685120\nclient_1 Layer 104 weight diff: 1530.6572265625\nclient_1 Layer 105 weight diff: 2.0014865398\nclient_1 Layer 106 weight diff: 2.0931179523\nclient_1 Layer 107 weight diff: 8.6099433899\nclient_1 Layer 108 weight diff: 9.3622159958\nclient_1 Layer 109 weight diff: 17.9355239868\nclient_1 Layer 110 weight diff: 1517.4589843750\nclient_1 Layer 111 weight diff: 2.0638129711\nclient_1 Layer 112 weight diff: 2.0280869007\nclient_1 Layer 113 weight diff: 6.8784646988\nclient_1 Layer 114 weight diff: 15.5623807907\nclient_1 Layer 115 weight diff: 18.0468444824\nclient_1 Layer 116 weight diff: 1532.5522460938\nclient_1 Layer 117 weight diff: 1.8773251772\nclient_1 Layer 118 weight diff: 1.9307849407\nclient_1 Layer 119 weight diff: 20.2401161194\nclient_1 Layer 120 weight diff: 28.7046279907\nclient_1 Layer 121 weight diff: 18.2257919312\nclient_1 Layer 122 weight diff: 1524.3038330078\nclient_1 Layer 123 weight diff: 1.9598873854\nclient_1 Layer 124 weight diff: 1.9840216637\nclient_1 Layer 125 weight diff: 9.7273683548\nclient_1 Layer 126 weight diff: 5.7788310051\nclient_1 Layer 127 weight diff: 18.1903762817\nclient_1 Layer 128 weight diff: 1521.5051269531\nclient_1 Layer 129 weight diff: 1.9712798595\nclient_1 Layer 130 weight diff: 2.0092842579\nclient_1 Layer 131 weight diff: 8.1071510315\nclient_1 Layer 132 weight diff: 4.1153821945\nclient_1 Layer 133 weight diff: 18.2090950012\nclient_1 Layer 134 weight diff: 1489.6101074219\nclient_1 Layer 135 weight diff: 2.0187540054\nclient_1 Layer 136 weight diff: 1.9933955669\nclient_1 Layer 137 weight diff: 32.5792999268\nclient_1 Layer 138 weight diff: 32.5709800720\nclient_1 Layer 139 weight diff: 18.4751548767\nclient_1 Layer 140 weight diff: 1473.9594726562\nclient_1 Layer 141 weight diff: 1.9230062962\nclient_1 Layer 142 weight diff: 1.9050530195\nclient_1 Layer 143 weight diff: 15.1045169830\nclient_1 Layer 144 weight diff: 8.4993991852\nclient_1 Layer 145 weight diff: 17.4200153351\nclient_1 Layer 146 weight diff: 1477.2850341797\nclient_1 Layer 147 weight diff: 1.9519677162\nclient_1 Layer 148 weight diff: 1.9328377247\nclient_1 Layer 149 weight diff: 17.5874862671\nclient_1 Layer 150 weight diff: 17.8025016785\nclient_1 Layer 151 weight diff: 19.0388031006\nclient_1 Layer 152 weight diff: 1554.3173828125\nclient_1 Layer 153 weight diff: 2.1599850655\nclient_1 Layer 154 weight diff: 2.2176964283\nclient_1 Layer 155 weight diff: 28.9670028687\nclient_1 Layer 156 weight diff: 30.5874862671\nclient_1 Layer 157 weight diff: 18.8039016724\nclient_1 Layer 158 weight diff: 1519.9047851562\nclient_1 Layer 159 weight diff: 2.0638475418\nclient_1 Layer 160 weight diff: 2.1018989086\nclient_1 Layer 161 weight diff: 12.3824300766\nclient_1 Layer 162 weight diff: 9.9283332825\nclient_1 Layer 163 weight diff: 18.0784149170\nclient_1 Layer 164 weight diff: 1489.2020263672\nclient_1 Layer 165 weight diff: 2.0319266319\nclient_1 Layer 166 weight diff: 1.9594218731\nclient_1 Layer 167 weight diff: 9.1699943542\nclient_1 Layer 168 weight diff: 10.4074115753\nclient_1 Layer 169 weight diff: 18.5321159363\nclient_1 Layer 170 weight diff: 1508.4655761719\nclient_1 Layer 171 weight diff: 2.0924024582\nclient_1 Layer 172 weight diff: 2.1181130409\nclient_1 Layer 173 weight diff: 32.5613708496\nclient_1 Layer 174 weight diff: 48.8073883057\nclient_1 Layer 175 weight diff: 18.1277618408\nclient_1 Layer 176 weight diff: 1471.1503906250\nclient_1 Layer 177 weight diff: 2.0191559792\nclient_1 Layer 178 weight diff: 2.0082488060\nclient_1 Layer 179 weight diff: 14.0387620926\nclient_1 Layer 180 weight diff: 15.5280475616\nclient_1 Layer 181 weight diff: 17.4477901459\nclient_1 Layer 182 weight diff: 1456.4483642578\nclient_1 Layer 183 weight diff: 2.0809214115\nclient_1 Layer 184 weight diff: 1.9301712513\nclient_1 Layer 185 weight diff: 8.6958341599\nclient_1 Layer 186 weight diff: 6.5629281998\nclient_1 Layer 187 weight diff: 18.7531261444\nclient_1 Layer 188 weight diff: 1473.0231933594\nclient_1 Layer 189 weight diff: 2.1385297775\nclient_1 Layer 190 weight diff: 2.1615304947\nclient_1 Layer 191 weight diff: 42.5278167725\nclient_1 Layer 192 weight diff: 57.3214416504\nclient_1 Layer 193 weight diff: 18.1763992310\nclient_1 Layer 194 weight diff: 1412.5439453125\nclient_1 Layer 195 weight diff: 1.9080933332\nclient_1 Layer 196 weight diff: 1.9087190628\nclient_1 Layer 197 weight diff: 20.7303733826\nclient_1 Layer 198 weight diff: 46.4757995605\nclient_1 Layer 199 weight diff: 17.2593803406\nclient_1 Layer 200 weight diff: 1363.3208007812\nclient_1 Layer 201 weight diff: 1.8485326767\nclient_1 Layer 202 weight diff: 1.9479258060\nclient_1 Layer 203 weight diff: 12.1435451508\nclient_1 Layer 204 weight diff: 31.7005691528\nclient_1 Layer 205 weight diff: 17.9156074524\nclient_1 Layer 206 weight diff: 1456.1323242188\nclient_1 Layer 207 weight diff: 1.8587207794\nclient_1 Layer 208 weight diff: 1.8729364872\nclient_1 Layer 209 weight diff: 83.7446289062\nclient_1 Layer 210 weight diff: 177.7189941406\nclient_1 Layer 211 weight diff: 17.3985557556\nclient_1 Layer 212 weight diff: 2004.6530761719\nclient_1 Layer 213 weight diff: 2.5241160393\nclient_1 Layer 214 weight diff: 2.1576271057\nclient_1 Layer 215 weight diff: 29.8652248383\nclient_1 Layer 216 weight diff: 18.0423698425\nclient_1 Layer 217 weight diff: 1998.8730468750\nclient_1 Layer 218 weight diff: 2.5834114552\nclient_1 Layer 219 weight diff: 2.1576271057\nclient_1 Layer 220 weight diff: 818.9511718750\nclient_1 Layer 221 weight diff: 32001.9394531250\nclient_1 Layer 222 weight diff: 23.6716613770\nclient_1 Layer 223 weight diff: 4181.5278320312\nclient_1 Layer 224 weight diff: 3.8685405254\nclient_1 Layer 225 weight diff: 3.8374180794\nclient_1 Layer 226 weight diff: 139.9919128418\nclient_1 Layer 227 weight diff: 423.3118591309\nclient_1 Layer 228 weight diff: 36.2073326111\nclient_1 Layer 229 weight diff: 7936.4135742188\nclient_1 Layer 230 weight diff: 4.9492545128\nclient_1 Layer 231 weight diff: 5.0138335228\nclient_1 Layer 232 weight diff: 312.8974914551\nclient_1 Layer 233 weight diff: 1131.6174316406\nclient_1 Layer 234 weight diff: 0.0000000000\nclient_1 Layer 235 weight diff: 0.0000000000\nclient_1 Layer 236 weight diff: 0.0000000000\nclient_1 Layer 237 weight diff: 0.0000000000\nclient_1 training accuracy history: [0.9643605947494507, 0.9790356159210205, 0.9811320900917053, 0.9884696006774902, 0.9947589039802551]\nclient_1 total local-global weight diff: 83823.50239801\n\n📶 Training on client_2\nTraining client_2 for 5 epochs...\nSum of weights before training: 193923.656\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 884ms/step - accuracy: 0.9596 - loss: 0.1710 - precision_39: 0.9649 - recall_39: 0.9553\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 650ms/step - accuracy: 0.9589 - loss: 0.1046 - precision_39: 0.9675 - recall_39: 0.9499\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 659ms/step - accuracy: 0.9813 - loss: 0.0487 - precision_39: 0.9813 - recall_39: 0.9813\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 665ms/step - accuracy: 0.9955 - loss: 0.0185 - precision_39: 0.9955 - recall_39: 0.9955\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 655ms/step - accuracy: 0.9967 - loss: 0.0150 - precision_39: 0.9967 - recall_39: 0.9967\nSum of weights after training: 194770.703\nclient_2 Layer 0 weight diff: 0.0000000000\nclient_2 Layer 1 weight diff: 0.0000000000\nclient_2 Layer 2 weight diff: 0.0000000000\nclient_2 Layer 3 weight diff: 0.0000000000\nclient_2 Layer 4 weight diff: 0.0000000000\nclient_2 Layer 5 weight diff: 0.0000000000\nclient_2 Layer 6 weight diff: 0.0000000000\nclient_2 Layer 7 weight diff: 0.0000000000\nclient_2 Layer 8 weight diff: 0.0000000000\nclient_2 Layer 9 weight diff: 0.0000000000\nclient_2 Layer 10 weight diff: 0.0000000000\nclient_2 Layer 11 weight diff: 0.0000000000\nclient_2 Layer 12 weight diff: 0.0000000000\nclient_2 Layer 13 weight diff: 0.0000000000\nclient_2 Layer 14 weight diff: 0.0000000000\nclient_2 Layer 15 weight diff: 0.0000000000\nclient_2 Layer 16 weight diff: 0.0000000000\nclient_2 Layer 17 weight diff: 0.0000000000\nclient_2 Layer 18 weight diff: 0.0000000000\nclient_2 Layer 19 weight diff: 0.0000000000\nclient_2 Layer 20 weight diff: 0.0000000000\nclient_2 Layer 21 weight diff: 0.0000000000\nclient_2 Layer 22 weight diff: 0.0000000000\nclient_2 Layer 23 weight diff: 0.0000000000\nclient_2 Layer 24 weight diff: 0.0000000000\nclient_2 Layer 25 weight diff: 0.0000000000\nclient_2 Layer 26 weight diff: 0.0000000000\nclient_2 Layer 27 weight diff: 0.0000000000\nclient_2 Layer 28 weight diff: 0.0000000000\nclient_2 Layer 29 weight diff: 0.0000000000\nclient_2 Layer 30 weight diff: 0.0000000000\nclient_2 Layer 31 weight diff: 0.0000000000\nclient_2 Layer 32 weight diff: 0.0000000000\nclient_2 Layer 33 weight diff: 0.0000000000\nclient_2 Layer 34 weight diff: 0.0000000000\nclient_2 Layer 35 weight diff: 0.0000000000\nclient_2 Layer 36 weight diff: 0.0000000000\nclient_2 Layer 37 weight diff: 0.0000000000\nclient_2 Layer 38 weight diff: 0.0000000000\nclient_2 Layer 39 weight diff: 0.0000000000\nclient_2 Layer 40 weight diff: 0.0000000000\nclient_2 Layer 41 weight diff: 0.0000000000\nclient_2 Layer 42 weight diff: 0.0000000000\nclient_2 Layer 43 weight diff: 0.0000000000\nclient_2 Layer 44 weight diff: 0.0000000000\nclient_2 Layer 45 weight diff: 0.0000000000\nclient_2 Layer 46 weight diff: 0.0000000000\nclient_2 Layer 47 weight diff: 0.0000000000\nclient_2 Layer 48 weight diff: 0.0000000000\nclient_2 Layer 49 weight diff: 0.0000000000\nclient_2 Layer 50 weight diff: 0.0000000000\nclient_2 Layer 51 weight diff: 0.0000000000\nclient_2 Layer 52 weight diff: 0.0000000000\nclient_2 Layer 53 weight diff: 0.0000000000\nclient_2 Layer 54 weight diff: 0.0000000000\nclient_2 Layer 55 weight diff: 0.0000000000\nclient_2 Layer 56 weight diff: 0.0000000000\nclient_2 Layer 57 weight diff: 0.0000000000\nclient_2 Layer 58 weight diff: 0.0000000000\nclient_2 Layer 59 weight diff: 0.0000000000\nclient_2 Layer 60 weight diff: 0.0000000000\nclient_2 Layer 61 weight diff: 0.0000000000\nclient_2 Layer 62 weight diff: 0.0000000000\nclient_2 Layer 63 weight diff: 0.0000000000\nclient_2 Layer 64 weight diff: 0.0000000000\nclient_2 Layer 65 weight diff: 0.0000000000\nclient_2 Layer 66 weight diff: 0.0000000000\nclient_2 Layer 67 weight diff: 0.0000000000\nclient_2 Layer 68 weight diff: 0.0000000000\nclient_2 Layer 69 weight diff: 0.0000000000\nclient_2 Layer 70 weight diff: 0.0000000000\nclient_2 Layer 71 weight diff: 0.0000000000\nclient_2 Layer 72 weight diff: 0.0000000000\nclient_2 Layer 73 weight diff: 0.0000000000\nclient_2 Layer 74 weight diff: 0.0000000000\nclient_2 Layer 75 weight diff: 0.0000000000\nclient_2 Layer 76 weight diff: 0.0000000000\nclient_2 Layer 77 weight diff: 0.0000000000\nclient_2 Layer 78 weight diff: 0.0000000000\nclient_2 Layer 79 weight diff: 0.0000000000\nclient_2 Layer 80 weight diff: 0.0000000000\nclient_2 Layer 81 weight diff: 0.0000000000\nclient_2 Layer 82 weight diff: 0.0000000000\nclient_2 Layer 83 weight diff: 0.0000000000\nclient_2 Layer 84 weight diff: 0.0000000000\nclient_2 Layer 85 weight diff: 19.7856140137\nclient_2 Layer 86 weight diff: 1568.6157226562\nclient_2 Layer 87 weight diff: 2.0886571407\nclient_2 Layer 88 weight diff: 2.0175356865\nclient_2 Layer 89 weight diff: 18.1615104675\nclient_2 Layer 90 weight diff: 8.7050275803\nclient_2 Layer 91 weight diff: 19.0529708862\nclient_2 Layer 92 weight diff: 1603.5354003906\nclient_2 Layer 93 weight diff: 2.1581239700\nclient_2 Layer 94 weight diff: 2.1114668846\nclient_2 Layer 95 weight diff: 17.3533668518\nclient_2 Layer 96 weight diff: 38.7972869873\nclient_2 Layer 97 weight diff: 21.1132297516\nclient_2 Layer 98 weight diff: 1675.9367675781\nclient_2 Layer 99 weight diff: 2.1915011406\nclient_2 Layer 100 weight diff: 2.2807464600\nclient_2 Layer 101 weight diff: 39.1827316284\nclient_2 Layer 102 weight diff: 33.0571975708\nclient_2 Layer 103 weight diff: 19.6073265076\nclient_2 Layer 104 weight diff: 1657.0854492188\nclient_2 Layer 105 weight diff: 2.1568875313\nclient_2 Layer 106 weight diff: 2.1458325386\nclient_2 Layer 107 weight diff: 10.0942583084\nclient_2 Layer 108 weight diff: 8.3382902145\nclient_2 Layer 109 weight diff: 20.4280929565\nclient_2 Layer 110 weight diff: 1668.5129394531\nclient_2 Layer 111 weight diff: 2.2545547485\nclient_2 Layer 112 weight diff: 2.0348293781\nclient_2 Layer 113 weight diff: 9.4189500809\nclient_2 Layer 114 weight diff: 16.9973068237\nclient_2 Layer 115 weight diff: 20.0383510590\nclient_2 Layer 116 weight diff: 1685.9956054688\nclient_2 Layer 117 weight diff: 2.2738685608\nclient_2 Layer 118 weight diff: 2.3106331825\nclient_2 Layer 119 weight diff: 21.7134246826\nclient_2 Layer 120 weight diff: 30.6724510193\nclient_2 Layer 121 weight diff: 20.4265174866\nclient_2 Layer 122 weight diff: 1669.9367675781\nclient_2 Layer 123 weight diff: 2.1937804222\nclient_2 Layer 124 weight diff: 2.1927750111\nclient_2 Layer 125 weight diff: 11.8032808304\nclient_2 Layer 126 weight diff: 6.3245248795\nclient_2 Layer 127 weight diff: 20.1115341187\nclient_2 Layer 128 weight diff: 1648.2558593750\nclient_2 Layer 129 weight diff: 2.1494784355\nclient_2 Layer 130 weight diff: 2.0526363850\nclient_2 Layer 131 weight diff: 9.5451450348\nclient_2 Layer 132 weight diff: 5.3210811615\nclient_2 Layer 133 weight diff: 19.6055908203\nclient_2 Layer 134 weight diff: 1631.5544433594\nclient_2 Layer 135 weight diff: 2.1539933681\nclient_2 Layer 136 weight diff: 2.1200127602\nclient_2 Layer 137 weight diff: 44.6140823364\nclient_2 Layer 138 weight diff: 39.2154197693\nclient_2 Layer 139 weight diff: 19.1906337738\nclient_2 Layer 140 weight diff: 1608.3095703125\nclient_2 Layer 141 weight diff: 2.2286386490\nclient_2 Layer 142 weight diff: 2.2194502354\nclient_2 Layer 143 weight diff: 21.6461105347\nclient_2 Layer 144 weight diff: 11.1194524765\nclient_2 Layer 145 weight diff: 19.5224761963\nclient_2 Layer 146 weight diff: 1607.8557128906\nclient_2 Layer 147 weight diff: 2.1280541420\nclient_2 Layer 148 weight diff: 2.1535630226\nclient_2 Layer 149 weight diff: 19.0481452942\nclient_2 Layer 150 weight diff: 13.0068817139\nclient_2 Layer 151 weight diff: 21.2040920258\nclient_2 Layer 152 weight diff: 1683.9788818359\nclient_2 Layer 153 weight diff: 2.2097687721\nclient_2 Layer 154 weight diff: 2.3726601601\nclient_2 Layer 155 weight diff: 39.2677726746\nclient_2 Layer 156 weight diff: 41.1109619141\nclient_2 Layer 157 weight diff: 19.7663917542\nclient_2 Layer 158 weight diff: 1635.2062988281\nclient_2 Layer 159 weight diff: 2.2702298164\nclient_2 Layer 160 weight diff: 2.2510552406\nclient_2 Layer 161 weight diff: 13.4332742691\nclient_2 Layer 162 weight diff: 10.8171806335\nclient_2 Layer 163 weight diff: 19.6614265442\nclient_2 Layer 164 weight diff: 1621.8447265625\nclient_2 Layer 165 weight diff: 2.1560046673\nclient_2 Layer 166 weight diff: 2.1385169029\nclient_2 Layer 167 weight diff: 9.4005451202\nclient_2 Layer 168 weight diff: 11.1408100128\nclient_2 Layer 169 weight diff: 20.6338539124\nclient_2 Layer 170 weight diff: 1645.9675292969\nclient_2 Layer 171 weight diff: 2.2672319412\nclient_2 Layer 172 weight diff: 2.3267762661\nclient_2 Layer 173 weight diff: 39.2995758057\nclient_2 Layer 174 weight diff: 47.0796508789\nclient_2 Layer 175 weight diff: 20.2414512634\nclient_2 Layer 176 weight diff: 1605.0900878906\nclient_2 Layer 177 weight diff: 2.0751729012\nclient_2 Layer 178 weight diff: 2.1136412621\nclient_2 Layer 179 weight diff: 16.4505844116\nclient_2 Layer 180 weight diff: 15.9627017975\nclient_2 Layer 181 weight diff: 19.4773693085\nclient_2 Layer 182 weight diff: 1588.3948974609\nclient_2 Layer 183 weight diff: 2.2831318378\nclient_2 Layer 184 weight diff: 2.1131772995\nclient_2 Layer 185 weight diff: 10.8305130005\nclient_2 Layer 186 weight diff: 13.3591833115\nclient_2 Layer 187 weight diff: 20.8772010803\nclient_2 Layer 188 weight diff: 1626.9909667969\nclient_2 Layer 189 weight diff: 2.2300863266\nclient_2 Layer 190 weight diff: 2.2480807304\nclient_2 Layer 191 weight diff: 54.5426177979\nclient_2 Layer 192 weight diff: 82.0517501831\nclient_2 Layer 193 weight diff: 19.5610809326\nclient_2 Layer 194 weight diff: 1586.7783203125\nclient_2 Layer 195 weight diff: 2.1281111240\nclient_2 Layer 196 weight diff: 2.1088762283\nclient_2 Layer 197 weight diff: 22.2928714752\nclient_2 Layer 198 weight diff: 27.0109748840\nclient_2 Layer 199 weight diff: 18.6155223846\nclient_2 Layer 200 weight diff: 1553.4239501953\nclient_2 Layer 201 weight diff: 2.1201989651\nclient_2 Layer 202 weight diff: 2.1033487320\nclient_2 Layer 203 weight diff: 13.2835216522\nclient_2 Layer 204 weight diff: 18.2599620819\nclient_2 Layer 205 weight diff: 18.7067642212\nclient_2 Layer 206 weight diff: 1558.2459716797\nclient_2 Layer 207 weight diff: 1.9930469990\nclient_2 Layer 208 weight diff: 2.0492258072\nclient_2 Layer 209 weight diff: 80.3274078369\nclient_2 Layer 210 weight diff: 426.0650634766\nclient_2 Layer 211 weight diff: 18.6486244202\nclient_2 Layer 212 weight diff: 2144.8178710938\nclient_2 Layer 213 weight diff: 2.8056383133\nclient_2 Layer 214 weight diff: 2.6521906853\nclient_2 Layer 215 weight diff: 30.0256652832\nclient_2 Layer 216 weight diff: 33.8655700684\nclient_2 Layer 217 weight diff: 2176.8647460938\nclient_2 Layer 218 weight diff: 2.9977459908\nclient_2 Layer 219 weight diff: 2.6521904469\nclient_2 Layer 220 weight diff: 920.6834106445\nclient_2 Layer 221 weight diff: 22753.6914062500\nclient_2 Layer 222 weight diff: 25.9792861938\nclient_2 Layer 223 weight diff: 4505.9306640625\nclient_2 Layer 224 weight diff: 4.0605382919\nclient_2 Layer 225 weight diff: 4.1661062241\nclient_2 Layer 226 weight diff: 168.7074890137\nclient_2 Layer 227 weight diff: 654.9285278320\nclient_2 Layer 228 weight diff: 38.1164970398\nclient_2 Layer 229 weight diff: 8457.8310546875\nclient_2 Layer 230 weight diff: 5.5545091629\nclient_2 Layer 231 weight diff: 5.6540851593\nclient_2 Layer 232 weight diff: 408.9859008789\nclient_2 Layer 233 weight diff: 1636.8666992188\nclient_2 Layer 234 weight diff: 0.0000000000\nclient_2 Layer 235 weight diff: 0.0000000000\nclient_2 Layer 236 weight diff: 0.0000000000\nclient_2 Layer 237 weight diff: 0.0000000000\nclient_2 training accuracy history: [0.9453781247138977, 0.9695377945899963, 0.9831932783126831, 0.993697464466095, 0.9947478771209717]\nclient_2 total local-global weight diff: 80072.92798829\n\n📶 Training on client_3\nTraining client_3 for 5 epochs...\nSum of weights before training: 193923.656\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 936ms/step - accuracy: 0.9611 - loss: 0.1462 - precision_40: 0.9642 - recall_40: 0.9581\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 650ms/step - accuracy: 0.9780 - loss: 0.0691 - precision_40: 0.9826 - recall_40: 0.9763\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 647ms/step - accuracy: 0.9871 - loss: 0.0352 - precision_40: 0.9871 - recall_40: 0.9871\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 655ms/step - accuracy: 0.9917 - loss: 0.0560 - precision_40: 0.9917 - recall_40: 0.9895\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 647ms/step - accuracy: 0.9901 - loss: 0.0276 - precision_40: 0.9902 - recall_40: 0.9901\nSum of weights after training: 212823.016\nclient_3 Layer 0 weight diff: 0.0000000000\nclient_3 Layer 1 weight diff: 0.0000000000\nclient_3 Layer 2 weight diff: 0.0000000000\nclient_3 Layer 3 weight diff: 0.0000000000\nclient_3 Layer 4 weight diff: 0.0000000000\nclient_3 Layer 5 weight diff: 0.0000000000\nclient_3 Layer 6 weight diff: 0.0000000000\nclient_3 Layer 7 weight diff: 0.0000000000\nclient_3 Layer 8 weight diff: 0.0000000000\nclient_3 Layer 9 weight diff: 0.0000000000\nclient_3 Layer 10 weight diff: 0.0000000000\nclient_3 Layer 11 weight diff: 0.0000000000\nclient_3 Layer 12 weight diff: 0.0000000000\nclient_3 Layer 13 weight diff: 0.0000000000\nclient_3 Layer 14 weight diff: 0.0000000000\nclient_3 Layer 15 weight diff: 0.0000000000\nclient_3 Layer 16 weight diff: 0.0000000000\nclient_3 Layer 17 weight diff: 0.0000000000\nclient_3 Layer 18 weight diff: 0.0000000000\nclient_3 Layer 19 weight diff: 0.0000000000\nclient_3 Layer 20 weight diff: 0.0000000000\nclient_3 Layer 21 weight diff: 0.0000000000\nclient_3 Layer 22 weight diff: 0.0000000000\nclient_3 Layer 23 weight diff: 0.0000000000\nclient_3 Layer 24 weight diff: 0.0000000000\nclient_3 Layer 25 weight diff: 0.0000000000\nclient_3 Layer 26 weight diff: 0.0000000000\nclient_3 Layer 27 weight diff: 0.0000000000\nclient_3 Layer 28 weight diff: 0.0000000000\nclient_3 Layer 29 weight diff: 0.0000000000\nclient_3 Layer 30 weight diff: 0.0000000000\nclient_3 Layer 31 weight diff: 0.0000000000\nclient_3 Layer 32 weight diff: 0.0000000000\nclient_3 Layer 33 weight diff: 0.0000000000\nclient_3 Layer 34 weight diff: 0.0000000000\nclient_3 Layer 35 weight diff: 0.0000000000\nclient_3 Layer 36 weight diff: 0.0000000000\nclient_3 Layer 37 weight diff: 0.0000000000\nclient_3 Layer 38 weight diff: 0.0000000000\nclient_3 Layer 39 weight diff: 0.0000000000\nclient_3 Layer 40 weight diff: 0.0000000000\nclient_3 Layer 41 weight diff: 0.0000000000\nclient_3 Layer 42 weight diff: 0.0000000000\nclient_3 Layer 43 weight diff: 0.0000000000\nclient_3 Layer 44 weight diff: 0.0000000000\nclient_3 Layer 45 weight diff: 0.0000000000\nclient_3 Layer 46 weight diff: 0.0000000000\nclient_3 Layer 47 weight diff: 0.0000000000\nclient_3 Layer 48 weight diff: 0.0000000000\nclient_3 Layer 49 weight diff: 0.0000000000\nclient_3 Layer 50 weight diff: 0.0000000000\nclient_3 Layer 51 weight diff: 0.0000000000\nclient_3 Layer 52 weight diff: 0.0000000000\nclient_3 Layer 53 weight diff: 0.0000000000\nclient_3 Layer 54 weight diff: 0.0000000000\nclient_3 Layer 55 weight diff: 0.0000000000\nclient_3 Layer 56 weight diff: 0.0000000000\nclient_3 Layer 57 weight diff: 0.0000000000\nclient_3 Layer 58 weight diff: 0.0000000000\nclient_3 Layer 59 weight diff: 0.0000000000\nclient_3 Layer 60 weight diff: 0.0000000000\nclient_3 Layer 61 weight diff: 0.0000000000\nclient_3 Layer 62 weight diff: 0.0000000000\nclient_3 Layer 63 weight diff: 0.0000000000\nclient_3 Layer 64 weight diff: 0.0000000000\nclient_3 Layer 65 weight diff: 0.0000000000\nclient_3 Layer 66 weight diff: 0.0000000000\nclient_3 Layer 67 weight diff: 0.0000000000\nclient_3 Layer 68 weight diff: 0.0000000000\nclient_3 Layer 69 weight diff: 0.0000000000\nclient_3 Layer 70 weight diff: 0.0000000000\nclient_3 Layer 71 weight diff: 0.0000000000\nclient_3 Layer 72 weight diff: 0.0000000000\nclient_3 Layer 73 weight diff: 0.0000000000\nclient_3 Layer 74 weight diff: 0.0000000000\nclient_3 Layer 75 weight diff: 0.0000000000\nclient_3 Layer 76 weight diff: 0.0000000000\nclient_3 Layer 77 weight diff: 0.0000000000\nclient_3 Layer 78 weight diff: 0.0000000000\nclient_3 Layer 79 weight diff: 0.0000000000\nclient_3 Layer 80 weight diff: 0.0000000000\nclient_3 Layer 81 weight diff: 0.0000000000\nclient_3 Layer 82 weight diff: 0.0000000000\nclient_3 Layer 83 weight diff: 0.0000000000\nclient_3 Layer 84 weight diff: 0.0000000000\nclient_3 Layer 85 weight diff: 18.5416870117\nclient_3 Layer 86 weight diff: 1472.7536621094\nclient_3 Layer 87 weight diff: 1.8770191669\nclient_3 Layer 88 weight diff: 1.9168881178\nclient_3 Layer 89 weight diff: 16.4640769958\nclient_3 Layer 90 weight diff: 7.7937860489\nclient_3 Layer 91 weight diff: 17.6133804321\nclient_3 Layer 92 weight diff: 1527.4233398438\nclient_3 Layer 93 weight diff: 2.1086411476\nclient_3 Layer 94 weight diff: 2.1128973961\nclient_3 Layer 95 weight diff: 14.2364912033\nclient_3 Layer 96 weight diff: 38.8973236084\nclient_3 Layer 97 weight diff: 20.4893016815\nclient_3 Layer 98 weight diff: 1627.1744384766\nclient_3 Layer 99 weight diff: 2.2786688805\nclient_3 Layer 100 weight diff: 2.1824793816\nclient_3 Layer 101 weight diff: 35.6969871521\nclient_3 Layer 102 weight diff: 37.0038909912\nclient_3 Layer 103 weight diff: 19.5164890289\nclient_3 Layer 104 weight diff: 1610.4095458984\nclient_3 Layer 105 weight diff: 2.2170605659\nclient_3 Layer 106 weight diff: 2.1918358803\nclient_3 Layer 107 weight diff: 8.7291526794\nclient_3 Layer 108 weight diff: 9.2185554504\nclient_3 Layer 109 weight diff: 19.6087684631\nclient_3 Layer 110 weight diff: 1596.8710937500\nclient_3 Layer 111 weight diff: 2.0442543030\nclient_3 Layer 112 weight diff: 2.1536605358\nclient_3 Layer 113 weight diff: 7.9785828590\nclient_3 Layer 114 weight diff: 17.6484451294\nclient_3 Layer 115 weight diff: 19.2045898438\nclient_3 Layer 116 weight diff: 1626.5780029297\nclient_3 Layer 117 weight diff: 2.2069087029\nclient_3 Layer 118 weight diff: 2.1207063198\nclient_3 Layer 119 weight diff: 22.2841033936\nclient_3 Layer 120 weight diff: 30.8803634644\nclient_3 Layer 121 weight diff: 19.7378463745\nclient_3 Layer 122 weight diff: 1615.2601318359\nclient_3 Layer 123 weight diff: 2.0672583580\nclient_3 Layer 124 weight diff: 2.1317207813\nclient_3 Layer 125 weight diff: 12.0734214783\nclient_3 Layer 126 weight diff: 6.3332405090\nclient_3 Layer 127 weight diff: 18.6251354218\nclient_3 Layer 128 weight diff: 1591.5335693359\nclient_3 Layer 129 weight diff: 2.2064113617\nclient_3 Layer 130 weight diff: 2.1539945602\nclient_3 Layer 131 weight diff: 8.6412429810\nclient_3 Layer 132 weight diff: 7.0254297256\nclient_3 Layer 133 weight diff: 20.0589866638\nclient_3 Layer 134 weight diff: 1552.2324218750\nclient_3 Layer 135 weight diff: 2.0752520561\nclient_3 Layer 136 weight diff: 2.1434540749\nclient_3 Layer 137 weight diff: 39.6010093689\nclient_3 Layer 138 weight diff: 31.0231323242\nclient_3 Layer 139 weight diff: 19.0105323792\nclient_3 Layer 140 weight diff: 1530.2075195312\nclient_3 Layer 141 weight diff: 2.1517488956\nclient_3 Layer 142 weight diff: 2.1708517075\nclient_3 Layer 143 weight diff: 15.3718299866\nclient_3 Layer 144 weight diff: 9.0906763077\nclient_3 Layer 145 weight diff: 19.0657119751\nclient_3 Layer 146 weight diff: 1544.5827636719\nclient_3 Layer 147 weight diff: 2.0712790489\nclient_3 Layer 148 weight diff: 2.0905976295\nclient_3 Layer 149 weight diff: 17.2064113617\nclient_3 Layer 150 weight diff: 12.0581693649\nclient_3 Layer 151 weight diff: 20.4231987000\nclient_3 Layer 152 weight diff: 1600.2052001953\nclient_3 Layer 153 weight diff: 2.0844957829\nclient_3 Layer 154 weight diff: 2.2134625912\nclient_3 Layer 155 weight diff: 31.8802890778\nclient_3 Layer 156 weight diff: 31.9184112549\nclient_3 Layer 157 weight diff: 19.5239601135\nclient_3 Layer 158 weight diff: 1578.3298339844\nclient_3 Layer 159 weight diff: 2.1563105583\nclient_3 Layer 160 weight diff: 2.1922087669\nclient_3 Layer 161 weight diff: 14.3346233368\nclient_3 Layer 162 weight diff: 9.5814809799\nclient_3 Layer 163 weight diff: 19.3992481232\nclient_3 Layer 164 weight diff: 1565.4287109375\nclient_3 Layer 165 weight diff: 2.1554787159\nclient_3 Layer 166 weight diff: 2.1319298744\nclient_3 Layer 167 weight diff: 8.5454082489\nclient_3 Layer 168 weight diff: 9.6457223892\nclient_3 Layer 169 weight diff: 20.0599594116\nclient_3 Layer 170 weight diff: 1590.2529296875\nclient_3 Layer 171 weight diff: 2.1562962532\nclient_3 Layer 172 weight diff: 2.2363591194\nclient_3 Layer 173 weight diff: 37.0949287415\nclient_3 Layer 174 weight diff: 47.7628097534\nclient_3 Layer 175 weight diff: 19.2340812683\nclient_3 Layer 176 weight diff: 1546.6281738281\nclient_3 Layer 177 weight diff: 2.1714982986\nclient_3 Layer 178 weight diff: 2.1548502445\nclient_3 Layer 179 weight diff: 13.1500740051\nclient_3 Layer 180 weight diff: 18.7331027985\nclient_3 Layer 181 weight diff: 18.9201259613\nclient_3 Layer 182 weight diff: 1516.8225097656\nclient_3 Layer 183 weight diff: 2.0960445404\nclient_3 Layer 184 weight diff: 2.1114048958\nclient_3 Layer 185 weight diff: 9.8255844116\nclient_3 Layer 186 weight diff: 8.0000810623\nclient_3 Layer 187 weight diff: 19.3253021240\nclient_3 Layer 188 weight diff: 1543.7467041016\nclient_3 Layer 189 weight diff: 1.9606155157\nclient_3 Layer 190 weight diff: 2.0258822441\nclient_3 Layer 191 weight diff: 46.0608749390\nclient_3 Layer 192 weight diff: 55.6972732544\nclient_3 Layer 193 weight diff: 18.4680786133\nclient_3 Layer 194 weight diff: 1498.5631103516\nclient_3 Layer 195 weight diff: 1.9979109764\nclient_3 Layer 196 weight diff: 2.0231089592\nclient_3 Layer 197 weight diff: 18.3873538971\nclient_3 Layer 198 weight diff: 26.9699077606\nclient_3 Layer 199 weight diff: 17.4618549347\nclient_3 Layer 200 weight diff: 1474.2332763672\nclient_3 Layer 201 weight diff: 1.9598476887\nclient_3 Layer 202 weight diff: 2.0034732819\nclient_3 Layer 203 weight diff: 12.2139291763\nclient_3 Layer 204 weight diff: 12.6848754883\nclient_3 Layer 205 weight diff: 18.0129318237\nclient_3 Layer 206 weight diff: 1490.4177246094\nclient_3 Layer 207 weight diff: 1.8828833103\nclient_3 Layer 208 weight diff: 1.8844482899\nclient_3 Layer 209 weight diff: 98.6614990234\nclient_3 Layer 210 weight diff: 257.9951782227\nclient_3 Layer 211 weight diff: 18.2095737457\nclient_3 Layer 212 weight diff: 2051.2248535156\nclient_3 Layer 213 weight diff: 2.7167625427\nclient_3 Layer 214 weight diff: 2.5114147663\nclient_3 Layer 215 weight diff: 26.2395019531\nclient_3 Layer 216 weight diff: 21.0672760010\nclient_3 Layer 217 weight diff: 2045.8854980469\nclient_3 Layer 218 weight diff: 2.6715869904\nclient_3 Layer 219 weight diff: 2.5114145279\nclient_3 Layer 220 weight diff: 920.6598510742\nclient_3 Layer 221 weight diff: 28568.6074218750\nclient_3 Layer 222 weight diff: 25.4965686798\nclient_3 Layer 223 weight diff: 4319.7456054688\nclient_3 Layer 224 weight diff: 3.8568243980\nclient_3 Layer 225 weight diff: 3.9864933491\nclient_3 Layer 226 weight diff: 139.8102416992\nclient_3 Layer 227 weight diff: 472.6671447754\nclient_3 Layer 228 weight diff: 36.8450088501\nclient_3 Layer 229 weight diff: 8143.5039062500\nclient_3 Layer 230 weight diff: 5.0173387527\nclient_3 Layer 231 weight diff: 5.1384453773\nclient_3 Layer 232 weight diff: 235.7072753906\nclient_3 Layer 233 weight diff: 582.0651855469\nclient_3 Layer 234 weight diff: 0.0000000000\nclient_3 Layer 235 weight diff: 0.0000000000\nclient_3 Layer 236 weight diff: 0.0000000000\nclient_3 Layer 237 weight diff: 0.0000000000\nclient_3 training accuracy history: [0.9579831957817078, 0.9768907427787781, 0.9873949289321899, 0.9905462265014648, 0.9905462265014648]\nclient_3 total local-global weight diff: 82000.77285600\n\n📶 Training on client_4\nTraining client_4 for 5 epochs...\nSum of weights before training: 193923.656\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 903ms/step - accuracy: 0.9735 - loss: 0.1050 - precision_41: 0.9738 - recall_41: 0.9712\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 642ms/step - accuracy: 0.9715 - loss: 0.0819 - precision_41: 0.9784 - recall_41: 0.9715\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 638ms/step - accuracy: 0.9831 - loss: 0.0545 - precision_41: 0.9850 - recall_41: 0.9800\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 680ms/step - accuracy: 0.9946 - loss: 0.0212 - precision_41: 0.9946 - recall_41: 0.9946\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 643ms/step - accuracy: 0.9935 - loss: 0.0274 - precision_41: 0.9939 - recall_41: 0.9935\nSum of weights after training: 212473.906\nclient_4 Layer 0 weight diff: 0.0000000000\nclient_4 Layer 1 weight diff: 0.0000000000\nclient_4 Layer 2 weight diff: 0.0000000000\nclient_4 Layer 3 weight diff: 0.0000000000\nclient_4 Layer 4 weight diff: 0.0000000000\nclient_4 Layer 5 weight diff: 0.0000000000\nclient_4 Layer 6 weight diff: 0.0000000000\nclient_4 Layer 7 weight diff: 0.0000000000\nclient_4 Layer 8 weight diff: 0.0000000000\nclient_4 Layer 9 weight diff: 0.0000000000\nclient_4 Layer 10 weight diff: 0.0000000000\nclient_4 Layer 11 weight diff: 0.0000000000\nclient_4 Layer 12 weight diff: 0.0000000000\nclient_4 Layer 13 weight diff: 0.0000000000\nclient_4 Layer 14 weight diff: 0.0000000000\nclient_4 Layer 15 weight diff: 0.0000000000\nclient_4 Layer 16 weight diff: 0.0000000000\nclient_4 Layer 17 weight diff: 0.0000000000\nclient_4 Layer 18 weight diff: 0.0000000000\nclient_4 Layer 19 weight diff: 0.0000000000\nclient_4 Layer 20 weight diff: 0.0000000000\nclient_4 Layer 21 weight diff: 0.0000000000\nclient_4 Layer 22 weight diff: 0.0000000000\nclient_4 Layer 23 weight diff: 0.0000000000\nclient_4 Layer 24 weight diff: 0.0000000000\nclient_4 Layer 25 weight diff: 0.0000000000\nclient_4 Layer 26 weight diff: 0.0000000000\nclient_4 Layer 27 weight diff: 0.0000000000\nclient_4 Layer 28 weight diff: 0.0000000000\nclient_4 Layer 29 weight diff: 0.0000000000\nclient_4 Layer 30 weight diff: 0.0000000000\nclient_4 Layer 31 weight diff: 0.0000000000\nclient_4 Layer 32 weight diff: 0.0000000000\nclient_4 Layer 33 weight diff: 0.0000000000\nclient_4 Layer 34 weight diff: 0.0000000000\nclient_4 Layer 35 weight diff: 0.0000000000\nclient_4 Layer 36 weight diff: 0.0000000000\nclient_4 Layer 37 weight diff: 0.0000000000\nclient_4 Layer 38 weight diff: 0.0000000000\nclient_4 Layer 39 weight diff: 0.0000000000\nclient_4 Layer 40 weight diff: 0.0000000000\nclient_4 Layer 41 weight diff: 0.0000000000\nclient_4 Layer 42 weight diff: 0.0000000000\nclient_4 Layer 43 weight diff: 0.0000000000\nclient_4 Layer 44 weight diff: 0.0000000000\nclient_4 Layer 45 weight diff: 0.0000000000\nclient_4 Layer 46 weight diff: 0.0000000000\nclient_4 Layer 47 weight diff: 0.0000000000\nclient_4 Layer 48 weight diff: 0.0000000000\nclient_4 Layer 49 weight diff: 0.0000000000\nclient_4 Layer 50 weight diff: 0.0000000000\nclient_4 Layer 51 weight diff: 0.0000000000\nclient_4 Layer 52 weight diff: 0.0000000000\nclient_4 Layer 53 weight diff: 0.0000000000\nclient_4 Layer 54 weight diff: 0.0000000000\nclient_4 Layer 55 weight diff: 0.0000000000\nclient_4 Layer 56 weight diff: 0.0000000000\nclient_4 Layer 57 weight diff: 0.0000000000\nclient_4 Layer 58 weight diff: 0.0000000000\nclient_4 Layer 59 weight diff: 0.0000000000\nclient_4 Layer 60 weight diff: 0.0000000000\nclient_4 Layer 61 weight diff: 0.0000000000\nclient_4 Layer 62 weight diff: 0.0000000000\nclient_4 Layer 63 weight diff: 0.0000000000\nclient_4 Layer 64 weight diff: 0.0000000000\nclient_4 Layer 65 weight diff: 0.0000000000\nclient_4 Layer 66 weight diff: 0.0000000000\nclient_4 Layer 67 weight diff: 0.0000000000\nclient_4 Layer 68 weight diff: 0.0000000000\nclient_4 Layer 69 weight diff: 0.0000000000\nclient_4 Layer 70 weight diff: 0.0000000000\nclient_4 Layer 71 weight diff: 0.0000000000\nclient_4 Layer 72 weight diff: 0.0000000000\nclient_4 Layer 73 weight diff: 0.0000000000\nclient_4 Layer 74 weight diff: 0.0000000000\nclient_4 Layer 75 weight diff: 0.0000000000\nclient_4 Layer 76 weight diff: 0.0000000000\nclient_4 Layer 77 weight diff: 0.0000000000\nclient_4 Layer 78 weight diff: 0.0000000000\nclient_4 Layer 79 weight diff: 0.0000000000\nclient_4 Layer 80 weight diff: 0.0000000000\nclient_4 Layer 81 weight diff: 0.0000000000\nclient_4 Layer 82 weight diff: 0.0000000000\nclient_4 Layer 83 weight diff: 0.0000000000\nclient_4 Layer 84 weight diff: 0.0000000000\nclient_4 Layer 85 weight diff: 17.7762584686\nclient_4 Layer 86 weight diff: 1418.1690673828\nclient_4 Layer 87 weight diff: 1.8891873360\nclient_4 Layer 88 weight diff: 1.8416223526\nclient_4 Layer 89 weight diff: 15.3836460114\nclient_4 Layer 90 weight diff: 7.3834476471\nclient_4 Layer 91 weight diff: 17.1153945923\nclient_4 Layer 92 weight diff: 1473.9313964844\nclient_4 Layer 93 weight diff: 1.9597926140\nclient_4 Layer 94 weight diff: 1.9894028902\nclient_4 Layer 95 weight diff: 14.6922779083\nclient_4 Layer 96 weight diff: 38.4584655762\nclient_4 Layer 97 weight diff: 18.7337875366\nclient_4 Layer 98 weight diff: 1524.6687011719\nclient_4 Layer 99 weight diff: 1.9799954891\nclient_4 Layer 100 weight diff: 1.9260845184\nclient_4 Layer 101 weight diff: 31.9317359924\nclient_4 Layer 102 weight diff: 31.0403900146\nclient_4 Layer 103 weight diff: 18.5830917358\nclient_4 Layer 104 weight diff: 1518.0385742188\nclient_4 Layer 105 weight diff: 1.9613680840\nclient_4 Layer 106 weight diff: 1.9505364895\nclient_4 Layer 107 weight diff: 8.3965892792\nclient_4 Layer 108 weight diff: 7.8561964035\nclient_4 Layer 109 weight diff: 18.3044681549\nclient_4 Layer 110 weight diff: 1535.3946533203\nclient_4 Layer 111 weight diff: 2.0765123367\nclient_4 Layer 112 weight diff: 2.0047502518\nclient_4 Layer 113 weight diff: 6.7617397308\nclient_4 Layer 114 weight diff: 18.4416313171\nclient_4 Layer 115 weight diff: 19.4691123962\nclient_4 Layer 116 weight diff: 1553.2521972656\nclient_4 Layer 117 weight diff: 2.0633258820\nclient_4 Layer 118 weight diff: 2.1533722878\nclient_4 Layer 119 weight diff: 19.7094230652\nclient_4 Layer 120 weight diff: 27.3500785828\nclient_4 Layer 121 weight diff: 18.4356403351\nclient_4 Layer 122 weight diff: 1541.2084960938\nclient_4 Layer 123 weight diff: 2.0462558270\nclient_4 Layer 124 weight diff: 2.0518651009\nclient_4 Layer 125 weight diff: 10.4652976990\nclient_4 Layer 126 weight diff: 5.7772574425\nclient_4 Layer 127 weight diff: 18.0288047791\nclient_4 Layer 128 weight diff: 1531.7062988281\nclient_4 Layer 129 weight diff: 2.0290806293\nclient_4 Layer 130 weight diff: 1.9728314877\nclient_4 Layer 131 weight diff: 8.1580934525\nclient_4 Layer 132 weight diff: 3.7687878609\nclient_4 Layer 133 weight diff: 18.4509239197\nclient_4 Layer 134 weight diff: 1501.0657958984\nclient_4 Layer 135 weight diff: 1.9686627388\nclient_4 Layer 136 weight diff: 1.9703559875\nclient_4 Layer 137 weight diff: 34.1386489868\nclient_4 Layer 138 weight diff: 31.4839973450\nclient_4 Layer 139 weight diff: 18.2189407349\nclient_4 Layer 140 weight diff: 1487.7934570312\nclient_4 Layer 141 weight diff: 1.9410786629\nclient_4 Layer 142 weight diff: 1.9944221973\nclient_4 Layer 143 weight diff: 15.6738815308\nclient_4 Layer 144 weight diff: 9.7077074051\nclient_4 Layer 145 weight diff: 17.4959449768\nclient_4 Layer 146 weight diff: 1506.6169433594\nclient_4 Layer 147 weight diff: 2.0646424294\nclient_4 Layer 148 weight diff: 2.0398433208\nclient_4 Layer 149 weight diff: 18.3080024719\nclient_4 Layer 150 weight diff: 15.4768371582\nclient_4 Layer 151 weight diff: 19.5794448853\nclient_4 Layer 152 weight diff: 1554.6450195312\nclient_4 Layer 153 weight diff: 2.0859208107\nclient_4 Layer 154 weight diff: 2.1853659153\nclient_4 Layer 155 weight diff: 29.2008056641\nclient_4 Layer 156 weight diff: 30.9118957520\nclient_4 Layer 157 weight diff: 18.3639297485\nclient_4 Layer 158 weight diff: 1531.7900390625\nclient_4 Layer 159 weight diff: 2.0697922707\nclient_4 Layer 160 weight diff: 2.0658578873\nclient_4 Layer 161 weight diff: 12.3000268936\nclient_4 Layer 162 weight diff: 11.3325099945\nclient_4 Layer 163 weight diff: 18.3058204651\nclient_4 Layer 164 weight diff: 1512.7294921875\nclient_4 Layer 165 weight diff: 2.0181419849\nclient_4 Layer 166 weight diff: 1.9729146957\nclient_4 Layer 167 weight diff: 8.5555725098\nclient_4 Layer 168 weight diff: 13.2590198517\nclient_4 Layer 169 weight diff: 19.2729988098\nclient_4 Layer 170 weight diff: 1518.4541015625\nclient_4 Layer 171 weight diff: 2.0052952766\nclient_4 Layer 172 weight diff: 2.0988574028\nclient_4 Layer 173 weight diff: 33.4531097412\nclient_4 Layer 174 weight diff: 40.2998428345\nclient_4 Layer 175 weight diff: 18.0164146423\nclient_4 Layer 176 weight diff: 1477.4448242188\nclient_4 Layer 177 weight diff: 2.0002527237\nclient_4 Layer 178 weight diff: 2.0461301804\nclient_4 Layer 179 weight diff: 15.9796142578\nclient_4 Layer 180 weight diff: 28.9171142578\nclient_4 Layer 181 weight diff: 17.7722301483\nclient_4 Layer 182 weight diff: 1488.0716552734\nclient_4 Layer 183 weight diff: 2.0305418968\nclient_4 Layer 184 weight diff: 1.9681811333\nclient_4 Layer 185 weight diff: 9.6335411072\nclient_4 Layer 186 weight diff: 15.5854854584\nclient_4 Layer 187 weight diff: 19.6990795135\nclient_4 Layer 188 weight diff: 1537.8625488281\nclient_4 Layer 189 weight diff: 2.0637376308\nclient_4 Layer 190 weight diff: 2.1037225723\nclient_4 Layer 191 weight diff: 44.2926788330\nclient_4 Layer 192 weight diff: 64.9270782471\nclient_4 Layer 193 weight diff: 18.6458930969\nclient_4 Layer 194 weight diff: 1497.4650878906\nclient_4 Layer 195 weight diff: 2.0238144398\nclient_4 Layer 196 weight diff: 2.0756607056\nclient_4 Layer 197 weight diff: 21.4829292297\nclient_4 Layer 198 weight diff: 34.6482162476\nclient_4 Layer 199 weight diff: 18.3382873535\nclient_4 Layer 200 weight diff: 1490.9027099609\nclient_4 Layer 201 weight diff: 1.9895813465\nclient_4 Layer 202 weight diff: 1.9370275736\nclient_4 Layer 203 weight diff: 13.6853628159\nclient_4 Layer 204 weight diff: 30.8845176697\nclient_4 Layer 205 weight diff: 17.7077293396\nclient_4 Layer 206 weight diff: 1467.1451416016\nclient_4 Layer 207 weight diff: 1.9425702095\nclient_4 Layer 208 weight diff: 1.9401078224\nclient_4 Layer 209 weight diff: 64.7987747192\nclient_4 Layer 210 weight diff: 200.0509033203\nclient_4 Layer 211 weight diff: 17.8553619385\nclient_4 Layer 212 weight diff: 2030.6870117188\nclient_4 Layer 213 weight diff: 2.7230091095\nclient_4 Layer 214 weight diff: 2.6063816547\nclient_4 Layer 215 weight diff: 27.9471015930\nclient_4 Layer 216 weight diff: 18.5280208588\nclient_4 Layer 217 weight diff: 2004.7590332031\nclient_4 Layer 218 weight diff: 2.8265242577\nclient_4 Layer 219 weight diff: 2.6063814163\nclient_4 Layer 220 weight diff: 867.5186767578\nclient_4 Layer 221 weight diff: 27876.5644531250\nclient_4 Layer 222 weight diff: 25.4388656616\nclient_4 Layer 223 weight diff: 4295.5346679688\nclient_4 Layer 224 weight diff: 4.0672140121\nclient_4 Layer 225 weight diff: 4.0122346878\nclient_4 Layer 226 weight diff: 135.2336730957\nclient_4 Layer 227 weight diff: 353.2283935547\nclient_4 Layer 228 weight diff: 36.7649459839\nclient_4 Layer 229 weight diff: 8014.9946289062\nclient_4 Layer 230 weight diff: 5.1755228043\nclient_4 Layer 231 weight diff: 5.3609294891\nclient_4 Layer 232 weight diff: 313.8251037598\nclient_4 Layer 233 weight diff: 917.5911254883\nclient_4 Layer 234 weight diff: 0.0000000000\nclient_4 Layer 235 weight diff: 0.0000000000\nclient_4 Layer 236 weight diff: 0.0000000000\nclient_4 Layer 237 weight diff: 0.0000000000\nclient_4 training accuracy history: [0.9674369692802429, 0.9758403301239014, 0.9852941036224365, 0.9873949289321899, 0.9947478771209717]\nclient_4 total local-global weight diff: 80209.58125353\n\n📶 Training on client_5\nTraining client_5 for 5 epochs...\nSum of weights before training: 193923.656\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 895ms/step - accuracy: 0.9654 - loss: 0.1716 - precision_42: 0.9675 - recall_42: 0.9608\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 639ms/step - accuracy: 0.9623 - loss: 0.1467 - precision_42: 0.9731 - recall_42: 0.9595\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 647ms/step - accuracy: 0.9911 - loss: 0.0386 - precision_42: 0.9911 - recall_42: 0.9911\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 662ms/step - accuracy: 0.9942 - loss: 0.0203 - precision_42: 0.9948 - recall_42: 0.9941\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 618ms/step - accuracy: 0.9912 - loss: 0.0288 - precision_42: 0.9912 - recall_42: 0.9912\nSum of weights after training: 208778.156\nclient_5 Layer 0 weight diff: 0.0000000000\nclient_5 Layer 1 weight diff: 0.0000000000\nclient_5 Layer 2 weight diff: 0.0000000000\nclient_5 Layer 3 weight diff: 0.0000000000\nclient_5 Layer 4 weight diff: 0.0000000000\nclient_5 Layer 5 weight diff: 0.0000000000\nclient_5 Layer 6 weight diff: 0.0000000000\nclient_5 Layer 7 weight diff: 0.0000000000\nclient_5 Layer 8 weight diff: 0.0000000000\nclient_5 Layer 9 weight diff: 0.0000000000\nclient_5 Layer 10 weight diff: 0.0000000000\nclient_5 Layer 11 weight diff: 0.0000000000\nclient_5 Layer 12 weight diff: 0.0000000000\nclient_5 Layer 13 weight diff: 0.0000000000\nclient_5 Layer 14 weight diff: 0.0000000000\nclient_5 Layer 15 weight diff: 0.0000000000\nclient_5 Layer 16 weight diff: 0.0000000000\nclient_5 Layer 17 weight diff: 0.0000000000\nclient_5 Layer 18 weight diff: 0.0000000000\nclient_5 Layer 19 weight diff: 0.0000000000\nclient_5 Layer 20 weight diff: 0.0000000000\nclient_5 Layer 21 weight diff: 0.0000000000\nclient_5 Layer 22 weight diff: 0.0000000000\nclient_5 Layer 23 weight diff: 0.0000000000\nclient_5 Layer 24 weight diff: 0.0000000000\nclient_5 Layer 25 weight diff: 0.0000000000\nclient_5 Layer 26 weight diff: 0.0000000000\nclient_5 Layer 27 weight diff: 0.0000000000\nclient_5 Layer 28 weight diff: 0.0000000000\nclient_5 Layer 29 weight diff: 0.0000000000\nclient_5 Layer 30 weight diff: 0.0000000000\nclient_5 Layer 31 weight diff: 0.0000000000\nclient_5 Layer 32 weight diff: 0.0000000000\nclient_5 Layer 33 weight diff: 0.0000000000\nclient_5 Layer 34 weight diff: 0.0000000000\nclient_5 Layer 35 weight diff: 0.0000000000\nclient_5 Layer 36 weight diff: 0.0000000000\nclient_5 Layer 37 weight diff: 0.0000000000\nclient_5 Layer 38 weight diff: 0.0000000000\nclient_5 Layer 39 weight diff: 0.0000000000\nclient_5 Layer 40 weight diff: 0.0000000000\nclient_5 Layer 41 weight diff: 0.0000000000\nclient_5 Layer 42 weight diff: 0.0000000000\nclient_5 Layer 43 weight diff: 0.0000000000\nclient_5 Layer 44 weight diff: 0.0000000000\nclient_5 Layer 45 weight diff: 0.0000000000\nclient_5 Layer 46 weight diff: 0.0000000000\nclient_5 Layer 47 weight diff: 0.0000000000\nclient_5 Layer 48 weight diff: 0.0000000000\nclient_5 Layer 49 weight diff: 0.0000000000\nclient_5 Layer 50 weight diff: 0.0000000000\nclient_5 Layer 51 weight diff: 0.0000000000\nclient_5 Layer 52 weight diff: 0.0000000000\nclient_5 Layer 53 weight diff: 0.0000000000\nclient_5 Layer 54 weight diff: 0.0000000000\nclient_5 Layer 55 weight diff: 0.0000000000\nclient_5 Layer 56 weight diff: 0.0000000000\nclient_5 Layer 57 weight diff: 0.0000000000\nclient_5 Layer 58 weight diff: 0.0000000000\nclient_5 Layer 59 weight diff: 0.0000000000\nclient_5 Layer 60 weight diff: 0.0000000000\nclient_5 Layer 61 weight diff: 0.0000000000\nclient_5 Layer 62 weight diff: 0.0000000000\nclient_5 Layer 63 weight diff: 0.0000000000\nclient_5 Layer 64 weight diff: 0.0000000000\nclient_5 Layer 65 weight diff: 0.0000000000\nclient_5 Layer 66 weight diff: 0.0000000000\nclient_5 Layer 67 weight diff: 0.0000000000\nclient_5 Layer 68 weight diff: 0.0000000000\nclient_5 Layer 69 weight diff: 0.0000000000\nclient_5 Layer 70 weight diff: 0.0000000000\nclient_5 Layer 71 weight diff: 0.0000000000\nclient_5 Layer 72 weight diff: 0.0000000000\nclient_5 Layer 73 weight diff: 0.0000000000\nclient_5 Layer 74 weight diff: 0.0000000000\nclient_5 Layer 75 weight diff: 0.0000000000\nclient_5 Layer 76 weight diff: 0.0000000000\nclient_5 Layer 77 weight diff: 0.0000000000\nclient_5 Layer 78 weight diff: 0.0000000000\nclient_5 Layer 79 weight diff: 0.0000000000\nclient_5 Layer 80 weight diff: 0.0000000000\nclient_5 Layer 81 weight diff: 0.0000000000\nclient_5 Layer 82 weight diff: 0.0000000000\nclient_5 Layer 83 weight diff: 0.0000000000\nclient_5 Layer 84 weight diff: 0.0000000000\nclient_5 Layer 85 weight diff: 16.7335128784\nclient_5 Layer 86 weight diff: 1345.8388671875\nclient_5 Layer 87 weight diff: 1.8175805807\nclient_5 Layer 88 weight diff: 1.8253494501\nclient_5 Layer 89 weight diff: 16.5513820648\nclient_5 Layer 90 weight diff: 7.2083230019\nclient_5 Layer 91 weight diff: 16.5136814117\nclient_5 Layer 92 weight diff: 1372.7136230469\nclient_5 Layer 93 weight diff: 1.9367232323\nclient_5 Layer 94 weight diff: 1.8597370386\nclient_5 Layer 95 weight diff: 13.8843717575\nclient_5 Layer 96 weight diff: 35.5792808533\nclient_5 Layer 97 weight diff: 17.6526527405\nclient_5 Layer 98 weight diff: 1423.1132812500\nclient_5 Layer 99 weight diff: 1.8495426178\nclient_5 Layer 100 weight diff: 1.9212141037\nclient_5 Layer 101 weight diff: 32.7104835510\nclient_5 Layer 102 weight diff: 33.9217758179\nclient_5 Layer 103 weight diff: 17.4699707031\nclient_5 Layer 104 weight diff: 1419.7434082031\nclient_5 Layer 105 weight diff: 1.9113060236\nclient_5 Layer 106 weight diff: 1.9767173529\nclient_5 Layer 107 weight diff: 8.4232196808\nclient_5 Layer 108 weight diff: 7.9162421227\nclient_5 Layer 109 weight diff: 17.0776176453\nclient_5 Layer 110 weight diff: 1412.3708496094\nclient_5 Layer 111 weight diff: 1.8329175711\nclient_5 Layer 112 weight diff: 1.8412467241\nclient_5 Layer 113 weight diff: 7.0229878426\nclient_5 Layer 114 weight diff: 18.8410396576\nclient_5 Layer 115 weight diff: 17.2513008118\nclient_5 Layer 116 weight diff: 1429.3454589844\nclient_5 Layer 117 weight diff: 1.8554340601\nclient_5 Layer 118 weight diff: 1.9376752377\nclient_5 Layer 119 weight diff: 19.2324867249\nclient_5 Layer 120 weight diff: 26.9312782288\nclient_5 Layer 121 weight diff: 17.0457420349\nclient_5 Layer 122 weight diff: 1425.3264160156\nclient_5 Layer 123 weight diff: 1.8127019405\nclient_5 Layer 124 weight diff: 1.8651714325\nclient_5 Layer 125 weight diff: 9.8295879364\nclient_5 Layer 126 weight diff: 5.5937242508\nclient_5 Layer 127 weight diff: 16.8580360413\nclient_5 Layer 128 weight diff: 1422.8743896484\nclient_5 Layer 129 weight diff: 1.9207918644\nclient_5 Layer 130 weight diff: 1.8825523853\nclient_5 Layer 131 weight diff: 8.7479143143\nclient_5 Layer 132 weight diff: 7.2087750435\nclient_5 Layer 133 weight diff: 17.3007659912\nclient_5 Layer 134 weight diff: 1389.4454345703\nclient_5 Layer 135 weight diff: 1.8457442522\nclient_5 Layer 136 weight diff: 1.8972131014\nclient_5 Layer 137 weight diff: 35.0147628784\nclient_5 Layer 138 weight diff: 29.9216651917\nclient_5 Layer 139 weight diff: 16.8537578583\nclient_5 Layer 140 weight diff: 1393.5118408203\nclient_5 Layer 141 weight diff: 1.8491190672\nclient_5 Layer 142 weight diff: 1.9012564421\nclient_5 Layer 143 weight diff: 16.9862918854\nclient_5 Layer 144 weight diff: 8.5466423035\nclient_5 Layer 145 weight diff: 16.2498435974\nclient_5 Layer 146 weight diff: 1397.5339355469\nclient_5 Layer 147 weight diff: 1.8766863346\nclient_5 Layer 148 weight diff: 1.8801069260\nclient_5 Layer 149 weight diff: 14.1252441406\nclient_5 Layer 150 weight diff: 10.9590682983\nclient_5 Layer 151 weight diff: 17.7346172333\nclient_5 Layer 152 weight diff: 1437.6466064453\nclient_5 Layer 153 weight diff: 2.0123047829\nclient_5 Layer 154 weight diff: 2.0022244453\nclient_5 Layer 155 weight diff: 32.5616149902\nclient_5 Layer 156 weight diff: 30.3954715729\nclient_5 Layer 157 weight diff: 17.3415908813\nclient_5 Layer 158 weight diff: 1425.0534667969\nclient_5 Layer 159 weight diff: 1.8981306553\nclient_5 Layer 160 weight diff: 1.9398990870\nclient_5 Layer 161 weight diff: 13.2651777267\nclient_5 Layer 162 weight diff: 10.9102296829\nclient_5 Layer 163 weight diff: 16.7677993774\nclient_5 Layer 164 weight diff: 1430.4812011719\nclient_5 Layer 165 weight diff: 1.8232674599\nclient_5 Layer 166 weight diff: 1.9267467260\nclient_5 Layer 167 weight diff: 9.0158319473\nclient_5 Layer 168 weight diff: 11.1499156952\nclient_5 Layer 169 weight diff: 17.6180458069\nclient_5 Layer 170 weight diff: 1416.6522216797\nclient_5 Layer 171 weight diff: 1.9635744095\nclient_5 Layer 172 weight diff: 2.0124385357\nclient_5 Layer 173 weight diff: 35.3502273560\nclient_5 Layer 174 weight diff: 47.0073928833\nclient_5 Layer 175 weight diff: 17.0328216553\nclient_5 Layer 176 weight diff: 1414.4956054688\nclient_5 Layer 177 weight diff: 1.9524133205\nclient_5 Layer 178 weight diff: 1.9410343170\nclient_5 Layer 179 weight diff: 16.0481758118\nclient_5 Layer 180 weight diff: 16.5726490021\nclient_5 Layer 181 weight diff: 16.9093418121\nclient_5 Layer 182 weight diff: 1397.7108154297\nclient_5 Layer 183 weight diff: 1.8755805492\nclient_5 Layer 184 weight diff: 1.9344631433\nclient_5 Layer 185 weight diff: 9.4392089844\nclient_5 Layer 186 weight diff: 7.3205690384\nclient_5 Layer 187 weight diff: 17.6565761566\nclient_5 Layer 188 weight diff: 1404.9443359375\nclient_5 Layer 189 weight diff: 1.8856127262\nclient_5 Layer 190 weight diff: 1.9112977982\nclient_5 Layer 191 weight diff: 45.4639244080\nclient_5 Layer 192 weight diff: 53.8101997375\nclient_5 Layer 193 weight diff: 16.6182365417\nclient_5 Layer 194 weight diff: 1387.2423095703\nclient_5 Layer 195 weight diff: 1.9022610188\nclient_5 Layer 196 weight diff: 1.9127615690\nclient_5 Layer 197 weight diff: 20.8493862152\nclient_5 Layer 198 weight diff: 25.0021400452\nclient_5 Layer 199 weight diff: 17.1145133972\nclient_5 Layer 200 weight diff: 1388.6850585938\nclient_5 Layer 201 weight diff: 1.9105149508\nclient_5 Layer 202 weight diff: 1.9800558090\nclient_5 Layer 203 weight diff: 12.4276180267\nclient_5 Layer 204 weight diff: 17.7423038483\nclient_5 Layer 205 weight diff: 17.0215759277\nclient_5 Layer 206 weight diff: 1399.1734619141\nclient_5 Layer 207 weight diff: 1.8513942957\nclient_5 Layer 208 weight diff: 1.8364510536\nclient_5 Layer 209 weight diff: 65.9752807617\nclient_5 Layer 210 weight diff: 183.0310668945\nclient_5 Layer 211 weight diff: 16.9740886688\nclient_5 Layer 212 weight diff: 1902.1234130859\nclient_5 Layer 213 weight diff: 2.4262425900\nclient_5 Layer 214 weight diff: 2.2984628677\nclient_5 Layer 215 weight diff: 28.4664726257\nclient_5 Layer 216 weight diff: 16.2005329132\nclient_5 Layer 217 weight diff: 1887.0466308594\nclient_5 Layer 218 weight diff: 2.5648312569\nclient_5 Layer 219 weight diff: 2.2984628677\nclient_5 Layer 220 weight diff: 762.5757446289\nclient_5 Layer 221 weight diff: 24890.4414062500\nclient_5 Layer 222 weight diff: 22.8239135742\nclient_5 Layer 223 weight diff: 3966.7756347656\nclient_5 Layer 224 weight diff: 3.7593867779\nclient_5 Layer 225 weight diff: 3.7096533775\nclient_5 Layer 226 weight diff: 148.2081298828\nclient_5 Layer 227 weight diff: 373.9594726562\nclient_5 Layer 228 weight diff: 34.2236557007\nclient_5 Layer 229 weight diff: 7655.7519531250\nclient_5 Layer 230 weight diff: 5.0242710114\nclient_5 Layer 231 weight diff: 5.2222766876\nclient_5 Layer 232 weight diff: 404.6109008789\nclient_5 Layer 233 weight diff: 1097.3236083984\nclient_5 Layer 234 weight diff: 0.0000000000\nclient_5 Layer 235 weight diff: 0.0000000000\nclient_5 Layer 236 weight diff: 0.0000000000\nclient_5 Layer 237 weight diff: 0.0000000000\nclient_5 training accuracy history: [0.9600840210914612, 0.973739504814148, 0.9894958138465881, 0.9915966391563416, 0.9884454011917114]\nclient_5 total local-global weight diff: 74245.79788041\n\n📶 Training on client_6\nTraining client_6 for 5 epochs...\nSum of weights before training: 193923.656\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 885ms/step - accuracy: 0.9665 - loss: 0.1351 - precision_43: 0.9667 - recall_43: 0.9654\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 647ms/step - accuracy: 0.9725 - loss: 0.0852 - precision_43: 0.9744 - recall_43: 0.9670\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 0.9882 - loss: 0.0486 - precision_43: 0.9882 - recall_43: 0.9879\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 642ms/step - accuracy: 0.9975 - loss: 0.0098 - precision_43: 0.9982 - recall_43: 0.9975\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 626ms/step - accuracy: 0.9914 - loss: 0.0215 - precision_43: 0.9914 - recall_43: 0.9914\nSum of weights after training: 207205.859\nclient_6 Layer 0 weight diff: 0.0000000000\nclient_6 Layer 1 weight diff: 0.0000000000\nclient_6 Layer 2 weight diff: 0.0000000000\nclient_6 Layer 3 weight diff: 0.0000000000\nclient_6 Layer 4 weight diff: 0.0000000000\nclient_6 Layer 5 weight diff: 0.0000000000\nclient_6 Layer 6 weight diff: 0.0000000000\nclient_6 Layer 7 weight diff: 0.0000000000\nclient_6 Layer 8 weight diff: 0.0000000000\nclient_6 Layer 9 weight diff: 0.0000000000\nclient_6 Layer 10 weight diff: 0.0000000000\nclient_6 Layer 11 weight diff: 0.0000000000\nclient_6 Layer 12 weight diff: 0.0000000000\nclient_6 Layer 13 weight diff: 0.0000000000\nclient_6 Layer 14 weight diff: 0.0000000000\nclient_6 Layer 15 weight diff: 0.0000000000\nclient_6 Layer 16 weight diff: 0.0000000000\nclient_6 Layer 17 weight diff: 0.0000000000\nclient_6 Layer 18 weight diff: 0.0000000000\nclient_6 Layer 19 weight diff: 0.0000000000\nclient_6 Layer 20 weight diff: 0.0000000000\nclient_6 Layer 21 weight diff: 0.0000000000\nclient_6 Layer 22 weight diff: 0.0000000000\nclient_6 Layer 23 weight diff: 0.0000000000\nclient_6 Layer 24 weight diff: 0.0000000000\nclient_6 Layer 25 weight diff: 0.0000000000\nclient_6 Layer 26 weight diff: 0.0000000000\nclient_6 Layer 27 weight diff: 0.0000000000\nclient_6 Layer 28 weight diff: 0.0000000000\nclient_6 Layer 29 weight diff: 0.0000000000\nclient_6 Layer 30 weight diff: 0.0000000000\nclient_6 Layer 31 weight diff: 0.0000000000\nclient_6 Layer 32 weight diff: 0.0000000000\nclient_6 Layer 33 weight diff: 0.0000000000\nclient_6 Layer 34 weight diff: 0.0000000000\nclient_6 Layer 35 weight diff: 0.0000000000\nclient_6 Layer 36 weight diff: 0.0000000000\nclient_6 Layer 37 weight diff: 0.0000000000\nclient_6 Layer 38 weight diff: 0.0000000000\nclient_6 Layer 39 weight diff: 0.0000000000\nclient_6 Layer 40 weight diff: 0.0000000000\nclient_6 Layer 41 weight diff: 0.0000000000\nclient_6 Layer 42 weight diff: 0.0000000000\nclient_6 Layer 43 weight diff: 0.0000000000\nclient_6 Layer 44 weight diff: 0.0000000000\nclient_6 Layer 45 weight diff: 0.0000000000\nclient_6 Layer 46 weight diff: 0.0000000000\nclient_6 Layer 47 weight diff: 0.0000000000\nclient_6 Layer 48 weight diff: 0.0000000000\nclient_6 Layer 49 weight diff: 0.0000000000\nclient_6 Layer 50 weight diff: 0.0000000000\nclient_6 Layer 51 weight diff: 0.0000000000\nclient_6 Layer 52 weight diff: 0.0000000000\nclient_6 Layer 53 weight diff: 0.0000000000\nclient_6 Layer 54 weight diff: 0.0000000000\nclient_6 Layer 55 weight diff: 0.0000000000\nclient_6 Layer 56 weight diff: 0.0000000000\nclient_6 Layer 57 weight diff: 0.0000000000\nclient_6 Layer 58 weight diff: 0.0000000000\nclient_6 Layer 59 weight diff: 0.0000000000\nclient_6 Layer 60 weight diff: 0.0000000000\nclient_6 Layer 61 weight diff: 0.0000000000\nclient_6 Layer 62 weight diff: 0.0000000000\nclient_6 Layer 63 weight diff: 0.0000000000\nclient_6 Layer 64 weight diff: 0.0000000000\nclient_6 Layer 65 weight diff: 0.0000000000\nclient_6 Layer 66 weight diff: 0.0000000000\nclient_6 Layer 67 weight diff: 0.0000000000\nclient_6 Layer 68 weight diff: 0.0000000000\nclient_6 Layer 69 weight diff: 0.0000000000\nclient_6 Layer 70 weight diff: 0.0000000000\nclient_6 Layer 71 weight diff: 0.0000000000\nclient_6 Layer 72 weight diff: 0.0000000000\nclient_6 Layer 73 weight diff: 0.0000000000\nclient_6 Layer 74 weight diff: 0.0000000000\nclient_6 Layer 75 weight diff: 0.0000000000\nclient_6 Layer 76 weight diff: 0.0000000000\nclient_6 Layer 77 weight diff: 0.0000000000\nclient_6 Layer 78 weight diff: 0.0000000000\nclient_6 Layer 79 weight diff: 0.0000000000\nclient_6 Layer 80 weight diff: 0.0000000000\nclient_6 Layer 81 weight diff: 0.0000000000\nclient_6 Layer 82 weight diff: 0.0000000000\nclient_6 Layer 83 weight diff: 0.0000000000\nclient_6 Layer 84 weight diff: 0.0000000000\nclient_6 Layer 85 weight diff: 13.5980720520\nclient_6 Layer 86 weight diff: 1104.9168701172\nclient_6 Layer 87 weight diff: 1.4713828564\nclient_6 Layer 88 weight diff: 1.4697117805\nclient_6 Layer 89 weight diff: 12.5943126678\nclient_6 Layer 90 weight diff: 7.0014963150\nclient_6 Layer 91 weight diff: 13.9862289429\nclient_6 Layer 92 weight diff: 1127.8642578125\nclient_6 Layer 93 weight diff: 1.5181511641\nclient_6 Layer 94 weight diff: 1.4601336718\nclient_6 Layer 95 weight diff: 11.6519889832\nclient_6 Layer 96 weight diff: 28.6812133789\nclient_6 Layer 97 weight diff: 14.4695196152\nclient_6 Layer 98 weight diff: 1181.3730468750\nclient_6 Layer 99 weight diff: 1.5749244690\nclient_6 Layer 100 weight diff: 1.5921789408\nclient_6 Layer 101 weight diff: 26.6017818451\nclient_6 Layer 102 weight diff: 26.1702156067\nclient_6 Layer 103 weight diff: 13.8918075562\nclient_6 Layer 104 weight diff: 1175.1372070312\nclient_6 Layer 105 weight diff: 1.4764180183\nclient_6 Layer 106 weight diff: 1.5203673840\nclient_6 Layer 107 weight diff: 7.1895389557\nclient_6 Layer 108 weight diff: 6.7445230484\nclient_6 Layer 109 weight diff: 13.9033031464\nclient_6 Layer 110 weight diff: 1170.8537597656\nclient_6 Layer 111 weight diff: 1.5333092213\nclient_6 Layer 112 weight diff: 1.4849259853\nclient_6 Layer 113 weight diff: 6.4193344116\nclient_6 Layer 114 weight diff: 12.5860023499\nclient_6 Layer 115 weight diff: 14.1979637146\nclient_6 Layer 116 weight diff: 1179.2785644531\nclient_6 Layer 117 weight diff: 1.5087566376\nclient_6 Layer 118 weight diff: 1.5643002987\nclient_6 Layer 119 weight diff: 15.5842208862\nclient_6 Layer 120 weight diff: 25.7319202423\nclient_6 Layer 121 weight diff: 14.2363700867\nclient_6 Layer 122 weight diff: 1183.2626953125\nclient_6 Layer 123 weight diff: 1.5860645771\nclient_6 Layer 124 weight diff: 1.5067359209\nclient_6 Layer 125 weight diff: 8.4670658112\nclient_6 Layer 126 weight diff: 5.4215612411\nclient_6 Layer 127 weight diff: 13.9312753677\nclient_6 Layer 128 weight diff: 1174.2283935547\nclient_6 Layer 129 weight diff: 1.4525437355\nclient_6 Layer 130 weight diff: 1.4910243750\nclient_6 Layer 131 weight diff: 7.5497198105\nclient_6 Layer 132 weight diff: 4.1289458275\nclient_6 Layer 133 weight diff: 14.2937545776\nclient_6 Layer 134 weight diff: 1157.3863525391\nclient_6 Layer 135 weight diff: 1.5342612267\nclient_6 Layer 136 weight diff: 1.5301480293\nclient_6 Layer 137 weight diff: 30.3655490875\nclient_6 Layer 138 weight diff: 26.9765243530\nclient_6 Layer 139 weight diff: 14.0395069122\nclient_6 Layer 140 weight diff: 1147.2775878906\nclient_6 Layer 141 weight diff: 1.5129222870\nclient_6 Layer 142 weight diff: 1.5045471191\nclient_6 Layer 143 weight diff: 12.5910148621\nclient_6 Layer 144 weight diff: 8.1518239975\nclient_6 Layer 145 weight diff: 13.8170394897\nclient_6 Layer 146 weight diff: 1149.7519531250\nclient_6 Layer 147 weight diff: 1.6656973362\nclient_6 Layer 148 weight diff: 1.5859346390\nclient_6 Layer 149 weight diff: 12.6493835449\nclient_6 Layer 150 weight diff: 12.9502458572\nclient_6 Layer 151 weight diff: 15.5626049042\nclient_6 Layer 152 weight diff: 1186.2165527344\nclient_6 Layer 153 weight diff: 1.6078722477\nclient_6 Layer 154 weight diff: 1.5840827227\nclient_6 Layer 155 weight diff: 25.9564170837\nclient_6 Layer 156 weight diff: 24.3917903900\nclient_6 Layer 157 weight diff: 14.3715763092\nclient_6 Layer 158 weight diff: 1184.7800292969\nclient_6 Layer 159 weight diff: 1.5874857903\nclient_6 Layer 160 weight diff: 1.6059901714\nclient_6 Layer 161 weight diff: 10.6821556091\nclient_6 Layer 162 weight diff: 8.0114021301\nclient_6 Layer 163 weight diff: 14.5056915283\nclient_6 Layer 164 weight diff: 1165.4981689453\nclient_6 Layer 165 weight diff: 1.6062750816\nclient_6 Layer 166 weight diff: 1.5598833561\nclient_6 Layer 167 weight diff: 7.0194301605\nclient_6 Layer 168 weight diff: 8.0712127686\nclient_6 Layer 169 weight diff: 14.9990758896\nclient_6 Layer 170 weight diff: 1175.9171142578\nclient_6 Layer 171 weight diff: 1.5970194340\nclient_6 Layer 172 weight diff: 1.6244854927\nclient_6 Layer 173 weight diff: 29.7928962708\nclient_6 Layer 174 weight diff: 44.5620880127\nclient_6 Layer 175 weight diff: 14.5086994171\nclient_6 Layer 176 weight diff: 1146.9711914062\nclient_6 Layer 177 weight diff: 1.5659025908\nclient_6 Layer 178 weight diff: 1.5841231346\nclient_6 Layer 179 weight diff: 13.3280305862\nclient_6 Layer 180 weight diff: 27.4973144531\nclient_6 Layer 181 weight diff: 13.9559717178\nclient_6 Layer 182 weight diff: 1126.1040039062\nclient_6 Layer 183 weight diff: 1.4923377037\nclient_6 Layer 184 weight diff: 1.5586099625\nclient_6 Layer 185 weight diff: 9.3524513245\nclient_6 Layer 186 weight diff: 8.7136812210\nclient_6 Layer 187 weight diff: 14.6797599792\nclient_6 Layer 188 weight diff: 1168.8985595703\nclient_6 Layer 189 weight diff: 1.6241897345\nclient_6 Layer 190 weight diff: 1.7147805691\nclient_6 Layer 191 weight diff: 36.6075553894\nclient_6 Layer 192 weight diff: 61.2423629761\nclient_6 Layer 193 weight diff: 14.5411977768\nclient_6 Layer 194 weight diff: 1145.6922607422\nclient_6 Layer 195 weight diff: 1.5736610889\nclient_6 Layer 196 weight diff: 1.5639464855\nclient_6 Layer 197 weight diff: 16.4318351746\nclient_6 Layer 198 weight diff: 20.0097274780\nclient_6 Layer 199 weight diff: 13.6883144379\nclient_6 Layer 200 weight diff: 1109.2081298828\nclient_6 Layer 201 weight diff: 1.5405726433\nclient_6 Layer 202 weight diff: 1.5340894461\nclient_6 Layer 203 weight diff: 10.8587808609\nclient_6 Layer 204 weight diff: 16.9700965881\nclient_6 Layer 205 weight diff: 13.7931413651\nclient_6 Layer 206 weight diff: 1149.7373046875\nclient_6 Layer 207 weight diff: 1.4537189007\nclient_6 Layer 208 weight diff: 1.4194581509\nclient_6 Layer 209 weight diff: 63.1944427490\nclient_6 Layer 210 weight diff: 225.4520568848\nclient_6 Layer 211 weight diff: 13.9632835388\nclient_6 Layer 212 weight diff: 1562.9864501953\nclient_6 Layer 213 weight diff: 2.1811175346\nclient_6 Layer 214 weight diff: 1.9352519512\nclient_6 Layer 215 weight diff: 21.5170459747\nclient_6 Layer 216 weight diff: 17.2294216156\nclient_6 Layer 217 weight diff: 1499.6683349609\nclient_6 Layer 218 weight diff: 1.9990258217\nclient_6 Layer 219 weight diff: 1.9352518320\nclient_6 Layer 220 weight diff: 668.2596435547\nclient_6 Layer 221 weight diff: 22640.9648437500\nclient_6 Layer 222 weight diff: 20.1782569885\nclient_6 Layer 223 weight diff: 3382.4970703125\nclient_6 Layer 224 weight diff: 3.2907886505\nclient_6 Layer 225 weight diff: 3.3658015728\nclient_6 Layer 226 weight diff: 136.8862915039\nclient_6 Layer 227 weight diff: 265.1644897461\nclient_6 Layer 228 weight diff: 29.4634189606\nclient_6 Layer 229 weight diff: 6163.2016601562\nclient_6 Layer 230 weight diff: 3.9629490376\nclient_6 Layer 231 weight diff: 4.1436104774\nclient_6 Layer 232 weight diff: 165.0659332275\nclient_6 Layer 233 weight diff: 263.5271911621\nclient_6 Layer 234 weight diff: 0.0000000000\nclient_6 Layer 235 weight diff: 0.0000000000\nclient_6 Layer 236 weight diff: 0.0000000000\nclient_6 Layer 237 weight diff: 0.0000000000\nclient_6 training accuracy history: [0.9536842107772827, 0.9768421053886414, 0.9905263185501099, 0.996842086315155, 0.9926315546035767]\nclient_6 total local-global weight diff: 62532.00904679\n\n✅ Round 4 average client accuracy: 0.9926\n\n📈 Global model evaluation on test data: {'loss': 0.05796099454164505, 'compile_metrics': 0.9870327711105347}\n\n🔁 Federated Round 5\n\n📶 Training on client_1\nTraining client_1 for 5 epochs...\nSum of weights before training: 209082.156\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 905ms/step - accuracy: 0.9791 - loss: 0.1154 - precision_45: 0.9794 - recall_45: 0.9791\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 666ms/step - accuracy: 0.9754 - loss: 0.0684 - precision_45: 0.9811 - recall_45: 0.9749\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 661ms/step - accuracy: 0.9812 - loss: 0.0407 - precision_45: 0.9834 - recall_45: 0.9804\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 647ms/step - accuracy: 0.9949 - loss: 0.0126 - precision_45: 0.9979 - recall_45: 0.9944\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 666ms/step - accuracy: 0.9976 - loss: 0.0093 - precision_45: 0.9987 - recall_45: 0.9976\nSum of weights after training: 229047.469\nclient_1 Layer 0 weight diff: 0.0000000000\nclient_1 Layer 1 weight diff: 0.0000000000\nclient_1 Layer 2 weight diff: 0.0000000000\nclient_1 Layer 3 weight diff: 0.0000000000\nclient_1 Layer 4 weight diff: 0.0000000000\nclient_1 Layer 5 weight diff: 0.0000000000\nclient_1 Layer 6 weight diff: 0.0000000000\nclient_1 Layer 7 weight diff: 0.0000000000\nclient_1 Layer 8 weight diff: 0.0000000000\nclient_1 Layer 9 weight diff: 0.0000000000\nclient_1 Layer 10 weight diff: 0.0000000000\nclient_1 Layer 11 weight diff: 0.0000000000\nclient_1 Layer 12 weight diff: 0.0000000000\nclient_1 Layer 13 weight diff: 0.0000000000\nclient_1 Layer 14 weight diff: 0.0000000000\nclient_1 Layer 15 weight diff: 0.0000000000\nclient_1 Layer 16 weight diff: 0.0000000000\nclient_1 Layer 17 weight diff: 0.0000000000\nclient_1 Layer 18 weight diff: 0.0000000000\nclient_1 Layer 19 weight diff: 0.0000000000\nclient_1 Layer 20 weight diff: 0.0000000000\nclient_1 Layer 21 weight diff: 0.0000000000\nclient_1 Layer 22 weight diff: 0.0000000000\nclient_1 Layer 23 weight diff: 0.0000000000\nclient_1 Layer 24 weight diff: 0.0000000000\nclient_1 Layer 25 weight diff: 0.0000000000\nclient_1 Layer 26 weight diff: 0.0000000000\nclient_1 Layer 27 weight diff: 0.0000000000\nclient_1 Layer 28 weight diff: 0.0000000000\nclient_1 Layer 29 weight diff: 0.0000000000\nclient_1 Layer 30 weight diff: 0.0000000000\nclient_1 Layer 31 weight diff: 0.0000000000\nclient_1 Layer 32 weight diff: 0.0000000000\nclient_1 Layer 33 weight diff: 0.0000000000\nclient_1 Layer 34 weight diff: 0.0000000000\nclient_1 Layer 35 weight diff: 0.0000000000\nclient_1 Layer 36 weight diff: 0.0000000000\nclient_1 Layer 37 weight diff: 0.0000000000\nclient_1 Layer 38 weight diff: 0.0000000000\nclient_1 Layer 39 weight diff: 0.0000000000\nclient_1 Layer 40 weight diff: 0.0000000000\nclient_1 Layer 41 weight diff: 0.0000000000\nclient_1 Layer 42 weight diff: 0.0000000000\nclient_1 Layer 43 weight diff: 0.0000000000\nclient_1 Layer 44 weight diff: 0.0000000000\nclient_1 Layer 45 weight diff: 0.0000000000\nclient_1 Layer 46 weight diff: 0.0000000000\nclient_1 Layer 47 weight diff: 0.0000000000\nclient_1 Layer 48 weight diff: 0.0000000000\nclient_1 Layer 49 weight diff: 0.0000000000\nclient_1 Layer 50 weight diff: 0.0000000000\nclient_1 Layer 51 weight diff: 0.0000000000\nclient_1 Layer 52 weight diff: 0.0000000000\nclient_1 Layer 53 weight diff: 0.0000000000\nclient_1 Layer 54 weight diff: 0.0000000000\nclient_1 Layer 55 weight diff: 0.0000000000\nclient_1 Layer 56 weight diff: 0.0000000000\nclient_1 Layer 57 weight diff: 0.0000000000\nclient_1 Layer 58 weight diff: 0.0000000000\nclient_1 Layer 59 weight diff: 0.0000000000\nclient_1 Layer 60 weight diff: 0.0000000000\nclient_1 Layer 61 weight diff: 0.0000000000\nclient_1 Layer 62 weight diff: 0.0000000000\nclient_1 Layer 63 weight diff: 0.0000000000\nclient_1 Layer 64 weight diff: 0.0000000000\nclient_1 Layer 65 weight diff: 0.0000000000\nclient_1 Layer 66 weight diff: 0.0000000000\nclient_1 Layer 67 weight diff: 0.0000000000\nclient_1 Layer 68 weight diff: 0.0000000000\nclient_1 Layer 69 weight diff: 0.0000000000\nclient_1 Layer 70 weight diff: 0.0000000000\nclient_1 Layer 71 weight diff: 0.0000000000\nclient_1 Layer 72 weight diff: 0.0000000000\nclient_1 Layer 73 weight diff: 0.0000000000\nclient_1 Layer 74 weight diff: 0.0000000000\nclient_1 Layer 75 weight diff: 0.0000000000\nclient_1 Layer 76 weight diff: 0.0000000000\nclient_1 Layer 77 weight diff: 0.0000000000\nclient_1 Layer 78 weight diff: 0.0000000000\nclient_1 Layer 79 weight diff: 0.0000000000\nclient_1 Layer 80 weight diff: 0.0000000000\nclient_1 Layer 81 weight diff: 0.0000000000\nclient_1 Layer 82 weight diff: 0.0000000000\nclient_1 Layer 83 weight diff: 0.0000000000\nclient_1 Layer 84 weight diff: 0.0000000000\nclient_1 Layer 85 weight diff: 13.9875116348\nclient_1 Layer 86 weight diff: 1140.4587402344\nclient_1 Layer 87 weight diff: 1.4825654030\nclient_1 Layer 88 weight diff: 1.4691405296\nclient_1 Layer 89 weight diff: 12.5630884171\nclient_1 Layer 90 weight diff: 6.9179420471\nclient_1 Layer 91 weight diff: 13.4847640991\nclient_1 Layer 92 weight diff: 1176.1254882812\nclient_1 Layer 93 weight diff: 1.5659686327\nclient_1 Layer 94 weight diff: 1.5688552856\nclient_1 Layer 95 weight diff: 11.6587066650\nclient_1 Layer 96 weight diff: 30.5232563019\nclient_1 Layer 97 weight diff: 15.0225658417\nclient_1 Layer 98 weight diff: 1228.7081298828\nclient_1 Layer 99 weight diff: 1.6731755733\nclient_1 Layer 100 weight diff: 1.6281213760\nclient_1 Layer 101 weight diff: 26.2394409180\nclient_1 Layer 102 weight diff: 26.8061466217\nclient_1 Layer 103 weight diff: 15.0370378494\nclient_1 Layer 104 weight diff: 1233.0577392578\nclient_1 Layer 105 weight diff: 1.6370666027\nclient_1 Layer 106 weight diff: 1.6188429594\nclient_1 Layer 107 weight diff: 7.5187501907\nclient_1 Layer 108 weight diff: 6.5787019730\nclient_1 Layer 109 weight diff: 14.7840518951\nclient_1 Layer 110 weight diff: 1222.9653320312\nclient_1 Layer 111 weight diff: 1.5602122545\nclient_1 Layer 112 weight diff: 1.5554206371\nclient_1 Layer 113 weight diff: 6.6563186646\nclient_1 Layer 114 weight diff: 17.1507625580\nclient_1 Layer 115 weight diff: 14.8144836426\nclient_1 Layer 116 weight diff: 1241.8977050781\nclient_1 Layer 117 weight diff: 1.6401569843\nclient_1 Layer 118 weight diff: 1.6549711227\nclient_1 Layer 119 weight diff: 16.7207031250\nclient_1 Layer 120 weight diff: 22.3563346863\nclient_1 Layer 121 weight diff: 14.7738685608\nclient_1 Layer 122 weight diff: 1231.5939941406\nclient_1 Layer 123 weight diff: 1.6809713840\nclient_1 Layer 124 weight diff: 1.6845209599\nclient_1 Layer 125 weight diff: 9.1636486053\nclient_1 Layer 126 weight diff: 5.0778603554\nclient_1 Layer 127 weight diff: 14.7255373001\nclient_1 Layer 128 weight diff: 1216.5747070312\nclient_1 Layer 129 weight diff: 1.6624019146\nclient_1 Layer 130 weight diff: 1.5361990929\nclient_1 Layer 131 weight diff: 6.5159254074\nclient_1 Layer 132 weight diff: 3.2021198273\nclient_1 Layer 133 weight diff: 14.6687383652\nclient_1 Layer 134 weight diff: 1203.3773193359\nclient_1 Layer 135 weight diff: 1.5726338625\nclient_1 Layer 136 weight diff: 1.5981724262\nclient_1 Layer 137 weight diff: 29.4815254211\nclient_1 Layer 138 weight diff: 27.2249774933\nclient_1 Layer 139 weight diff: 14.3704910278\nclient_1 Layer 140 weight diff: 1199.0266113281\nclient_1 Layer 141 weight diff: 1.5772421360\nclient_1 Layer 142 weight diff: 1.6267741919\nclient_1 Layer 143 weight diff: 12.5191287994\nclient_1 Layer 144 weight diff: 8.6150436401\nclient_1 Layer 145 weight diff: 14.0321283340\nclient_1 Layer 146 weight diff: 1190.6477050781\nclient_1 Layer 147 weight diff: 1.5917651653\nclient_1 Layer 148 weight diff: 1.5767431259\nclient_1 Layer 149 weight diff: 13.5185794830\nclient_1 Layer 150 weight diff: 11.5332870483\nclient_1 Layer 151 weight diff: 15.2380065918\nclient_1 Layer 152 weight diff: 1222.9733886719\nclient_1 Layer 153 weight diff: 1.6483321190\nclient_1 Layer 154 weight diff: 1.6086299419\nclient_1 Layer 155 weight diff: 25.3160724640\nclient_1 Layer 156 weight diff: 27.2946510315\nclient_1 Layer 157 weight diff: 14.9383840561\nclient_1 Layer 158 weight diff: 1219.4270019531\nclient_1 Layer 159 weight diff: 1.6441011429\nclient_1 Layer 160 weight diff: 1.6554316282\nclient_1 Layer 161 weight diff: 9.9934787750\nclient_1 Layer 162 weight diff: 8.0852546692\nclient_1 Layer 163 weight diff: 14.7120094299\nclient_1 Layer 164 weight diff: 1197.0253906250\nclient_1 Layer 165 weight diff: 1.5490367413\nclient_1 Layer 166 weight diff: 1.6027122736\nclient_1 Layer 167 weight diff: 6.8425636292\nclient_1 Layer 168 weight diff: 10.0849132538\nclient_1 Layer 169 weight diff: 14.9015369415\nclient_1 Layer 170 weight diff: 1202.3857421875\nclient_1 Layer 171 weight diff: 1.5960850716\nclient_1 Layer 172 weight diff: 1.6219398975\nclient_1 Layer 173 weight diff: 27.6844673157\nclient_1 Layer 174 weight diff: 37.9606170654\nclient_1 Layer 175 weight diff: 14.3882350922\nclient_1 Layer 176 weight diff: 1177.8740234375\nclient_1 Layer 177 weight diff: 1.5872169733\nclient_1 Layer 178 weight diff: 1.6161376238\nclient_1 Layer 179 weight diff: 11.1700363159\nclient_1 Layer 180 weight diff: 14.6388149261\nclient_1 Layer 181 weight diff: 14.5236940384\nclient_1 Layer 182 weight diff: 1174.2320556641\nclient_1 Layer 183 weight diff: 1.4790905714\nclient_1 Layer 184 weight diff: 1.6016269922\nclient_1 Layer 185 weight diff: 7.1049108505\nclient_1 Layer 186 weight diff: 10.7140827179\nclient_1 Layer 187 weight diff: 15.2537403107\nclient_1 Layer 188 weight diff: 1187.3935546875\nclient_1 Layer 189 weight diff: 1.5988059044\nclient_1 Layer 190 weight diff: 1.6237800121\nclient_1 Layer 191 weight diff: 37.2828025818\nclient_1 Layer 192 weight diff: 53.6675491333\nclient_1 Layer 193 weight diff: 14.1579961777\nclient_1 Layer 194 weight diff: 1161.0683593750\nclient_1 Layer 195 weight diff: 1.5080028772\nclient_1 Layer 196 weight diff: 1.4993791580\nclient_1 Layer 197 weight diff: 15.5308094025\nclient_1 Layer 198 weight diff: 17.9666881561\nclient_1 Layer 199 weight diff: 13.9512920380\nclient_1 Layer 200 weight diff: 1142.3563232422\nclient_1 Layer 201 weight diff: 1.6779789925\nclient_1 Layer 202 weight diff: 1.5426470041\nclient_1 Layer 203 weight diff: 10.8593959808\nclient_1 Layer 204 weight diff: 16.8828353882\nclient_1 Layer 205 weight diff: 13.8420009613\nclient_1 Layer 206 weight diff: 1191.5681152344\nclient_1 Layer 207 weight diff: 1.5730047226\nclient_1 Layer 208 weight diff: 1.5689837933\nclient_1 Layer 209 weight diff: 59.2403564453\nclient_1 Layer 210 weight diff: 163.7622680664\nclient_1 Layer 211 weight diff: 14.7398681641\nclient_1 Layer 212 weight diff: 1625.9042968750\nclient_1 Layer 213 weight diff: 2.2565269470\nclient_1 Layer 214 weight diff: 2.1617777348\nclient_1 Layer 215 weight diff: 21.4056835175\nclient_1 Layer 216 weight diff: 13.4045534134\nclient_1 Layer 217 weight diff: 1582.1892089844\nclient_1 Layer 218 weight diff: 2.1816637516\nclient_1 Layer 219 weight diff: 2.1617779732\nclient_1 Layer 220 weight diff: 755.0305175781\nclient_1 Layer 221 weight diff: 27586.5273437500\nclient_1 Layer 222 weight diff: 20.1465873718\nclient_1 Layer 223 weight diff: 3495.6289062500\nclient_1 Layer 224 weight diff: 2.9861185551\nclient_1 Layer 225 weight diff: 3.0089495182\nclient_1 Layer 226 weight diff: 132.7980499268\nclient_1 Layer 227 weight diff: 323.4219970703\nclient_1 Layer 228 weight diff: 28.7322311401\nclient_1 Layer 229 weight diff: 6558.7333984375\nclient_1 Layer 230 weight diff: 4.1508593559\nclient_1 Layer 231 weight diff: 4.4022026062\nclient_1 Layer 232 weight diff: 174.0199432373\nclient_1 Layer 233 weight diff: 351.6920166016\nclient_1 Layer 234 weight diff: 0.0000000000\nclient_1 Layer 235 weight diff: 0.0000000000\nclient_1 Layer 236 weight diff: 0.0000000000\nclient_1 Layer 237 weight diff: 0.0000000000\nclient_1 training accuracy history: [0.9696016907691956, 0.9790356159210205, 0.9853249192237854, 0.9947589039802551, 0.9968553185462952]\nclient_1 total local-global weight diff: 69131.61964118\n\n📶 Training on client_2\nTraining client_2 for 5 epochs...\nSum of weights before training: 209082.156\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 907ms/step - accuracy: 0.9766 - loss: 0.0925 - precision_46: 0.9766 - recall_46: 0.9765\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 660ms/step - accuracy: 0.9703 - loss: 0.0925 - precision_46: 0.9726 - recall_46: 0.9643\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 647ms/step - accuracy: 0.9804 - loss: 0.0526 - precision_46: 0.9804 - recall_46: 0.9804\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 633ms/step - accuracy: 0.9953 - loss: 0.0168 - precision_46: 0.9967 - recall_46: 0.9953\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 652ms/step - accuracy: 0.9975 - loss: 0.0080 - precision_46: 0.9975 - recall_46: 0.9975\nSum of weights after training: 221447.391\nclient_2 Layer 0 weight diff: 0.0000000000\nclient_2 Layer 1 weight diff: 0.0000000000\nclient_2 Layer 2 weight diff: 0.0000000000\nclient_2 Layer 3 weight diff: 0.0000000000\nclient_2 Layer 4 weight diff: 0.0000000000\nclient_2 Layer 5 weight diff: 0.0000000000\nclient_2 Layer 6 weight diff: 0.0000000000\nclient_2 Layer 7 weight diff: 0.0000000000\nclient_2 Layer 8 weight diff: 0.0000000000\nclient_2 Layer 9 weight diff: 0.0000000000\nclient_2 Layer 10 weight diff: 0.0000000000\nclient_2 Layer 11 weight diff: 0.0000000000\nclient_2 Layer 12 weight diff: 0.0000000000\nclient_2 Layer 13 weight diff: 0.0000000000\nclient_2 Layer 14 weight diff: 0.0000000000\nclient_2 Layer 15 weight diff: 0.0000000000\nclient_2 Layer 16 weight diff: 0.0000000000\nclient_2 Layer 17 weight diff: 0.0000000000\nclient_2 Layer 18 weight diff: 0.0000000000\nclient_2 Layer 19 weight diff: 0.0000000000\nclient_2 Layer 20 weight diff: 0.0000000000\nclient_2 Layer 21 weight diff: 0.0000000000\nclient_2 Layer 22 weight diff: 0.0000000000\nclient_2 Layer 23 weight diff: 0.0000000000\nclient_2 Layer 24 weight diff: 0.0000000000\nclient_2 Layer 25 weight diff: 0.0000000000\nclient_2 Layer 26 weight diff: 0.0000000000\nclient_2 Layer 27 weight diff: 0.0000000000\nclient_2 Layer 28 weight diff: 0.0000000000\nclient_2 Layer 29 weight diff: 0.0000000000\nclient_2 Layer 30 weight diff: 0.0000000000\nclient_2 Layer 31 weight diff: 0.0000000000\nclient_2 Layer 32 weight diff: 0.0000000000\nclient_2 Layer 33 weight diff: 0.0000000000\nclient_2 Layer 34 weight diff: 0.0000000000\nclient_2 Layer 35 weight diff: 0.0000000000\nclient_2 Layer 36 weight diff: 0.0000000000\nclient_2 Layer 37 weight diff: 0.0000000000\nclient_2 Layer 38 weight diff: 0.0000000000\nclient_2 Layer 39 weight diff: 0.0000000000\nclient_2 Layer 40 weight diff: 0.0000000000\nclient_2 Layer 41 weight diff: 0.0000000000\nclient_2 Layer 42 weight diff: 0.0000000000\nclient_2 Layer 43 weight diff: 0.0000000000\nclient_2 Layer 44 weight diff: 0.0000000000\nclient_2 Layer 45 weight diff: 0.0000000000\nclient_2 Layer 46 weight diff: 0.0000000000\nclient_2 Layer 47 weight diff: 0.0000000000\nclient_2 Layer 48 weight diff: 0.0000000000\nclient_2 Layer 49 weight diff: 0.0000000000\nclient_2 Layer 50 weight diff: 0.0000000000\nclient_2 Layer 51 weight diff: 0.0000000000\nclient_2 Layer 52 weight diff: 0.0000000000\nclient_2 Layer 53 weight diff: 0.0000000000\nclient_2 Layer 54 weight diff: 0.0000000000\nclient_2 Layer 55 weight diff: 0.0000000000\nclient_2 Layer 56 weight diff: 0.0000000000\nclient_2 Layer 57 weight diff: 0.0000000000\nclient_2 Layer 58 weight diff: 0.0000000000\nclient_2 Layer 59 weight diff: 0.0000000000\nclient_2 Layer 60 weight diff: 0.0000000000\nclient_2 Layer 61 weight diff: 0.0000000000\nclient_2 Layer 62 weight diff: 0.0000000000\nclient_2 Layer 63 weight diff: 0.0000000000\nclient_2 Layer 64 weight diff: 0.0000000000\nclient_2 Layer 65 weight diff: 0.0000000000\nclient_2 Layer 66 weight diff: 0.0000000000\nclient_2 Layer 67 weight diff: 0.0000000000\nclient_2 Layer 68 weight diff: 0.0000000000\nclient_2 Layer 69 weight diff: 0.0000000000\nclient_2 Layer 70 weight diff: 0.0000000000\nclient_2 Layer 71 weight diff: 0.0000000000\nclient_2 Layer 72 weight diff: 0.0000000000\nclient_2 Layer 73 weight diff: 0.0000000000\nclient_2 Layer 74 weight diff: 0.0000000000\nclient_2 Layer 75 weight diff: 0.0000000000\nclient_2 Layer 76 weight diff: 0.0000000000\nclient_2 Layer 77 weight diff: 0.0000000000\nclient_2 Layer 78 weight diff: 0.0000000000\nclient_2 Layer 79 weight diff: 0.0000000000\nclient_2 Layer 80 weight diff: 0.0000000000\nclient_2 Layer 81 weight diff: 0.0000000000\nclient_2 Layer 82 weight diff: 0.0000000000\nclient_2 Layer 83 weight diff: 0.0000000000\nclient_2 Layer 84 weight diff: 0.0000000000\nclient_2 Layer 85 weight diff: 15.4754848480\nclient_2 Layer 86 weight diff: 1232.3762207031\nclient_2 Layer 87 weight diff: 1.6041159630\nclient_2 Layer 88 weight diff: 1.6032030582\nclient_2 Layer 89 weight diff: 13.9640665054\nclient_2 Layer 90 weight diff: 7.1896162033\nclient_2 Layer 91 weight diff: 14.8962974548\nclient_2 Layer 92 weight diff: 1255.2746582031\nclient_2 Layer 93 weight diff: 1.7351320982\nclient_2 Layer 94 weight diff: 1.5823861361\nclient_2 Layer 95 weight diff: 12.6979475021\nclient_2 Layer 96 weight diff: 30.9466438293\nclient_2 Layer 97 weight diff: 15.6504745483\nclient_2 Layer 98 weight diff: 1280.3135986328\nclient_2 Layer 99 weight diff: 1.6552226543\nclient_2 Layer 100 weight diff: 1.6562891006\nclient_2 Layer 101 weight diff: 27.3149909973\nclient_2 Layer 102 weight diff: 27.0942134857\nclient_2 Layer 103 weight diff: 14.9946594238\nclient_2 Layer 104 weight diff: 1285.5820312500\nclient_2 Layer 105 weight diff: 1.6384134293\nclient_2 Layer 106 weight diff: 1.6395084858\nclient_2 Layer 107 weight diff: 7.3495049477\nclient_2 Layer 108 weight diff: 7.1433053017\nclient_2 Layer 109 weight diff: 15.4103183746\nclient_2 Layer 110 weight diff: 1297.2492675781\nclient_2 Layer 111 weight diff: 1.7078869343\nclient_2 Layer 112 weight diff: 1.5850092173\nclient_2 Layer 113 weight diff: 6.8237419128\nclient_2 Layer 114 weight diff: 21.5831832886\nclient_2 Layer 115 weight diff: 15.6462154388\nclient_2 Layer 116 weight diff: 1297.5415039062\nclient_2 Layer 117 weight diff: 1.7868416309\nclient_2 Layer 118 weight diff: 1.7935672998\nclient_2 Layer 119 weight diff: 17.9568519592\nclient_2 Layer 120 weight diff: 25.2529411316\nclient_2 Layer 121 weight diff: 16.1744880676\nclient_2 Layer 122 weight diff: 1300.4484863281\nclient_2 Layer 123 weight diff: 1.7908746004\nclient_2 Layer 124 weight diff: 1.7621270418\nclient_2 Layer 125 weight diff: 9.6380767822\nclient_2 Layer 126 weight diff: 4.4690232277\nclient_2 Layer 127 weight diff: 15.8829069138\nclient_2 Layer 128 weight diff: 1298.7382812500\nclient_2 Layer 129 weight diff: 1.7284657955\nclient_2 Layer 130 weight diff: 1.6079919338\nclient_2 Layer 131 weight diff: 8.7253761292\nclient_2 Layer 132 weight diff: 3.0315365791\nclient_2 Layer 133 weight diff: 15.5892572403\nclient_2 Layer 134 weight diff: 1288.9971923828\nclient_2 Layer 135 weight diff: 1.7023875713\nclient_2 Layer 136 weight diff: 1.7549799681\nclient_2 Layer 137 weight diff: 33.0487785339\nclient_2 Layer 138 weight diff: 29.3970165253\nclient_2 Layer 139 weight diff: 15.4237775803\nclient_2 Layer 140 weight diff: 1253.4716796875\nclient_2 Layer 141 weight diff: 1.6471300125\nclient_2 Layer 142 weight diff: 1.6349580288\nclient_2 Layer 143 weight diff: 16.4440193176\nclient_2 Layer 144 weight diff: 9.5467443466\nclient_2 Layer 145 weight diff: 15.2682533264\nclient_2 Layer 146 weight diff: 1263.2860107422\nclient_2 Layer 147 weight diff: 1.6958935261\nclient_2 Layer 148 weight diff: 1.6315259933\nclient_2 Layer 149 weight diff: 14.3420352936\nclient_2 Layer 150 weight diff: 10.1714382172\nclient_2 Layer 151 weight diff: 15.6392288208\nclient_2 Layer 152 weight diff: 1274.3195800781\nclient_2 Layer 153 weight diff: 1.6711351871\nclient_2 Layer 154 weight diff: 1.7830539942\nclient_2 Layer 155 weight diff: 27.0839424133\nclient_2 Layer 156 weight diff: 29.7367057800\nclient_2 Layer 157 weight diff: 15.4359188080\nclient_2 Layer 158 weight diff: 1257.0136718750\nclient_2 Layer 159 weight diff: 1.6390681267\nclient_2 Layer 160 weight diff: 1.6507034302\nclient_2 Layer 161 weight diff: 11.7442970276\nclient_2 Layer 162 weight diff: 9.3781833649\nclient_2 Layer 163 weight diff: 15.0275011063\nclient_2 Layer 164 weight diff: 1249.5432128906\nclient_2 Layer 165 weight diff: 1.6996049881\nclient_2 Layer 166 weight diff: 1.6595497131\nclient_2 Layer 167 weight diff: 8.5029926300\nclient_2 Layer 168 weight diff: 8.2183094025\nclient_2 Layer 169 weight diff: 15.4096202850\nclient_2 Layer 170 weight diff: 1262.9528808594\nclient_2 Layer 171 weight diff: 1.7329721451\nclient_2 Layer 172 weight diff: 1.6964108944\nclient_2 Layer 173 weight diff: 31.8511333466\nclient_2 Layer 174 weight diff: 38.0321617126\nclient_2 Layer 175 weight diff: 15.5550584793\nclient_2 Layer 176 weight diff: 1247.4705810547\nclient_2 Layer 177 weight diff: 1.6910490990\nclient_2 Layer 178 weight diff: 1.6844594479\nclient_2 Layer 179 weight diff: 12.8961286545\nclient_2 Layer 180 weight diff: 15.6779422760\nclient_2 Layer 181 weight diff: 14.7537164688\nclient_2 Layer 182 weight diff: 1228.3229980469\nclient_2 Layer 183 weight diff: 1.6668794155\nclient_2 Layer 184 weight diff: 1.6028001308\nclient_2 Layer 185 weight diff: 9.3211612701\nclient_2 Layer 186 weight diff: 8.1912441254\nclient_2 Layer 187 weight diff: 15.4112224579\nclient_2 Layer 188 weight diff: 1222.7298583984\nclient_2 Layer 189 weight diff: 1.5484552383\nclient_2 Layer 190 weight diff: 1.5236021280\nclient_2 Layer 191 weight diff: 39.8645401001\nclient_2 Layer 192 weight diff: 61.3391647339\nclient_2 Layer 193 weight diff: 14.4870910645\nclient_2 Layer 194 weight diff: 1201.1652832031\nclient_2 Layer 195 weight diff: 1.6221599579\nclient_2 Layer 196 weight diff: 1.6539121866\nclient_2 Layer 197 weight diff: 19.2173004150\nclient_2 Layer 198 weight diff: 41.9633789062\nclient_2 Layer 199 weight diff: 14.6590061188\nclient_2 Layer 200 weight diff: 1178.9138183594\nclient_2 Layer 201 weight diff: 1.6491937637\nclient_2 Layer 202 weight diff: 1.6613540649\nclient_2 Layer 203 weight diff: 10.8433113098\nclient_2 Layer 204 weight diff: 30.2993068695\nclient_2 Layer 205 weight diff: 14.7289848328\nclient_2 Layer 206 weight diff: 1268.3596191406\nclient_2 Layer 207 weight diff: 1.6686514616\nclient_2 Layer 208 weight diff: 1.6835328341\nclient_2 Layer 209 weight diff: 68.0602035522\nclient_2 Layer 210 weight diff: 203.0616912842\nclient_2 Layer 211 weight diff: 15.6399745941\nclient_2 Layer 212 weight diff: 1735.6311035156\nclient_2 Layer 213 weight diff: 2.3625950813\nclient_2 Layer 214 weight diff: 2.0186228752\nclient_2 Layer 215 weight diff: 28.4576797485\nclient_2 Layer 216 weight diff: 20.3172836304\nclient_2 Layer 217 weight diff: 1726.4543457031\nclient_2 Layer 218 weight diff: 2.3290903568\nclient_2 Layer 219 weight diff: 2.0186235905\nclient_2 Layer 220 weight diff: 823.4955444336\nclient_2 Layer 221 weight diff: 23906.0234375000\nclient_2 Layer 222 weight diff: 21.7289733887\nclient_2 Layer 223 weight diff: 3694.4838867188\nclient_2 Layer 224 weight diff: 3.3908147812\nclient_2 Layer 225 weight diff: 3.4537658691\nclient_2 Layer 226 weight diff: 128.5128326416\nclient_2 Layer 227 weight diff: 384.7813415527\nclient_2 Layer 228 weight diff: 31.1659622192\nclient_2 Layer 229 weight diff: 6924.1689453125\nclient_2 Layer 230 weight diff: 4.7149963379\nclient_2 Layer 231 weight diff: 4.9154944420\nclient_2 Layer 232 weight diff: 203.8321533203\nclient_2 Layer 233 weight diff: 590.8846435547\nclient_2 Layer 234 weight diff: 0.0000000000\nclient_2 Layer 235 weight diff: 0.0000000000\nclient_2 Layer 236 weight diff: 0.0000000000\nclient_2 Layer 237 weight diff: 0.0000000000\nclient_2 training accuracy history: [0.9716386795043945, 0.973739504814148, 0.9873949289321899, 0.993697464466095, 0.9968487620353699]\nclient_2 total local-global weight diff: 68125.91863728\n\n📶 Training on client_3\nTraining client_3 for 5 epochs...\nSum of weights before training: 209082.156\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 890ms/step - accuracy: 0.9704 - loss: 0.1387 - precision_47: 0.9741 - recall_47: 0.9641\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 644ms/step - accuracy: 0.9849 - loss: 0.0489 - precision_47: 0.9862 - recall_47: 0.9849\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 621ms/step - accuracy: 0.9944 - loss: 0.0154 - precision_47: 0.9950 - recall_47: 0.9944\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 642ms/step - accuracy: 0.9866 - loss: 0.0404 - precision_47: 0.9866 - recall_47: 0.9866\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 637ms/step - accuracy: 0.9836 - loss: 0.0457 - precision_47: 0.9836 - recall_47: 0.9836\nSum of weights after training: 221192.719\nclient_3 Layer 0 weight diff: 0.0000000000\nclient_3 Layer 1 weight diff: 0.0000000000\nclient_3 Layer 2 weight diff: 0.0000000000\nclient_3 Layer 3 weight diff: 0.0000000000\nclient_3 Layer 4 weight diff: 0.0000000000\nclient_3 Layer 5 weight diff: 0.0000000000\nclient_3 Layer 6 weight diff: 0.0000000000\nclient_3 Layer 7 weight diff: 0.0000000000\nclient_3 Layer 8 weight diff: 0.0000000000\nclient_3 Layer 9 weight diff: 0.0000000000\nclient_3 Layer 10 weight diff: 0.0000000000\nclient_3 Layer 11 weight diff: 0.0000000000\nclient_3 Layer 12 weight diff: 0.0000000000\nclient_3 Layer 13 weight diff: 0.0000000000\nclient_3 Layer 14 weight diff: 0.0000000000\nclient_3 Layer 15 weight diff: 0.0000000000\nclient_3 Layer 16 weight diff: 0.0000000000\nclient_3 Layer 17 weight diff: 0.0000000000\nclient_3 Layer 18 weight diff: 0.0000000000\nclient_3 Layer 19 weight diff: 0.0000000000\nclient_3 Layer 20 weight diff: 0.0000000000\nclient_3 Layer 21 weight diff: 0.0000000000\nclient_3 Layer 22 weight diff: 0.0000000000\nclient_3 Layer 23 weight diff: 0.0000000000\nclient_3 Layer 24 weight diff: 0.0000000000\nclient_3 Layer 25 weight diff: 0.0000000000\nclient_3 Layer 26 weight diff: 0.0000000000\nclient_3 Layer 27 weight diff: 0.0000000000\nclient_3 Layer 28 weight diff: 0.0000000000\nclient_3 Layer 29 weight diff: 0.0000000000\nclient_3 Layer 30 weight diff: 0.0000000000\nclient_3 Layer 31 weight diff: 0.0000000000\nclient_3 Layer 32 weight diff: 0.0000000000\nclient_3 Layer 33 weight diff: 0.0000000000\nclient_3 Layer 34 weight diff: 0.0000000000\nclient_3 Layer 35 weight diff: 0.0000000000\nclient_3 Layer 36 weight diff: 0.0000000000\nclient_3 Layer 37 weight diff: 0.0000000000\nclient_3 Layer 38 weight diff: 0.0000000000\nclient_3 Layer 39 weight diff: 0.0000000000\nclient_3 Layer 40 weight diff: 0.0000000000\nclient_3 Layer 41 weight diff: 0.0000000000\nclient_3 Layer 42 weight diff: 0.0000000000\nclient_3 Layer 43 weight diff: 0.0000000000\nclient_3 Layer 44 weight diff: 0.0000000000\nclient_3 Layer 45 weight diff: 0.0000000000\nclient_3 Layer 46 weight diff: 0.0000000000\nclient_3 Layer 47 weight diff: 0.0000000000\nclient_3 Layer 48 weight diff: 0.0000000000\nclient_3 Layer 49 weight diff: 0.0000000000\nclient_3 Layer 50 weight diff: 0.0000000000\nclient_3 Layer 51 weight diff: 0.0000000000\nclient_3 Layer 52 weight diff: 0.0000000000\nclient_3 Layer 53 weight diff: 0.0000000000\nclient_3 Layer 54 weight diff: 0.0000000000\nclient_3 Layer 55 weight diff: 0.0000000000\nclient_3 Layer 56 weight diff: 0.0000000000\nclient_3 Layer 57 weight diff: 0.0000000000\nclient_3 Layer 58 weight diff: 0.0000000000\nclient_3 Layer 59 weight diff: 0.0000000000\nclient_3 Layer 60 weight diff: 0.0000000000\nclient_3 Layer 61 weight diff: 0.0000000000\nclient_3 Layer 62 weight diff: 0.0000000000\nclient_3 Layer 63 weight diff: 0.0000000000\nclient_3 Layer 64 weight diff: 0.0000000000\nclient_3 Layer 65 weight diff: 0.0000000000\nclient_3 Layer 66 weight diff: 0.0000000000\nclient_3 Layer 67 weight diff: 0.0000000000\nclient_3 Layer 68 weight diff: 0.0000000000\nclient_3 Layer 69 weight diff: 0.0000000000\nclient_3 Layer 70 weight diff: 0.0000000000\nclient_3 Layer 71 weight diff: 0.0000000000\nclient_3 Layer 72 weight diff: 0.0000000000\nclient_3 Layer 73 weight diff: 0.0000000000\nclient_3 Layer 74 weight diff: 0.0000000000\nclient_3 Layer 75 weight diff: 0.0000000000\nclient_3 Layer 76 weight diff: 0.0000000000\nclient_3 Layer 77 weight diff: 0.0000000000\nclient_3 Layer 78 weight diff: 0.0000000000\nclient_3 Layer 79 weight diff: 0.0000000000\nclient_3 Layer 80 weight diff: 0.0000000000\nclient_3 Layer 81 weight diff: 0.0000000000\nclient_3 Layer 82 weight diff: 0.0000000000\nclient_3 Layer 83 weight diff: 0.0000000000\nclient_3 Layer 84 weight diff: 0.0000000000\nclient_3 Layer 85 weight diff: 15.9721946716\nclient_3 Layer 86 weight diff: 1301.3714599609\nclient_3 Layer 87 weight diff: 1.7385452986\nclient_3 Layer 88 weight diff: 1.7123054266\nclient_3 Layer 89 weight diff: 15.0734062195\nclient_3 Layer 90 weight diff: 6.5260372162\nclient_3 Layer 91 weight diff: 15.8140239716\nclient_3 Layer 92 weight diff: 1362.5687255859\nclient_3 Layer 93 weight diff: 1.7350237370\nclient_3 Layer 94 weight diff: 1.8948473930\nclient_3 Layer 95 weight diff: 11.8184757233\nclient_3 Layer 96 weight diff: 33.2413177490\nclient_3 Layer 97 weight diff: 17.9881343842\nclient_3 Layer 98 weight diff: 1444.5948486328\nclient_3 Layer 99 weight diff: 1.8855450153\nclient_3 Layer 100 weight diff: 1.9316977262\nclient_3 Layer 101 weight diff: 28.5198173523\nclient_3 Layer 102 weight diff: 26.4369583130\nclient_3 Layer 103 weight diff: 16.7900505066\nclient_3 Layer 104 weight diff: 1447.4765625000\nclient_3 Layer 105 weight diff: 1.9608085155\nclient_3 Layer 106 weight diff: 1.9498740435\nclient_3 Layer 107 weight diff: 8.3650903702\nclient_3 Layer 108 weight diff: 6.8198151588\nclient_3 Layer 109 weight diff: 17.4359436035\nclient_3 Layer 110 weight diff: 1457.2070312500\nclient_3 Layer 111 weight diff: 1.9563623667\nclient_3 Layer 112 weight diff: 1.8722946644\nclient_3 Layer 113 weight diff: 7.8355236053\nclient_3 Layer 114 weight diff: 18.0850906372\nclient_3 Layer 115 weight diff: 17.7833480835\nclient_3 Layer 116 weight diff: 1476.2337646484\nclient_3 Layer 117 weight diff: 1.9459103346\nclient_3 Layer 118 weight diff: 1.9950709343\nclient_3 Layer 119 weight diff: 17.2053413391\nclient_3 Layer 120 weight diff: 24.9688835144\nclient_3 Layer 121 weight diff: 17.7643718719\nclient_3 Layer 122 weight diff: 1458.5482177734\nclient_3 Layer 123 weight diff: 1.8942507505\nclient_3 Layer 124 weight diff: 1.8836765289\nclient_3 Layer 125 weight diff: 10.8988265991\nclient_3 Layer 126 weight diff: 5.0618047714\nclient_3 Layer 127 weight diff: 17.0758037567\nclient_3 Layer 128 weight diff: 1434.2996826172\nclient_3 Layer 129 weight diff: 1.8562016487\nclient_3 Layer 130 weight diff: 1.8089673519\nclient_3 Layer 131 weight diff: 8.2881832123\nclient_3 Layer 132 weight diff: 4.4196939468\nclient_3 Layer 133 weight diff: 17.6507301331\nclient_3 Layer 134 weight diff: 1406.5026855469\nclient_3 Layer 135 weight diff: 1.9159488678\nclient_3 Layer 136 weight diff: 1.8872873783\nclient_3 Layer 137 weight diff: 31.3569068909\nclient_3 Layer 138 weight diff: 30.1713027954\nclient_3 Layer 139 weight diff: 16.6600265503\nclient_3 Layer 140 weight diff: 1386.7474365234\nclient_3 Layer 141 weight diff: 1.7984237671\nclient_3 Layer 142 weight diff: 1.8164147139\nclient_3 Layer 143 weight diff: 15.5864391327\nclient_3 Layer 144 weight diff: 7.4501457214\nclient_3 Layer 145 weight diff: 16.7942352295\nclient_3 Layer 146 weight diff: 1378.7065429688\nclient_3 Layer 147 weight diff: 1.7902973890\nclient_3 Layer 148 weight diff: 1.8161253929\nclient_3 Layer 149 weight diff: 17.0876770020\nclient_3 Layer 150 weight diff: 13.8843345642\nclient_3 Layer 151 weight diff: 18.4750137329\nclient_3 Layer 152 weight diff: 1458.2817382812\nclient_3 Layer 153 weight diff: 1.9861006737\nclient_3 Layer 154 weight diff: 2.1094164848\nclient_3 Layer 155 weight diff: 29.8099479675\nclient_3 Layer 156 weight diff: 32.4617271423\nclient_3 Layer 157 weight diff: 17.6542167664\nclient_3 Layer 158 weight diff: 1431.9038085938\nclient_3 Layer 159 weight diff: 1.9459228516\nclient_3 Layer 160 weight diff: 1.9607845545\nclient_3 Layer 161 weight diff: 13.1483001709\nclient_3 Layer 162 weight diff: 9.6089954376\nclient_3 Layer 163 weight diff: 17.1023120880\nclient_3 Layer 164 weight diff: 1410.7585449219\nclient_3 Layer 165 weight diff: 1.8606384993\nclient_3 Layer 166 weight diff: 1.8743232489\nclient_3 Layer 167 weight diff: 8.6186847687\nclient_3 Layer 168 weight diff: 11.0680627823\nclient_3 Layer 169 weight diff: 17.4602432251\nclient_3 Layer 170 weight diff: 1428.1768798828\nclient_3 Layer 171 weight diff: 1.8890144825\nclient_3 Layer 172 weight diff: 1.9326790571\nclient_3 Layer 173 weight diff: 34.0398254395\nclient_3 Layer 174 weight diff: 41.1677322388\nclient_3 Layer 175 weight diff: 16.9586811066\nclient_3 Layer 176 weight diff: 1408.6909179688\nclient_3 Layer 177 weight diff: 1.8580638170\nclient_3 Layer 178 weight diff: 1.8832421303\nclient_3 Layer 179 weight diff: 15.1729221344\nclient_3 Layer 180 weight diff: 15.3432073593\nclient_3 Layer 181 weight diff: 16.5399475098\nclient_3 Layer 182 weight diff: 1377.4246826172\nclient_3 Layer 183 weight diff: 1.8068523407\nclient_3 Layer 184 weight diff: 1.8779225349\nclient_3 Layer 185 weight diff: 8.4989700317\nclient_3 Layer 186 weight diff: 12.4299192429\nclient_3 Layer 187 weight diff: 17.4072036743\nclient_3 Layer 188 weight diff: 1394.9216308594\nclient_3 Layer 189 weight diff: 1.8815116882\nclient_3 Layer 190 weight diff: 1.9224942923\nclient_3 Layer 191 weight diff: 40.8141174316\nclient_3 Layer 192 weight diff: 56.9024124146\nclient_3 Layer 193 weight diff: 16.8303375244\nclient_3 Layer 194 weight diff: 1377.9338378906\nclient_3 Layer 195 weight diff: 1.7540616989\nclient_3 Layer 196 weight diff: 1.7345615625\nclient_3 Layer 197 weight diff: 20.1569747925\nclient_3 Layer 198 weight diff: 19.1478061676\nclient_3 Layer 199 weight diff: 15.7008476257\nclient_3 Layer 200 weight diff: 1353.0695800781\nclient_3 Layer 201 weight diff: 1.8162029982\nclient_3 Layer 202 weight diff: 1.8795204163\nclient_3 Layer 203 weight diff: 11.9810581207\nclient_3 Layer 204 weight diff: 22.9159927368\nclient_3 Layer 205 weight diff: 15.9533472061\nclient_3 Layer 206 weight diff: 1359.8015136719\nclient_3 Layer 207 weight diff: 1.7640028000\nclient_3 Layer 208 weight diff: 1.7289652824\nclient_3 Layer 209 weight diff: 71.5162658691\nclient_3 Layer 210 weight diff: 229.1625366211\nclient_3 Layer 211 weight diff: 16.5444259644\nclient_3 Layer 212 weight diff: 1830.8209228516\nclient_3 Layer 213 weight diff: 2.3124098778\nclient_3 Layer 214 weight diff: 2.2382040024\nclient_3 Layer 215 weight diff: 27.0604000092\nclient_3 Layer 216 weight diff: 20.3949813843\nclient_3 Layer 217 weight diff: 1772.3405761719\nclient_3 Layer 218 weight diff: 2.3384242058\nclient_3 Layer 219 weight diff: 2.2382040024\nclient_3 Layer 220 weight diff: 813.9545898438\nclient_3 Layer 221 weight diff: 23146.6796875000\nclient_3 Layer 222 weight diff: 21.1303710938\nclient_3 Layer 223 weight diff: 4030.7778320312\nclient_3 Layer 224 weight diff: 3.8047215939\nclient_3 Layer 225 weight diff: 4.0361351967\nclient_3 Layer 226 weight diff: 140.6044006348\nclient_3 Layer 227 weight diff: 361.1528930664\nclient_3 Layer 228 weight diff: 33.5975112915\nclient_3 Layer 229 weight diff: 7218.3149414062\nclient_3 Layer 230 weight diff: 4.6087112427\nclient_3 Layer 231 weight diff: 4.7311425209\nclient_3 Layer 232 weight diff: 241.6785583496\nclient_3 Layer 233 weight diff: 1195.7618408203\nclient_3 Layer 234 weight diff: 0.0000000000\nclient_3 Layer 235 weight diff: 0.0000000000\nclient_3 Layer 236 weight diff: 0.0000000000\nclient_3 Layer 237 weight diff: 0.0000000000\nclient_3 training accuracy history: [0.9716386795043945, 0.9810924530029297, 0.993697464466095, 0.9894958138465881, 0.9894958138465881]\nclient_3 total local-global weight diff: 71941.73168242\n\n📶 Training on client_4\nTraining client_4 for 5 epochs...\nSum of weights before training: 209082.156\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 901ms/step - accuracy: 0.9782 - loss: 0.0888 - precision_48: 0.9795 - recall_48: 0.9782\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 646ms/step - accuracy: 0.9787 - loss: 0.0654 - precision_48: 0.9787 - recall_48: 0.9787\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 630ms/step - accuracy: 0.9922 - loss: 0.0257 - precision_48: 0.9922 - recall_48: 0.9922\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 0.9988 - loss: 0.0069 - precision_48: 0.9988 - recall_48: 0.9988\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 688ms/step - accuracy: 0.9994 - loss: 0.0035 - precision_48: 0.9994 - recall_48: 0.9994\nSum of weights after training: 223489.297\nclient_4 Layer 0 weight diff: 0.0000000000\nclient_4 Layer 1 weight diff: 0.0000000000\nclient_4 Layer 2 weight diff: 0.0000000000\nclient_4 Layer 3 weight diff: 0.0000000000\nclient_4 Layer 4 weight diff: 0.0000000000\nclient_4 Layer 5 weight diff: 0.0000000000\nclient_4 Layer 6 weight diff: 0.0000000000\nclient_4 Layer 7 weight diff: 0.0000000000\nclient_4 Layer 8 weight diff: 0.0000000000\nclient_4 Layer 9 weight diff: 0.0000000000\nclient_4 Layer 10 weight diff: 0.0000000000\nclient_4 Layer 11 weight diff: 0.0000000000\nclient_4 Layer 12 weight diff: 0.0000000000\nclient_4 Layer 13 weight diff: 0.0000000000\nclient_4 Layer 14 weight diff: 0.0000000000\nclient_4 Layer 15 weight diff: 0.0000000000\nclient_4 Layer 16 weight diff: 0.0000000000\nclient_4 Layer 17 weight diff: 0.0000000000\nclient_4 Layer 18 weight diff: 0.0000000000\nclient_4 Layer 19 weight diff: 0.0000000000\nclient_4 Layer 20 weight diff: 0.0000000000\nclient_4 Layer 21 weight diff: 0.0000000000\nclient_4 Layer 22 weight diff: 0.0000000000\nclient_4 Layer 23 weight diff: 0.0000000000\nclient_4 Layer 24 weight diff: 0.0000000000\nclient_4 Layer 25 weight diff: 0.0000000000\nclient_4 Layer 26 weight diff: 0.0000000000\nclient_4 Layer 27 weight diff: 0.0000000000\nclient_4 Layer 28 weight diff: 0.0000000000\nclient_4 Layer 29 weight diff: 0.0000000000\nclient_4 Layer 30 weight diff: 0.0000000000\nclient_4 Layer 31 weight diff: 0.0000000000\nclient_4 Layer 32 weight diff: 0.0000000000\nclient_4 Layer 33 weight diff: 0.0000000000\nclient_4 Layer 34 weight diff: 0.0000000000\nclient_4 Layer 35 weight diff: 0.0000000000\nclient_4 Layer 36 weight diff: 0.0000000000\nclient_4 Layer 37 weight diff: 0.0000000000\nclient_4 Layer 38 weight diff: 0.0000000000\nclient_4 Layer 39 weight diff: 0.0000000000\nclient_4 Layer 40 weight diff: 0.0000000000\nclient_4 Layer 41 weight diff: 0.0000000000\nclient_4 Layer 42 weight diff: 0.0000000000\nclient_4 Layer 43 weight diff: 0.0000000000\nclient_4 Layer 44 weight diff: 0.0000000000\nclient_4 Layer 45 weight diff: 0.0000000000\nclient_4 Layer 46 weight diff: 0.0000000000\nclient_4 Layer 47 weight diff: 0.0000000000\nclient_4 Layer 48 weight diff: 0.0000000000\nclient_4 Layer 49 weight diff: 0.0000000000\nclient_4 Layer 50 weight diff: 0.0000000000\nclient_4 Layer 51 weight diff: 0.0000000000\nclient_4 Layer 52 weight diff: 0.0000000000\nclient_4 Layer 53 weight diff: 0.0000000000\nclient_4 Layer 54 weight diff: 0.0000000000\nclient_4 Layer 55 weight diff: 0.0000000000\nclient_4 Layer 56 weight diff: 0.0000000000\nclient_4 Layer 57 weight diff: 0.0000000000\nclient_4 Layer 58 weight diff: 0.0000000000\nclient_4 Layer 59 weight diff: 0.0000000000\nclient_4 Layer 60 weight diff: 0.0000000000\nclient_4 Layer 61 weight diff: 0.0000000000\nclient_4 Layer 62 weight diff: 0.0000000000\nclient_4 Layer 63 weight diff: 0.0000000000\nclient_4 Layer 64 weight diff: 0.0000000000\nclient_4 Layer 65 weight diff: 0.0000000000\nclient_4 Layer 66 weight diff: 0.0000000000\nclient_4 Layer 67 weight diff: 0.0000000000\nclient_4 Layer 68 weight diff: 0.0000000000\nclient_4 Layer 69 weight diff: 0.0000000000\nclient_4 Layer 70 weight diff: 0.0000000000\nclient_4 Layer 71 weight diff: 0.0000000000\nclient_4 Layer 72 weight diff: 0.0000000000\nclient_4 Layer 73 weight diff: 0.0000000000\nclient_4 Layer 74 weight diff: 0.0000000000\nclient_4 Layer 75 weight diff: 0.0000000000\nclient_4 Layer 76 weight diff: 0.0000000000\nclient_4 Layer 77 weight diff: 0.0000000000\nclient_4 Layer 78 weight diff: 0.0000000000\nclient_4 Layer 79 weight diff: 0.0000000000\nclient_4 Layer 80 weight diff: 0.0000000000\nclient_4 Layer 81 weight diff: 0.0000000000\nclient_4 Layer 82 weight diff: 0.0000000000\nclient_4 Layer 83 weight diff: 0.0000000000\nclient_4 Layer 84 weight diff: 0.0000000000\nclient_4 Layer 85 weight diff: 16.0373935699\nclient_4 Layer 86 weight diff: 1299.8393554688\nclient_4 Layer 87 weight diff: 1.7762613297\nclient_4 Layer 88 weight diff: 1.7596071959\nclient_4 Layer 89 weight diff: 15.3315696716\nclient_4 Layer 90 weight diff: 6.9333887100\nclient_4 Layer 91 weight diff: 16.0326728821\nclient_4 Layer 92 weight diff: 1331.4152832031\nclient_4 Layer 93 weight diff: 1.8179259300\nclient_4 Layer 94 weight diff: 1.8745217323\nclient_4 Layer 95 weight diff: 13.3947896957\nclient_4 Layer 96 weight diff: 33.9505767822\nclient_4 Layer 97 weight diff: 16.9378452301\nclient_4 Layer 98 weight diff: 1390.7288818359\nclient_4 Layer 99 weight diff: 1.8486946821\nclient_4 Layer 100 weight diff: 1.8192275763\nclient_4 Layer 101 weight diff: 28.4306831360\nclient_4 Layer 102 weight diff: 27.3288154602\nclient_4 Layer 103 weight diff: 16.7073936462\nclient_4 Layer 104 weight diff: 1392.5240478516\nclient_4 Layer 105 weight diff: 1.8657066822\nclient_4 Layer 106 weight diff: 1.8774671555\nclient_4 Layer 107 weight diff: 8.2083225250\nclient_4 Layer 108 weight diff: 6.7674937248\nclient_4 Layer 109 weight diff: 16.5367069244\nclient_4 Layer 110 weight diff: 1400.0261230469\nclient_4 Layer 111 weight diff: 1.9192917347\nclient_4 Layer 112 weight diff: 1.8752074242\nclient_4 Layer 113 weight diff: 7.6332483292\nclient_4 Layer 114 weight diff: 13.5180730820\nclient_4 Layer 115 weight diff: 16.6078224182\nclient_4 Layer 116 weight diff: 1394.7813720703\nclient_4 Layer 117 weight diff: 1.8623141050\nclient_4 Layer 118 weight diff: 1.8584406376\nclient_4 Layer 119 weight diff: 18.0670547485\nclient_4 Layer 120 weight diff: 27.4609203339\nclient_4 Layer 121 weight diff: 16.9642906189\nclient_4 Layer 122 weight diff: 1392.6109619141\nclient_4 Layer 123 weight diff: 1.7857539654\nclient_4 Layer 124 weight diff: 1.7974712849\nclient_4 Layer 125 weight diff: 10.4864978790\nclient_4 Layer 126 weight diff: 5.1421661377\nclient_4 Layer 127 weight diff: 16.6552848816\nclient_4 Layer 128 weight diff: 1391.5444335938\nclient_4 Layer 129 weight diff: 1.7338037491\nclient_4 Layer 130 weight diff: 1.8021183014\nclient_4 Layer 131 weight diff: 7.9461660385\nclient_4 Layer 132 weight diff: 2.9021749496\nclient_4 Layer 133 weight diff: 16.6491470337\nclient_4 Layer 134 weight diff: 1363.4978027344\nclient_4 Layer 135 weight diff: 1.7218728065\nclient_4 Layer 136 weight diff: 1.7695946693\nclient_4 Layer 137 weight diff: 35.6833724976\nclient_4 Layer 138 weight diff: 28.5721740723\nclient_4 Layer 139 weight diff: 16.1415061951\nclient_4 Layer 140 weight diff: 1356.2701416016\nclient_4 Layer 141 weight diff: 1.7785761356\nclient_4 Layer 142 weight diff: 1.8143961430\nclient_4 Layer 143 weight diff: 15.0740661621\nclient_4 Layer 144 weight diff: 9.1718521118\nclient_4 Layer 145 weight diff: 15.9060831070\nclient_4 Layer 146 weight diff: 1347.8105468750\nclient_4 Layer 147 weight diff: 1.8971250057\nclient_4 Layer 148 weight diff: 1.7800382376\nclient_4 Layer 149 weight diff: 16.5695972443\nclient_4 Layer 150 weight diff: 17.1510467529\nclient_4 Layer 151 weight diff: 17.5623607635\nclient_4 Layer 152 weight diff: 1432.4270019531\nclient_4 Layer 153 weight diff: 1.9006328583\nclient_4 Layer 154 weight diff: 1.9211903811\nclient_4 Layer 155 weight diff: 28.7947883606\nclient_4 Layer 156 weight diff: 32.8619842529\nclient_4 Layer 157 weight diff: 18.0586185455\nclient_4 Layer 158 weight diff: 1422.6503906250\nclient_4 Layer 159 weight diff: 1.9617654085\nclient_4 Layer 160 weight diff: 2.0226359367\nclient_4 Layer 161 weight diff: 11.7556495667\nclient_4 Layer 162 weight diff: 13.9838390350\nclient_4 Layer 163 weight diff: 17.3796787262\nclient_4 Layer 164 weight diff: 1394.4328613281\nclient_4 Layer 165 weight diff: 1.8562448025\nclient_4 Layer 166 weight diff: 1.7651829720\nclient_4 Layer 167 weight diff: 8.5923833847\nclient_4 Layer 168 weight diff: 10.9696960449\nclient_4 Layer 169 weight diff: 17.0871315002\nclient_4 Layer 170 weight diff: 1400.8769531250\nclient_4 Layer 171 weight diff: 1.8901934624\nclient_4 Layer 172 weight diff: 1.9547898769\nclient_4 Layer 173 weight diff: 33.4319839478\nclient_4 Layer 174 weight diff: 44.9597320557\nclient_4 Layer 175 weight diff: 16.9281311035\nclient_4 Layer 176 weight diff: 1350.7839355469\nclient_4 Layer 177 weight diff: 1.7983597517\nclient_4 Layer 178 weight diff: 1.8680000305\nclient_4 Layer 179 weight diff: 14.9858884811\nclient_4 Layer 180 weight diff: 33.4975967407\nclient_4 Layer 181 weight diff: 16.2996692657\nclient_4 Layer 182 weight diff: 1331.8736572266\nclient_4 Layer 183 weight diff: 1.7842695713\nclient_4 Layer 184 weight diff: 1.8040473461\nclient_4 Layer 185 weight diff: 9.6350307465\nclient_4 Layer 186 weight diff: 14.1711273193\nclient_4 Layer 187 weight diff: 17.3029270172\nclient_4 Layer 188 weight diff: 1374.9509277344\nclient_4 Layer 189 weight diff: 1.9123235941\nclient_4 Layer 190 weight diff: 1.9004726410\nclient_4 Layer 191 weight diff: 42.1020050049\nclient_4 Layer 192 weight diff: 60.8363418579\nclient_4 Layer 193 weight diff: 16.5760402679\nclient_4 Layer 194 weight diff: 1331.0427246094\nclient_4 Layer 195 weight diff: 1.7800521851\nclient_4 Layer 196 weight diff: 1.8112099171\nclient_4 Layer 197 weight diff: 19.4910697937\nclient_4 Layer 198 weight diff: 54.5735130310\nclient_4 Layer 199 weight diff: 15.6708869934\nclient_4 Layer 200 weight diff: 1311.4371337891\nclient_4 Layer 201 weight diff: 1.8674635887\nclient_4 Layer 202 weight diff: 1.8239033222\nclient_4 Layer 203 weight diff: 12.2553987503\nclient_4 Layer 204 weight diff: 37.2937965393\nclient_4 Layer 205 weight diff: 16.4586296082\nclient_4 Layer 206 weight diff: 1337.7410888672\nclient_4 Layer 207 weight diff: 1.6762416363\nclient_4 Layer 208 weight diff: 1.7183089256\nclient_4 Layer 209 weight diff: 72.9815216064\nclient_4 Layer 210 weight diff: 241.8257446289\nclient_4 Layer 211 weight diff: 15.9770431519\nclient_4 Layer 212 weight diff: 1833.5424804688\nclient_4 Layer 213 weight diff: 2.5009171963\nclient_4 Layer 214 weight diff: 2.1908049583\nclient_4 Layer 215 weight diff: 25.8884563446\nclient_4 Layer 216 weight diff: 16.9833183289\nclient_4 Layer 217 weight diff: 1842.5467529297\nclient_4 Layer 218 weight diff: 2.5127267838\nclient_4 Layer 219 weight diff: 2.1908049583\nclient_4 Layer 220 weight diff: 846.5997314453\nclient_4 Layer 221 weight diff: 26311.5312500000\nclient_4 Layer 222 weight diff: 23.1111850739\nclient_4 Layer 223 weight diff: 3887.0136718750\nclient_4 Layer 224 weight diff: 3.6440682411\nclient_4 Layer 225 weight diff: 3.7160880566\nclient_4 Layer 226 weight diff: 136.2938385010\nclient_4 Layer 227 weight diff: 364.1097412109\nclient_4 Layer 228 weight diff: 33.4376487732\nclient_4 Layer 229 weight diff: 7372.5410156250\nclient_4 Layer 230 weight diff: 4.7963848114\nclient_4 Layer 231 weight diff: 4.8805255890\nclient_4 Layer 232 weight diff: 213.2869567871\nclient_4 Layer 233 weight diff: 488.9825439453\nclient_4 Layer 234 weight diff: 0.0000000000\nclient_4 Layer 235 weight diff: 0.0000000000\nclient_4 Layer 236 weight diff: 0.0000000000\nclient_4 Layer 237 weight diff: 0.0000000000\nclient_4 training accuracy history: [0.9716386795043945, 0.9831932783126831, 0.9926470518112183, 0.9978991746902466, 0.9989495873451233]\nclient_4 total local-global weight diff: 73769.81964624\n\n📶 Training on client_5\nTraining client_5 for 5 epochs...\nSum of weights before training: 209082.156\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 975ms/step - accuracy: 0.9563 - loss: 0.1260 - precision_49: 0.9624 - recall_49: 0.9502\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 646ms/step - accuracy: 0.9887 - loss: 0.0531 - precision_49: 0.9887 - recall_49: 0.9873\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 652ms/step - accuracy: 0.9884 - loss: 0.0257 - precision_49: 0.9884 - recall_49: 0.9884\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 635ms/step - accuracy: 0.9911 - loss: 0.0243 - precision_49: 0.9911 - recall_49: 0.9911\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 653ms/step - accuracy: 0.9943 - loss: 0.0192 - precision_49: 0.9954 - recall_49: 0.9927\nSum of weights after training: 237356.781\nclient_5 Layer 0 weight diff: 0.0000000000\nclient_5 Layer 1 weight diff: 0.0000000000\nclient_5 Layer 2 weight diff: 0.0000000000\nclient_5 Layer 3 weight diff: 0.0000000000\nclient_5 Layer 4 weight diff: 0.0000000000\nclient_5 Layer 5 weight diff: 0.0000000000\nclient_5 Layer 6 weight diff: 0.0000000000\nclient_5 Layer 7 weight diff: 0.0000000000\nclient_5 Layer 8 weight diff: 0.0000000000\nclient_5 Layer 9 weight diff: 0.0000000000\nclient_5 Layer 10 weight diff: 0.0000000000\nclient_5 Layer 11 weight diff: 0.0000000000\nclient_5 Layer 12 weight diff: 0.0000000000\nclient_5 Layer 13 weight diff: 0.0000000000\nclient_5 Layer 14 weight diff: 0.0000000000\nclient_5 Layer 15 weight diff: 0.0000000000\nclient_5 Layer 16 weight diff: 0.0000000000\nclient_5 Layer 17 weight diff: 0.0000000000\nclient_5 Layer 18 weight diff: 0.0000000000\nclient_5 Layer 19 weight diff: 0.0000000000\nclient_5 Layer 20 weight diff: 0.0000000000\nclient_5 Layer 21 weight diff: 0.0000000000\nclient_5 Layer 22 weight diff: 0.0000000000\nclient_5 Layer 23 weight diff: 0.0000000000\nclient_5 Layer 24 weight diff: 0.0000000000\nclient_5 Layer 25 weight diff: 0.0000000000\nclient_5 Layer 26 weight diff: 0.0000000000\nclient_5 Layer 27 weight diff: 0.0000000000\nclient_5 Layer 28 weight diff: 0.0000000000\nclient_5 Layer 29 weight diff: 0.0000000000\nclient_5 Layer 30 weight diff: 0.0000000000\nclient_5 Layer 31 weight diff: 0.0000000000\nclient_5 Layer 32 weight diff: 0.0000000000\nclient_5 Layer 33 weight diff: 0.0000000000\nclient_5 Layer 34 weight diff: 0.0000000000\nclient_5 Layer 35 weight diff: 0.0000000000\nclient_5 Layer 36 weight diff: 0.0000000000\nclient_5 Layer 37 weight diff: 0.0000000000\nclient_5 Layer 38 weight diff: 0.0000000000\nclient_5 Layer 39 weight diff: 0.0000000000\nclient_5 Layer 40 weight diff: 0.0000000000\nclient_5 Layer 41 weight diff: 0.0000000000\nclient_5 Layer 42 weight diff: 0.0000000000\nclient_5 Layer 43 weight diff: 0.0000000000\nclient_5 Layer 44 weight diff: 0.0000000000\nclient_5 Layer 45 weight diff: 0.0000000000\nclient_5 Layer 46 weight diff: 0.0000000000\nclient_5 Layer 47 weight diff: 0.0000000000\nclient_5 Layer 48 weight diff: 0.0000000000\nclient_5 Layer 49 weight diff: 0.0000000000\nclient_5 Layer 50 weight diff: 0.0000000000\nclient_5 Layer 51 weight diff: 0.0000000000\nclient_5 Layer 52 weight diff: 0.0000000000\nclient_5 Layer 53 weight diff: 0.0000000000\nclient_5 Layer 54 weight diff: 0.0000000000\nclient_5 Layer 55 weight diff: 0.0000000000\nclient_5 Layer 56 weight diff: 0.0000000000\nclient_5 Layer 57 weight diff: 0.0000000000\nclient_5 Layer 58 weight diff: 0.0000000000\nclient_5 Layer 59 weight diff: 0.0000000000\nclient_5 Layer 60 weight diff: 0.0000000000\nclient_5 Layer 61 weight diff: 0.0000000000\nclient_5 Layer 62 weight diff: 0.0000000000\nclient_5 Layer 63 weight diff: 0.0000000000\nclient_5 Layer 64 weight diff: 0.0000000000\nclient_5 Layer 65 weight diff: 0.0000000000\nclient_5 Layer 66 weight diff: 0.0000000000\nclient_5 Layer 67 weight diff: 0.0000000000\nclient_5 Layer 68 weight diff: 0.0000000000\nclient_5 Layer 69 weight diff: 0.0000000000\nclient_5 Layer 70 weight diff: 0.0000000000\nclient_5 Layer 71 weight diff: 0.0000000000\nclient_5 Layer 72 weight diff: 0.0000000000\nclient_5 Layer 73 weight diff: 0.0000000000\nclient_5 Layer 74 weight diff: 0.0000000000\nclient_5 Layer 75 weight diff: 0.0000000000\nclient_5 Layer 76 weight diff: 0.0000000000\nclient_5 Layer 77 weight diff: 0.0000000000\nclient_5 Layer 78 weight diff: 0.0000000000\nclient_5 Layer 79 weight diff: 0.0000000000\nclient_5 Layer 80 weight diff: 0.0000000000\nclient_5 Layer 81 weight diff: 0.0000000000\nclient_5 Layer 82 weight diff: 0.0000000000\nclient_5 Layer 83 weight diff: 0.0000000000\nclient_5 Layer 84 weight diff: 0.0000000000\nclient_5 Layer 85 weight diff: 17.9580993652\nclient_5 Layer 86 weight diff: 1483.1029052734\nclient_5 Layer 87 weight diff: 1.9799759388\nclient_5 Layer 88 weight diff: 1.9855753183\nclient_5 Layer 89 weight diff: 17.3703861237\nclient_5 Layer 90 weight diff: 8.1449584961\nclient_5 Layer 91 weight diff: 17.9153766632\nclient_5 Layer 92 weight diff: 1509.7700195312\nclient_5 Layer 93 weight diff: 1.9748404026\nclient_5 Layer 94 weight diff: 1.9835046530\nclient_5 Layer 95 weight diff: 12.9966726303\nclient_5 Layer 96 weight diff: 34.7974777222\nclient_5 Layer 97 weight diff: 18.7367210388\nclient_5 Layer 98 weight diff: 1540.7702636719\nclient_5 Layer 99 weight diff: 1.8888266087\nclient_5 Layer 100 weight diff: 2.0218577385\nclient_5 Layer 101 weight diff: 30.8902244568\nclient_5 Layer 102 weight diff: 30.5274696350\nclient_5 Layer 103 weight diff: 17.9596214294\nclient_5 Layer 104 weight diff: 1549.4053955078\nclient_5 Layer 105 weight diff: 2.0793650150\nclient_5 Layer 106 weight diff: 2.0836515427\nclient_5 Layer 107 weight diff: 9.0061826706\nclient_5 Layer 108 weight diff: 7.5515341759\nclient_5 Layer 109 weight diff: 19.0647621155\nclient_5 Layer 110 weight diff: 1547.0186767578\nclient_5 Layer 111 weight diff: 2.0119385719\nclient_5 Layer 112 weight diff: 1.9907433987\nclient_5 Layer 113 weight diff: 8.3215847015\nclient_5 Layer 114 weight diff: 16.9777526855\nclient_5 Layer 115 weight diff: 18.4158172607\nclient_5 Layer 116 weight diff: 1577.3397216797\nclient_5 Layer 117 weight diff: 2.1767807007\nclient_5 Layer 118 weight diff: 2.2229895592\nclient_5 Layer 119 weight diff: 19.2720451355\nclient_5 Layer 120 weight diff: 27.9367904663\nclient_5 Layer 121 weight diff: 19.4118270874\nclient_5 Layer 122 weight diff: 1573.1330566406\nclient_5 Layer 123 weight diff: 2.0636515617\nclient_5 Layer 124 weight diff: 2.0623872280\nclient_5 Layer 125 weight diff: 10.5131530762\nclient_5 Layer 126 weight diff: 5.3212332726\nclient_5 Layer 127 weight diff: 18.7020378113\nclient_5 Layer 128 weight diff: 1558.3906250000\nclient_5 Layer 129 weight diff: 2.1153855324\nclient_5 Layer 130 weight diff: 2.0369579792\nclient_5 Layer 131 weight diff: 8.1932945251\nclient_5 Layer 132 weight diff: 5.0357980728\nclient_5 Layer 133 weight diff: 19.1642799377\nclient_5 Layer 134 weight diff: 1538.8741455078\nclient_5 Layer 135 weight diff: 2.0296678543\nclient_5 Layer 136 weight diff: 2.1531431675\nclient_5 Layer 137 weight diff: 36.7822036743\nclient_5 Layer 138 weight diff: 33.6205863953\nclient_5 Layer 139 weight diff: 18.1032829285\nclient_5 Layer 140 weight diff: 1516.2946777344\nclient_5 Layer 141 weight diff: 2.0522584915\nclient_5 Layer 142 weight diff: 2.0876212120\nclient_5 Layer 143 weight diff: 16.8882579803\nclient_5 Layer 144 weight diff: 8.9414157867\nclient_5 Layer 145 weight diff: 18.5856666565\nclient_5 Layer 146 weight diff: 1514.0257568359\nclient_5 Layer 147 weight diff: 2.0851845741\nclient_5 Layer 148 weight diff: 1.9775383472\nclient_5 Layer 149 weight diff: 17.6851959229\nclient_5 Layer 150 weight diff: 12.8455953598\nclient_5 Layer 151 weight diff: 19.5697708130\nclient_5 Layer 152 weight diff: 1579.3430175781\nclient_5 Layer 153 weight diff: 2.2090003490\nclient_5 Layer 154 weight diff: 2.1936945915\nclient_5 Layer 155 weight diff: 31.3746414185\nclient_5 Layer 156 weight diff: 29.5938320160\nclient_5 Layer 157 weight diff: 19.4977340698\nclient_5 Layer 158 weight diff: 1554.1860351562\nclient_5 Layer 159 weight diff: 2.0824260712\nclient_5 Layer 160 weight diff: 2.0953469276\nclient_5 Layer 161 weight diff: 12.8829154968\nclient_5 Layer 162 weight diff: 8.9156837463\nclient_5 Layer 163 weight diff: 18.6451244354\nclient_5 Layer 164 weight diff: 1536.2497558594\nclient_5 Layer 165 weight diff: 1.9604611397\nclient_5 Layer 166 weight diff: 2.0195598602\nclient_5 Layer 167 weight diff: 9.3856353760\nclient_5 Layer 168 weight diff: 8.6285438538\nclient_5 Layer 169 weight diff: 19.3963756561\nclient_5 Layer 170 weight diff: 1536.4030761719\nclient_5 Layer 171 weight diff: 2.0765273571\nclient_5 Layer 172 weight diff: 2.0893096924\nclient_5 Layer 173 weight diff: 33.2074584961\nclient_5 Layer 174 weight diff: 41.9093170166\nclient_5 Layer 175 weight diff: 18.9998359680\nclient_5 Layer 176 weight diff: 1515.2341308594\nclient_5 Layer 177 weight diff: 2.1180388927\nclient_5 Layer 178 weight diff: 2.0701575279\nclient_5 Layer 179 weight diff: 15.1345319748\nclient_5 Layer 180 weight diff: 15.8340797424\nclient_5 Layer 181 weight diff: 18.5259170532\nclient_5 Layer 182 weight diff: 1501.6198730469\nclient_5 Layer 183 weight diff: 2.0231964588\nclient_5 Layer 184 weight diff: 2.0569243431\nclient_5 Layer 185 weight diff: 8.6107082367\nclient_5 Layer 186 weight diff: 10.8374061584\nclient_5 Layer 187 weight diff: 18.2887954712\nclient_5 Layer 188 weight diff: 1507.2404785156\nclient_5 Layer 189 weight diff: 1.9574685097\nclient_5 Layer 190 weight diff: 1.9690399170\nclient_5 Layer 191 weight diff: 45.0641860962\nclient_5 Layer 192 weight diff: 59.0347976685\nclient_5 Layer 193 weight diff: 17.3942184448\nclient_5 Layer 194 weight diff: 1497.6352539062\nclient_5 Layer 195 weight diff: 2.0008690357\nclient_5 Layer 196 weight diff: 2.0539612770\nclient_5 Layer 197 weight diff: 21.5644454956\nclient_5 Layer 198 weight diff: 22.4059715271\nclient_5 Layer 199 weight diff: 17.6943511963\nclient_5 Layer 200 weight diff: 1486.4860839844\nclient_5 Layer 201 weight diff: 1.9950062037\nclient_5 Layer 202 weight diff: 2.0671463013\nclient_5 Layer 203 weight diff: 11.9814376831\nclient_5 Layer 204 weight diff: 17.5827903748\nclient_5 Layer 205 weight diff: 18.4313468933\nclient_5 Layer 206 weight diff: 1497.0344238281\nclient_5 Layer 207 weight diff: 2.0111472607\nclient_5 Layer 208 weight diff: 2.0467104912\nclient_5 Layer 209 weight diff: 71.3625717163\nclient_5 Layer 210 weight diff: 197.0998535156\nclient_5 Layer 211 weight diff: 18.2951240540\nclient_5 Layer 212 weight diff: 2056.2583007812\nclient_5 Layer 213 weight diff: 2.8185615540\nclient_5 Layer 214 weight diff: 2.5188601017\nclient_5 Layer 215 weight diff: 27.8073673248\nclient_5 Layer 216 weight diff: 18.3436374664\nclient_5 Layer 217 weight diff: 2066.2434082031\nclient_5 Layer 218 weight diff: 2.7948198318\nclient_5 Layer 219 weight diff: 2.5188596249\nclient_5 Layer 220 weight diff: 1000.8471679688\nclient_5 Layer 221 weight diff: 35940.1484375000\nclient_5 Layer 222 weight diff: 25.5132160187\nclient_5 Layer 223 weight diff: 4437.9301757812\nclient_5 Layer 224 weight diff: 4.0837049484\nclient_5 Layer 225 weight diff: 4.1557507515\nclient_5 Layer 226 weight diff: 155.8908081055\nclient_5 Layer 227 weight diff: 395.3136901855\nclient_5 Layer 228 weight diff: 36.6685523987\nclient_5 Layer 229 weight diff: 7923.0776367188\nclient_5 Layer 230 weight diff: 5.2075347900\nclient_5 Layer 231 weight diff: 5.2804398537\nclient_5 Layer 232 weight diff: 169.2913360596\nclient_5 Layer 233 weight diff: 617.1512451172\nclient_5 Layer 234 weight diff: 0.0000000000\nclient_5 Layer 235 weight diff: 0.0000000000\nclient_5 Layer 236 weight diff: 0.0000000000\nclient_5 Layer 237 weight diff: 0.0000000000\nclient_5 training accuracy history: [0.9558823704719543, 0.9894958138465881, 0.9894958138465881, 0.9842436909675598, 0.9905462265014648]\nclient_5 total local-global weight diff: 88566.36742866\n\n📶 Training on client_6\nTraining client_6 for 5 epochs...\nSum of weights before training: 209082.156\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 957ms/step - accuracy: 0.9684 - loss: 0.1291 - precision_50: 0.9688 - recall_50: 0.9646\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 626ms/step - accuracy: 0.9843 - loss: 0.0570 - precision_50: 0.9875 - recall_50: 0.9836\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 679ms/step - accuracy: 0.9957 - loss: 0.0220 - precision_50: 0.9957 - recall_50: 0.9951\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 634ms/step - accuracy: 0.9835 - loss: 0.0762 - precision_50: 0.9836 - recall_50: 0.9835\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 678ms/step - accuracy: 0.9936 - loss: 0.0280 - precision_50: 0.9936 - recall_50: 0.9936\nSum of weights after training: 226401.172\nclient_6 Layer 0 weight diff: 0.0000000000\nclient_6 Layer 1 weight diff: 0.0000000000\nclient_6 Layer 2 weight diff: 0.0000000000\nclient_6 Layer 3 weight diff: 0.0000000000\nclient_6 Layer 4 weight diff: 0.0000000000\nclient_6 Layer 5 weight diff: 0.0000000000\nclient_6 Layer 6 weight diff: 0.0000000000\nclient_6 Layer 7 weight diff: 0.0000000000\nclient_6 Layer 8 weight diff: 0.0000000000\nclient_6 Layer 9 weight diff: 0.0000000000\nclient_6 Layer 10 weight diff: 0.0000000000\nclient_6 Layer 11 weight diff: 0.0000000000\nclient_6 Layer 12 weight diff: 0.0000000000\nclient_6 Layer 13 weight diff: 0.0000000000\nclient_6 Layer 14 weight diff: 0.0000000000\nclient_6 Layer 15 weight diff: 0.0000000000\nclient_6 Layer 16 weight diff: 0.0000000000\nclient_6 Layer 17 weight diff: 0.0000000000\nclient_6 Layer 18 weight diff: 0.0000000000\nclient_6 Layer 19 weight diff: 0.0000000000\nclient_6 Layer 20 weight diff: 0.0000000000\nclient_6 Layer 21 weight diff: 0.0000000000\nclient_6 Layer 22 weight diff: 0.0000000000\nclient_6 Layer 23 weight diff: 0.0000000000\nclient_6 Layer 24 weight diff: 0.0000000000\nclient_6 Layer 25 weight diff: 0.0000000000\nclient_6 Layer 26 weight diff: 0.0000000000\nclient_6 Layer 27 weight diff: 0.0000000000\nclient_6 Layer 28 weight diff: 0.0000000000\nclient_6 Layer 29 weight diff: 0.0000000000\nclient_6 Layer 30 weight diff: 0.0000000000\nclient_6 Layer 31 weight diff: 0.0000000000\nclient_6 Layer 32 weight diff: 0.0000000000\nclient_6 Layer 33 weight diff: 0.0000000000\nclient_6 Layer 34 weight diff: 0.0000000000\nclient_6 Layer 35 weight diff: 0.0000000000\nclient_6 Layer 36 weight diff: 0.0000000000\nclient_6 Layer 37 weight diff: 0.0000000000\nclient_6 Layer 38 weight diff: 0.0000000000\nclient_6 Layer 39 weight diff: 0.0000000000\nclient_6 Layer 40 weight diff: 0.0000000000\nclient_6 Layer 41 weight diff: 0.0000000000\nclient_6 Layer 42 weight diff: 0.0000000000\nclient_6 Layer 43 weight diff: 0.0000000000\nclient_6 Layer 44 weight diff: 0.0000000000\nclient_6 Layer 45 weight diff: 0.0000000000\nclient_6 Layer 46 weight diff: 0.0000000000\nclient_6 Layer 47 weight diff: 0.0000000000\nclient_6 Layer 48 weight diff: 0.0000000000\nclient_6 Layer 49 weight diff: 0.0000000000\nclient_6 Layer 50 weight diff: 0.0000000000\nclient_6 Layer 51 weight diff: 0.0000000000\nclient_6 Layer 52 weight diff: 0.0000000000\nclient_6 Layer 53 weight diff: 0.0000000000\nclient_6 Layer 54 weight diff: 0.0000000000\nclient_6 Layer 55 weight diff: 0.0000000000\nclient_6 Layer 56 weight diff: 0.0000000000\nclient_6 Layer 57 weight diff: 0.0000000000\nclient_6 Layer 58 weight diff: 0.0000000000\nclient_6 Layer 59 weight diff: 0.0000000000\nclient_6 Layer 60 weight diff: 0.0000000000\nclient_6 Layer 61 weight diff: 0.0000000000\nclient_6 Layer 62 weight diff: 0.0000000000\nclient_6 Layer 63 weight diff: 0.0000000000\nclient_6 Layer 64 weight diff: 0.0000000000\nclient_6 Layer 65 weight diff: 0.0000000000\nclient_6 Layer 66 weight diff: 0.0000000000\nclient_6 Layer 67 weight diff: 0.0000000000\nclient_6 Layer 68 weight diff: 0.0000000000\nclient_6 Layer 69 weight diff: 0.0000000000\nclient_6 Layer 70 weight diff: 0.0000000000\nclient_6 Layer 71 weight diff: 0.0000000000\nclient_6 Layer 72 weight diff: 0.0000000000\nclient_6 Layer 73 weight diff: 0.0000000000\nclient_6 Layer 74 weight diff: 0.0000000000\nclient_6 Layer 75 weight diff: 0.0000000000\nclient_6 Layer 76 weight diff: 0.0000000000\nclient_6 Layer 77 weight diff: 0.0000000000\nclient_6 Layer 78 weight diff: 0.0000000000\nclient_6 Layer 79 weight diff: 0.0000000000\nclient_6 Layer 80 weight diff: 0.0000000000\nclient_6 Layer 81 weight diff: 0.0000000000\nclient_6 Layer 82 weight diff: 0.0000000000\nclient_6 Layer 83 weight diff: 0.0000000000\nclient_6 Layer 84 weight diff: 0.0000000000\nclient_6 Layer 85 weight diff: 18.0144042969\nclient_6 Layer 86 weight diff: 1448.3704833984\nclient_6 Layer 87 weight diff: 1.8281191587\nclient_6 Layer 88 weight diff: 1.7901799679\nclient_6 Layer 89 weight diff: 17.3577880859\nclient_6 Layer 90 weight diff: 7.7400913239\nclient_6 Layer 91 weight diff: 16.9012737274\nclient_6 Layer 92 weight diff: 1479.4815673828\nclient_6 Layer 93 weight diff: 2.0056283474\nclient_6 Layer 94 weight diff: 1.9680935144\nclient_6 Layer 95 weight diff: 14.2912521362\nclient_6 Layer 96 weight diff: 37.4171371460\nclient_6 Layer 97 weight diff: 19.0627727509\nclient_6 Layer 98 weight diff: 1561.6199951172\nclient_6 Layer 99 weight diff: 2.0742099285\nclient_6 Layer 100 weight diff: 2.1010055542\nclient_6 Layer 101 weight diff: 33.4076194763\nclient_6 Layer 102 weight diff: 33.4767875671\nclient_6 Layer 103 weight diff: 18.9252834320\nclient_6 Layer 104 weight diff: 1548.8551025391\nclient_6 Layer 105 weight diff: 2.0110626221\nclient_6 Layer 106 weight diff: 2.0811429024\nclient_6 Layer 107 weight diff: 8.6283493042\nclient_6 Layer 108 weight diff: 8.3066902161\nclient_6 Layer 109 weight diff: 18.3877067566\nclient_6 Layer 110 weight diff: 1538.5645751953\nclient_6 Layer 111 weight diff: 1.9771602154\nclient_6 Layer 112 weight diff: 1.9500490427\nclient_6 Layer 113 weight diff: 8.8719778061\nclient_6 Layer 114 weight diff: 27.4939765930\nclient_6 Layer 115 weight diff: 18.7078514099\nclient_6 Layer 116 weight diff: 1573.5593261719\nclient_6 Layer 117 weight diff: 2.0833992958\nclient_6 Layer 118 weight diff: 2.1160812378\nclient_6 Layer 119 weight diff: 20.9817695618\nclient_6 Layer 120 weight diff: 29.7008514404\nclient_6 Layer 121 weight diff: 18.4860572815\nclient_6 Layer 122 weight diff: 1551.7424316406\nclient_6 Layer 123 weight diff: 1.8998800516\nclient_6 Layer 124 weight diff: 1.9626175165\nclient_6 Layer 125 weight diff: 11.3343362808\nclient_6 Layer 126 weight diff: 6.3953065872\nclient_6 Layer 127 weight diff: 17.9871902466\nclient_6 Layer 128 weight diff: 1532.3118896484\nclient_6 Layer 129 weight diff: 2.0708408356\nclient_6 Layer 130 weight diff: 1.9566128254\nclient_6 Layer 131 weight diff: 9.1366252899\nclient_6 Layer 132 weight diff: 7.1890172958\nclient_6 Layer 133 weight diff: 19.1355381012\nclient_6 Layer 134 weight diff: 1510.7008056641\nclient_6 Layer 135 weight diff: 2.1579146385\nclient_6 Layer 136 weight diff: 2.1563367844\nclient_6 Layer 137 weight diff: 37.0884323120\nclient_6 Layer 138 weight diff: 31.5248794556\nclient_6 Layer 139 weight diff: 18.7355556488\nclient_6 Layer 140 weight diff: 1486.8947753906\nclient_6 Layer 141 weight diff: 1.9248890877\nclient_6 Layer 142 weight diff: 2.0327408314\nclient_6 Layer 143 weight diff: 15.1189785004\nclient_6 Layer 144 weight diff: 7.9082622528\nclient_6 Layer 145 weight diff: 17.8406543732\nclient_6 Layer 146 weight diff: 1500.8337402344\nclient_6 Layer 147 weight diff: 1.9331078529\nclient_6 Layer 148 weight diff: 1.9341289997\nclient_6 Layer 149 weight diff: 17.8918571472\nclient_6 Layer 150 weight diff: 11.3128213882\nclient_6 Layer 151 weight diff: 19.6098098755\nclient_6 Layer 152 weight diff: 1540.0395507812\nclient_6 Layer 153 weight diff: 2.0701665878\nclient_6 Layer 154 weight diff: 2.1783118248\nclient_6 Layer 155 weight diff: 31.8549041748\nclient_6 Layer 156 weight diff: 29.9036998749\nclient_6 Layer 157 weight diff: 18.9579277039\nclient_6 Layer 158 weight diff: 1510.5698242188\nclient_6 Layer 159 weight diff: 2.0058302879\nclient_6 Layer 160 weight diff: 2.0706937313\nclient_6 Layer 161 weight diff: 13.4270706177\nclient_6 Layer 162 weight diff: 9.3387947083\nclient_6 Layer 163 weight diff: 18.3247451782\nclient_6 Layer 164 weight diff: 1495.1798095703\nclient_6 Layer 165 weight diff: 1.9384120703\nclient_6 Layer 166 weight diff: 1.9589099884\nclient_6 Layer 167 weight diff: 9.5619907379\nclient_6 Layer 168 weight diff: 8.5384902954\nclient_6 Layer 169 weight diff: 18.7131004333\nclient_6 Layer 170 weight diff: 1494.4309082031\nclient_6 Layer 171 weight diff: 2.0013160706\nclient_6 Layer 172 weight diff: 2.1040735245\nclient_6 Layer 173 weight diff: 32.3228454590\nclient_6 Layer 174 weight diff: 42.0465736389\nclient_6 Layer 175 weight diff: 18.1680526733\nclient_6 Layer 176 weight diff: 1458.2053222656\nclient_6 Layer 177 weight diff: 1.9328675270\nclient_6 Layer 178 weight diff: 2.0186524391\nclient_6 Layer 179 weight diff: 13.9451522827\nclient_6 Layer 180 weight diff: 15.8215541840\nclient_6 Layer 181 weight diff: 16.8024425507\nclient_6 Layer 182 weight diff: 1439.1027832031\nclient_6 Layer 183 weight diff: 1.8845214844\nclient_6 Layer 184 weight diff: 1.8695657253\nclient_6 Layer 185 weight diff: 8.1623859406\nclient_6 Layer 186 weight diff: 10.4335460663\nclient_6 Layer 187 weight diff: 18.7821598053\nclient_6 Layer 188 weight diff: 1483.1347656250\nclient_6 Layer 189 weight diff: 1.9981386662\nclient_6 Layer 190 weight diff: 2.0377564430\nclient_6 Layer 191 weight diff: 38.9896202087\nclient_6 Layer 192 weight diff: 58.3387222290\nclient_6 Layer 193 weight diff: 18.5304870605\nclient_6 Layer 194 weight diff: 1439.9052734375\nclient_6 Layer 195 weight diff: 1.8942996264\nclient_6 Layer 196 weight diff: 1.8956626654\nclient_6 Layer 197 weight diff: 18.0577087402\nclient_6 Layer 198 weight diff: 19.4067401886\nclient_6 Layer 199 weight diff: 16.6150093079\nclient_6 Layer 200 weight diff: 1407.5791015625\nclient_6 Layer 201 weight diff: 1.8456615210\nclient_6 Layer 202 weight diff: 1.8831236362\nclient_6 Layer 203 weight diff: 11.7336521149\nclient_6 Layer 204 weight diff: 13.8673715591\nclient_6 Layer 205 weight diff: 17.2123489380\nclient_6 Layer 206 weight diff: 1446.0617675781\nclient_6 Layer 207 weight diff: 1.8814063072\nclient_6 Layer 208 weight diff: 1.8489947319\nclient_6 Layer 209 weight diff: 63.6402473450\nclient_6 Layer 210 weight diff: 174.3306579590\nclient_6 Layer 211 weight diff: 17.8437042236\nclient_6 Layer 212 weight diff: 1997.1319580078\nclient_6 Layer 213 weight diff: 2.6409397125\nclient_6 Layer 214 weight diff: 2.3162822723\nclient_6 Layer 215 weight diff: 29.2616977692\nclient_6 Layer 216 weight diff: 23.9969139099\nclient_6 Layer 217 weight diff: 1964.6818847656\nclient_6 Layer 218 weight diff: 2.6527097225\nclient_6 Layer 219 weight diff: 2.3162817955\nclient_6 Layer 220 weight diff: 783.6307373047\nclient_6 Layer 221 weight diff: 26680.8320312500\nclient_6 Layer 222 weight diff: 24.7429656982\nclient_6 Layer 223 weight diff: 4351.3574218750\nclient_6 Layer 224 weight diff: 4.2546405792\nclient_6 Layer 225 weight diff: 4.2950086594\nclient_6 Layer 226 weight diff: 142.5178680420\nclient_6 Layer 227 weight diff: 433.4802856445\nclient_6 Layer 228 weight diff: 37.7529983521\nclient_6 Layer 229 weight diff: 8146.7001953125\nclient_6 Layer 230 weight diff: 5.3099164963\nclient_6 Layer 231 weight diff: 5.3843531609\nclient_6 Layer 232 weight diff: 373.0954589844\nclient_6 Layer 233 weight diff: 1684.2043457031\nclient_6 Layer 234 weight diff: 0.0000000000\nclient_6 Layer 235 weight diff: 0.0000000000\nclient_6 Layer 236 weight diff: 0.0000000000\nclient_6 Layer 237 weight diff: 0.0000000000\nclient_6 training accuracy history: [0.9642105102539062, 0.9831578731536865, 0.9936842322349548, 0.9852631688117981, 0.9915789365768433]\nclient_6 total local-global weight diff: 79661.07487118\n\n✅ Round 5 average client accuracy: 0.9940\n\n📈 Global model evaluation on test data: {'loss': 0.031960584223270416, 'compile_metrics': 0.9908466935157776}\n\n🔁 Federated Round 6\n\n📶 Training on client_1\nTraining client_1 for 5 epochs...\nSum of weights before training: 226489.141\nEpoch 1/5\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2270025219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mtest_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/kaggle/input/braintumor-detection/final_test_data/final_test_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFederatedLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederated_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_35/2270025219.py\u001b[0m in \u001b[0;36mfederated_training\u001b[0;34m(self, rounds)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mclient_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n📶 Training on {client_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_client_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0mclient_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/2270025219.py\u001b[0m in \u001b[0;36mtrain_client_model\u001b[0;34m(self, client_name)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Sum of weights before training: {sum_weights_before:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         history = local_model.fit(\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mmulti_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 return tf.experimental.Optional.from_value(\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m    115\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mtrainable_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m   \u001b[0msum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_scaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m       \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    726\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9673\u001b[0m     \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9674\u001b[0m   \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9675\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   9676\u001b[0m         \"Shape\", input=input, out_type=out_type, name=name)\n\u001b[1;32m   9677\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    797\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m     return super()._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         compute_device)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2699\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2701\u001b[0;31m       ret = Operation.from_node_def(\n\u001b[0m\u001b[1;32m   2702\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mfrom_node_def\u001b[0;34m(cls, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1145\u001b[0m       raise TypeError(f\"Argument node_def must be a NodeDef. \"\n\u001b[1;32m   1146\u001b[0m                       f\"Received an instance of type: {type(node_def)}.\")\n\u001b[0;32m-> 1147\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m       raise ValueError(\n\u001b[1;32m   1149\u001b[0m           \u001b[0;34mf\"Cannot create a tensor proto whose content is larger than 2GB. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/protobuf/internal/encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[0;34m(map_value)\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;31m# duplication. For message map, value.ByteSize() should be called to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;31m# update the status.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mentry_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmessage_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_message_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m           \u001b[0mfield_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GetIntegerEnumValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menum_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m           \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m           \u001b[0m_ReraiseTypeErrorWithFieldName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mfield_setter\u001b[0;34m(self, new_value)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;31m# (0, 0.0, enum 0, and False).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_checker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m       raise TypeError(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/protobuf/internal/type_checkers.py\u001b[0m in \u001b[0;36mCheckValue\u001b[0;34m(self, proposed_value)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mproposed_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         raise ValueError('%.1024r isn\\'t a valid unicode string and '\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"fl.global_model.save(\"global_model_round5.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T15:01:07.302737Z","iopub.execute_input":"2025-06-04T15:01:07.303438Z","iopub.status.idle":"2025-06-04T15:01:07.319452Z","shell.execute_reply.started":"2025-06-04T15:01:07.303415Z","shell.execute_reply":"2025-06-04T15:01:07.318247Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1868025595.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"global_model_round5.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'fl' is not defined"],"ename":"NameError","evalue":"name 'fl' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"fl.global_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T13:56:00.048882Z","iopub.execute_input":"2025-06-04T13:56:00.049358Z","iopub.status.idle":"2025-06-04T13:56:00.070041Z","shell.execute_reply.started":"2025-06-04T13:56:00.049334Z","shell.execute_reply":"2025-06-04T13:56:00.069429Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ xception (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │      \u001b[38;5;34m20,861,480\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m262,272\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,124,268\u001b[0m (80.58 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,124,268</span> (80.58 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,548,224\u001b[0m (66.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,548,224</span> (66.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,576,044\u001b[0m (13.64 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,576,044</span> (13.64 MB)\n</pre>\n"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import load_model\n\nmodel = load_model(r\"/kaggle/input/models/global_model_round5.h5\")\nplot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T15:18:04.377102Z","iopub.execute_input":"2025-06-04T15:18:04.377430Z","iopub.status.idle":"2025-06-04T15:18:13.731069Z","shell.execute_reply.started":"2025-06-04T15:18:04.377405Z","shell.execute_reply":"2025-06-04T15:18:13.730290Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1749050288.540416      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1749050288.541316      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"image/png":"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\n","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T15:18:49.257943Z","iopub.execute_input":"2025-06-04T15:18:49.258247Z","iopub.status.idle":"2025-06-04T15:18:49.282332Z","shell.execute_reply.started":"2025-06-04T15:18:49.258224Z","shell.execute_reply":"2025-06-04T15:18:49.281531Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ xception (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │      \u001b[38;5;34m20,861,480\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m262,272\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,124,270\u001b[0m (80.58 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,124,270</span> (80.58 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,548,224\u001b[0m (66.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,548,224</span> (66.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,576,044\u001b[0m (13.64 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,576,044</span> (13.64 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import load_model\n\ndef test_brain_tumor_model(model_path, img_path):\n    # Load the trained model\n    model = load_model(model_path)\n\n    # Class labels\n    class_names = ['Meningioma', 'Notumor', 'Glioma', 'Pituitary']\n\n    # Load and preprocess the image\n    img = image.load_img(img_path, target_size=(299, 299))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)  # Batch dimension\n    img_array = img_array / 255.0  # Normalize\n\n    # Prediction\n    preds = model.predict(img_array)\n    predicted_index = np.argmax(preds)\n    predicted_name = class_names[predicted_index]\n\n    print(f\"Predicted class index: {predicted_index}\")\n    print(f\"Class probabilities: {preds}\")\n    print(f\"Predicted class name: {predicted_name}\")\n\n    # Visualize prediction\n    probs = preds[0]\n    plt.figure(figsize=(6, 4))\n    bars = plt.bar(class_names, probs, color='skyblue')\n    bars[predicted_index].set_color('orange')\n    #plt.title(\"Prediction Probabilities\")\n    plt.ylabel(\"Probability\")\n    plt.ylim([0, 1])\n    plt.text(predicted_index, probs[predicted_index] + 0.02,\n             f\"{probs[predicted_index]*100:.2f}%\", ha='center', fontsize=10, weight='bold')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T15:21:40.369512Z","iopub.execute_input":"2025-06-04T15:21:40.369855Z","iopub.status.idle":"2025-06-04T15:21:40.377640Z","shell.execute_reply.started":"2025-06-04T15:21:40.369834Z","shell.execute_reply":"2025-06-04T15:21:40.376863Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"test_brain_tumor_model(\n    model_path=r'/kaggle/input/models/global_model_round5.h5',\n    img_path=r'/kaggle/input/braintumor-detection/final_test_data/final_test_data/notumor/Te-noTr_0000.jpg'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T16:16:43.149043Z","iopub.execute_input":"2025-06-04T16:16:43.149359Z","iopub.status.idle":"2025-06-04T16:16:48.140928Z","shell.execute_reply.started":"2025-06-04T16:16:43.149339Z","shell.execute_reply":"2025-06-04T16:16:48.140021Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\nPredicted class index: 2\nClass probabilities: [[4.3421000e-04 1.7409270e-04 9.9938524e-01 6.4435094e-06]]\nPredicted class name: Glioma\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":15}]}